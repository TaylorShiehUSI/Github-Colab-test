{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220814 2230.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMHzDrWuV0lx1oYx3PLd8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaylorShiehUSI/Github-Colab-test/blob/main/20220814_2230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k8nXyuRd_S",
        "outputId": "4b42bd35-a4d4-44ec-8052-0892132f67aa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "cviUbaTWRSko"
      },
      "outputs": [],
      "source": [
        "# 下載資料套件\n",
        "import requests as r\n",
        "\n",
        "# 資料處理套件\n",
        "from lxml import etree\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "# 財經套件\n",
        "# import yfinance as yf\n",
        "\n",
        "# 畫圖套件\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## down load stock data\n",
        "def get_tw_stock_data(start_year, start_month, end_year, end_month, stock_code):\n",
        "    start_date = str(date(start_year, start_month, 1))\n",
        "    end_date = str(date(end_year, end_month, 1))\n",
        "    month_list = pd.date_range(start_date, end_date, freq='MS').strftime(\"%Y%m%d\").tolist()\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    for month in month_list:\n",
        "        url = \"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"+ month + \"&stockNo=\" + str(stock_code)\n",
        "        res = r.get(url)\n",
        "        stock_json = res.json()\n",
        "        stock_df = pd.DataFrame.from_dict(stock_json['data'])\n",
        "        df = df.append(stock_df, ignore_index = True)\n",
        "        \n",
        "    # 資料轉型\n",
        "    for col in [0, 1, 2, 3, 4, 5, 6, 8]:\n",
        "        for row in range(df.shape[0]):\n",
        "            # 把\"日期\"從字串(string)換成時間(datetime)，並將民國年換成西元年\n",
        "            if col == 0:\n",
        "                day = df.iloc[row,0].split('/')\n",
        "                df.iloc[row, 0] = datetime(int(day[0]) + 1911, int(day[1]), int(day[2]))  \n",
        "            # 把\"開盤價\", \"最高價\", \"最低價\", \"收盤價\"帶有逗號的字串(string)換成浮點數(float) \n",
        "            elif col != 0:\n",
        "                df.iloc[row, col] = float(df.iloc[row,col].replace(',', ''))\n",
        "    \n",
        "    df.columns = ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數']\n",
        "    return df"
      ],
      "metadata": {
        "id": "6IuqlNYjRvxb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  input Start - End , and stock index\n",
        "stock_df = get_tw_stock_data(start_year = 2021, \n",
        "                start_month = 1, \n",
        "                end_year = 2022, \n",
        "                end_month = 8, \n",
        "                stock_code = 2330)\n",
        "stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "tjxBWizKRyTK",
        "outputId": "7df0622e-f0d2-45da-f911-3980093bf742"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    383\u001b[0m                     \u001b[0;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    383\u001b[0m                     \u001b[0;31m# otherwise it looks like a programming error was the cause.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-a19af238e6f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mend_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2022\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mend_month\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 stock_code = 2330)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mstock_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-704851048cdc>\u001b[0m in \u001b[0;36mget_tw_stock_data\u001b[0;34m(start_year, start_month, end_year, end_month, stock_code)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonth_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&stockNo=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mstock_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mstock_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.to_csv('2230.csv',encoding='utf-8_sig')"
      ],
      "metadata": {
        "id": "aa45vys1Vefv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Processing // Add is_up\n",
        "import numpy as np\n",
        "\n",
        "stock_df['is_up'] = (stock_df['開盤價'].shift(-1) - stock_df['收盤價'] >0).astype('int')\n",
        "stock_df['高低差'] = (stock_df['最高價'] - stock_df['最低價']).astype('int')\n",
        "stock_df['漲跌價差'] = (stock_df['收盤價'] - stock_df['開盤價']).astype('int')\n",
        "stock_df['單筆股數'] = (stock_df['成交股數']/stock_df['成交筆數']).astype('int')\n",
        "\n",
        "def one_hot(targets, nb_classes):\n",
        "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "y_data = one_hot(stock_df['is_up'], 2)\n",
        "stock_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s28R2AUsYOgW",
        "outputId": "054d9f1a-da36-489b-ad31-54ab482a2b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    日期        成交股數           成交金額    開盤價    最高價    最低價    收盤價  \\\n",
              "0  2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0  536.0   \n",
              "1  2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0  542.0   \n",
              "2  2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0  549.0   \n",
              "3  2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0  565.0   \n",
              "4  2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0  580.0   \n",
              "\n",
              "   漲跌價差     成交筆數  is_up  高低差  單筆股數  \n",
              "0     6  33316.0      0   12  1185  \n",
              "1     6  28512.0      1    7  1221  \n",
              "2    -6  55462.0      1   14  1002  \n",
              "3    11  47905.0      1   17  1114  \n",
              "4     0  56426.0      0    9  1115  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9c763bb-be67-477b-8c71-aa235979904b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>is_up</th>\n",
              "      <th>高低差</th>\n",
              "      <th>單筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>6</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>6</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>-6</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>11</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>0</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9c763bb-be67-477b-8c71-aa235979904b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9c763bb-be67-477b-8c71-aa235979904b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9c763bb-be67-477b-8c71-aa235979904b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock Data Exploring\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '成交金額',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '成交筆數',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '單筆股數',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '高低差', kde=False)\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '漲跌價差', kde=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6L5IslyY-A0",
        "outputId": "0f9dc0e5-f1cb-4169-df11-579682d81c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 28466 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36300 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20729 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fea2fab9810>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 28466 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36300 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20729 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data = pd.read_csv('data/data1to21.csv', header=None)\n",
        "\n",
        "# data[52] = data[52].astype(int).data\n",
        "\n",
        "# # # 計算fisher得分\n",
        "# items = list(range(52))\n",
        "\n",
        "# num_classes = len(set(data[52]))\n",
        "\n",
        "# fisher_score = []\n",
        "\n",
        "# grouped = data.groupby([52], as_index=False)\n",
        "\n",
        "# n = [len(data[data[52] == k+1]) for k in range(num_classes)]\n",
        "\n",
        "# for i in items:  # 遍歷所有特徵列\n",
        "#     temp = grouped[i].agg({str(i)+'_mean': 'mean',\n",
        "#                            str(i)+'_std': 'std'})     # 已求出特徵i在各類別k中的均值u_ik、方差p_ik\n",
        "\n",
        "#     numerator = 0\n",
        "#     denominator = 0\n",
        "\n",
        "#     u_i = data[i].mean()\n",
        "\n",
        "#     for k in range(num_classes):\n",
        "#         n_k = n[k]\n",
        "#         u_ik = temp.iloc[k, :][str(i)+'_mean']\n",
        "#         p_ik = temp.iloc[k, :][str(i)+'_std']\n",
        "\n",
        "#         numerator += n_k*(u_ik-u_i)**2\n",
        "#         denominator += n_k*p_ik**2\n",
        "\n",
        "#     fisher_score.append(numerator/denominator)\n",
        "\n",
        "# pd.DataFrame(fisher_score).to_csv('fisher_score.csv', index=False, header=None)"
      ],
      "metadata": {
        "id": "fwRsmXg4GsQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Feature Engineering\n",
        "# ##group = data.groupby(\"company\")\n",
        "# ##list(group)\n",
        "# ##data.groupby(\"company\").agg('mean')\n",
        "# ##data.groupby('company').agg({'salary':'median','age':'mean'})\n",
        "# ##avg_salary_dict = data.groupby('company')['salary'].mean().to_dict()\n",
        "# ​##data['avg_salary'] = data['company'].map(avg_salary_dict)\n",
        "\n",
        "# group1 = stock_df.groupby(\"is_up\").agg({'成交股數':'mean'})\n",
        "# print(group1)\n",
        "\n",
        "# group2 = stock_df.groupby(\"is_up\").agg({'成交金額':'mean'})\n",
        "# print(group2)\n",
        "\n",
        "# # As feature\n",
        "# group3 = stock_df.groupby(\"is_up\").agg({'漲跌價差':'mean'})\n",
        "# print(group3)\n",
        "\n",
        "# # As feature\n",
        "# group4 = stock_df.groupby(\"is_up\").agg({'高低差':'mean'})\n",
        "# print(group4)\n",
        "\n",
        "# # As feature\n",
        "# group5 = stock_df.groupby(\"is_up\").agg({'單筆股數':'mean'})\n",
        "# print(group5)\n",
        "\n",
        "# group6 = stock_df.groupby(\"is_up\").agg({'成交筆數':'mean'})\n",
        "# print(group6)\n",
        "\n",
        "# group7 = stock_df.groupby(\"is_up\").agg({'收盤價':'mean'})\n",
        "# print(group7)\n",
        "# ## data.groupby(\"company\").agg('mean')\n",
        "# ## data.groupby('company').agg({'salary':'median','age':'mean'})\n",
        "# ## avg_salary_dict = data.groupby('company')['salary'].mean().to_dict()\n",
        "# ​## data['avg_salary'] = data['company'].map(avg_salary_dict)\n",
        "# ## Prepare Feature Data\n",
        "\n",
        "X_data = stock_df.drop(['日期','is_up'], axis=1)\n",
        "X_data.head()\n",
        "X_data.columns"
      ],
      "metadata": {
        "id": "ZLkeXMcLxjrf",
        "outputId": "a447410d-959f-4c58-ecc5-bc6a20d93e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數', '高低差',\n",
              "       '單筆股數'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalized\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "scaled = scaler.fit_transform(X_data)\n",
        "X_data = pd.DataFrame(scaled, columns=X_data.columns)\n",
        "#print(X_data)\n",
        "X_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WeNiJCBNQ3x9",
        "outputId": "a20aa4bc-5841-4f45-e978-decee9e148f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       成交股數      成交金額       開盤價       最高價       最低價       收盤價      漲跌價差  \\\n",
              "0  0.080186 -0.071667 -1.153338 -1.019302 -1.096278 -1.012538  1.013817   \n",
              "1 -0.134087 -0.247813 -1.019090 -0.974565 -0.938529 -0.878155  1.013817   \n",
              "2  0.823115  0.631591 -0.593973 -0.683771 -0.803315 -0.721375 -0.906334   \n",
              "3  0.720752  0.590331 -0.616347 -0.348240 -0.532888 -0.363020  1.813879   \n",
              "4  1.161428  1.060977 -0.034607 -0.124553 -0.127247 -0.027063  0.053742   \n",
              "\n",
              "       成交筆數       高低差      單筆股數  \n",
              "0 -0.379426  0.621208  0.741872  \n",
              "1 -0.487942 -0.380414  0.845271  \n",
              "2  0.120824  1.021857  0.216262  \n",
              "3 -0.049879  1.622830  0.537947  \n",
              "4  0.142600  0.020235  0.540819  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-536dc34d-1b94-4971-ac3c-87f35d04e901\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>高低差</th>\n",
              "      <th>單筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.080186</td>\n",
              "      <td>-0.071667</td>\n",
              "      <td>-1.153338</td>\n",
              "      <td>-1.019302</td>\n",
              "      <td>-1.096278</td>\n",
              "      <td>-1.012538</td>\n",
              "      <td>1.013817</td>\n",
              "      <td>-0.379426</td>\n",
              "      <td>0.621208</td>\n",
              "      <td>0.741872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.134087</td>\n",
              "      <td>-0.247813</td>\n",
              "      <td>-1.019090</td>\n",
              "      <td>-0.974565</td>\n",
              "      <td>-0.938529</td>\n",
              "      <td>-0.878155</td>\n",
              "      <td>1.013817</td>\n",
              "      <td>-0.487942</td>\n",
              "      <td>-0.380414</td>\n",
              "      <td>0.845271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.823115</td>\n",
              "      <td>0.631591</td>\n",
              "      <td>-0.593973</td>\n",
              "      <td>-0.683771</td>\n",
              "      <td>-0.803315</td>\n",
              "      <td>-0.721375</td>\n",
              "      <td>-0.906334</td>\n",
              "      <td>0.120824</td>\n",
              "      <td>1.021857</td>\n",
              "      <td>0.216262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.720752</td>\n",
              "      <td>0.590331</td>\n",
              "      <td>-0.616347</td>\n",
              "      <td>-0.348240</td>\n",
              "      <td>-0.532888</td>\n",
              "      <td>-0.363020</td>\n",
              "      <td>1.813879</td>\n",
              "      <td>-0.049879</td>\n",
              "      <td>1.622830</td>\n",
              "      <td>0.537947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.161428</td>\n",
              "      <td>1.060977</td>\n",
              "      <td>-0.034607</td>\n",
              "      <td>-0.124553</td>\n",
              "      <td>-0.127247</td>\n",
              "      <td>-0.027063</td>\n",
              "      <td>0.053742</td>\n",
              "      <td>0.142600</td>\n",
              "      <td>0.020235</td>\n",
              "      <td>0.540819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-536dc34d-1b94-4971-ac3c-87f35d04e901')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-536dc34d-1b94-4971-ac3c-87f35d04e901 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-536dc34d-1b94-4971-ac3c-87f35d04e901');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model, with preparing the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# keep one hot Encoding in y for Cross Table\n",
        "y_test_cross = y_test\n",
        "y_test_cross = np.argmax(y_test_cross,axis=1)\n",
        "print(y_test_cross)\n",
        "# print(y_test_cross)\n",
        "\n",
        "X_train = K.cast_to_floatx(X_train)\n",
        "y_train = K.cast_to_floatx(y_train)\n",
        "X_test = K.cast_to_floatx(X_test)\n",
        "y_test = K.cast_to_floatx(y_test)"
      ],
      "metadata": {
        "id": "dSxbm6ltjPHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249d2023-9b20-4448-ad91-36999637816e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot( stock_df['收盤價'], '--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2M7fNrNijimi",
        "outputId": "4e55b3b8-f1c7-4721-c41f-4a49bc934d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ],
      "metadata": {
        "id": "G_DulbtRjrdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set up model, and print the model summary\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 128,\n",
        "                input_shape=X_train.shape[1:],\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(units = 2,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f98ijyGEjunx",
        "outputId": "f2cf6659-4e64-43ea-e250-458977168c10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,602\n",
            "Trainable params: 2,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "model.fit(x = X_train,\n",
        "          y = y_train,\n",
        "          validation_split = 0.2,\n",
        "          batch_size=128,\n",
        "          epochs=1000,\n",
        "          verbose = 2) "
      ],
      "metadata": {
        "id": "Kd8QlzjZkAG4",
        "outputId": "33e76155-6a10-43d0-df79-f1fd27d9f16a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 - 1s - loss: 0.6932 - accuracy: 0.4484 - val_loss: 0.6931 - val_accuracy: 0.5625 - 953ms/epoch - 477ms/step\n",
            "Epoch 2/1000\n",
            "2/2 - 0s - loss: 0.6932 - accuracy: 0.4881 - val_loss: 0.6933 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 3/1000\n",
            "2/2 - 0s - loss: 0.6931 - accuracy: 0.5278 - val_loss: 0.6934 - val_accuracy: 0.4375 - 29ms/epoch - 14ms/step\n",
            "Epoch 4/1000\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5278 - val_loss: 0.6936 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 5/1000\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5278 - val_loss: 0.6937 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 6/1000\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5278 - val_loss: 0.6939 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 7/1000\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5278 - val_loss: 0.6941 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 8/1000\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5278 - val_loss: 0.6943 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 9/1000\n",
            "2/2 - 0s - loss: 0.6927 - accuracy: 0.5278 - val_loss: 0.6944 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 10/1000\n",
            "2/2 - 0s - loss: 0.6926 - accuracy: 0.5278 - val_loss: 0.6946 - val_accuracy: 0.4375 - 28ms/epoch - 14ms/step\n",
            "Epoch 11/1000\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5278 - val_loss: 0.6949 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 12/1000\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5278 - val_loss: 0.6951 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 13/1000\n",
            "2/2 - 0s - loss: 0.6924 - accuracy: 0.5278 - val_loss: 0.6953 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 14/1000\n",
            "2/2 - 0s - loss: 0.6924 - accuracy: 0.5278 - val_loss: 0.6955 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 15/1000\n",
            "2/2 - 0s - loss: 0.6923 - accuracy: 0.5278 - val_loss: 0.6957 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 16/1000\n",
            "2/2 - 0s - loss: 0.6922 - accuracy: 0.5278 - val_loss: 0.6959 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 17/1000\n",
            "2/2 - 0s - loss: 0.6921 - accuracy: 0.5278 - val_loss: 0.6962 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 18/1000\n",
            "2/2 - 0s - loss: 0.6921 - accuracy: 0.5278 - val_loss: 0.6964 - val_accuracy: 0.4375 - 45ms/epoch - 23ms/step\n",
            "Epoch 19/1000\n",
            "2/2 - 0s - loss: 0.6921 - accuracy: 0.5278 - val_loss: 0.6966 - val_accuracy: 0.4375 - 41ms/epoch - 20ms/step\n",
            "Epoch 20/1000\n",
            "2/2 - 0s - loss: 0.6917 - accuracy: 0.5278 - val_loss: 0.6969 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 21/1000\n",
            "2/2 - 0s - loss: 0.6918 - accuracy: 0.5278 - val_loss: 0.6972 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 22/1000\n",
            "2/2 - 0s - loss: 0.6916 - accuracy: 0.5278 - val_loss: 0.6975 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 23/1000\n",
            "2/2 - 0s - loss: 0.6914 - accuracy: 0.5278 - val_loss: 0.6978 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 24/1000\n",
            "2/2 - 0s - loss: 0.6914 - accuracy: 0.5278 - val_loss: 0.6982 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 25/1000\n",
            "2/2 - 0s - loss: 0.6910 - accuracy: 0.5278 - val_loss: 0.6987 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 26/1000\n",
            "2/2 - 0s - loss: 0.6911 - accuracy: 0.5278 - val_loss: 0.6992 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 27/1000\n",
            "2/2 - 0s - loss: 0.6909 - accuracy: 0.5278 - val_loss: 0.6997 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 28/1000\n",
            "2/2 - 0s - loss: 0.6907 - accuracy: 0.5278 - val_loss: 0.7002 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 29/1000\n",
            "2/2 - 0s - loss: 0.6902 - accuracy: 0.5278 - val_loss: 0.7009 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 30/1000\n",
            "2/2 - 0s - loss: 0.6898 - accuracy: 0.5278 - val_loss: 0.7017 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 31/1000\n",
            "2/2 - 0s - loss: 0.6899 - accuracy: 0.5278 - val_loss: 0.7024 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 32/1000\n",
            "2/2 - 0s - loss: 0.6900 - accuracy: 0.5278 - val_loss: 0.7032 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 33/1000\n",
            "2/2 - 0s - loss: 0.6878 - accuracy: 0.5278 - val_loss: 0.7042 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 34/1000\n",
            "2/2 - 0s - loss: 0.6873 - accuracy: 0.5278 - val_loss: 0.7053 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 35/1000\n",
            "2/2 - 0s - loss: 0.6897 - accuracy: 0.5278 - val_loss: 0.7065 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 36/1000\n",
            "2/2 - 0s - loss: 0.6850 - accuracy: 0.5278 - val_loss: 0.7078 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 37/1000\n",
            "2/2 - 0s - loss: 0.6851 - accuracy: 0.5278 - val_loss: 0.7092 - val_accuracy: 0.4375 - 58ms/epoch - 29ms/step\n",
            "Epoch 38/1000\n",
            "2/2 - 0s - loss: 0.6841 - accuracy: 0.5278 - val_loss: 0.7109 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 39/1000\n",
            "2/2 - 0s - loss: 0.6809 - accuracy: 0.5278 - val_loss: 0.7130 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 40/1000\n",
            "2/2 - 0s - loss: 0.6882 - accuracy: 0.5278 - val_loss: 0.7151 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 41/1000\n",
            "2/2 - 0s - loss: 0.6820 - accuracy: 0.5278 - val_loss: 0.7165 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 42/1000\n",
            "2/2 - 0s - loss: 0.6859 - accuracy: 0.5278 - val_loss: 0.7175 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 43/1000\n",
            "2/2 - 0s - loss: 0.6869 - accuracy: 0.5278 - val_loss: 0.7184 - val_accuracy: 0.4375 - 39ms/epoch - 20ms/step\n",
            "Epoch 44/1000\n",
            "2/2 - 0s - loss: 0.6764 - accuracy: 0.5278 - val_loss: 0.7189 - val_accuracy: 0.4375 - 28ms/epoch - 14ms/step\n",
            "Epoch 45/1000\n",
            "2/2 - 0s - loss: 0.6831 - accuracy: 0.5278 - val_loss: 0.7200 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 46/1000\n",
            "2/2 - 0s - loss: 0.6762 - accuracy: 0.5278 - val_loss: 0.7210 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 47/1000\n",
            "2/2 - 0s - loss: 0.6821 - accuracy: 0.5278 - val_loss: 0.7214 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 48/1000\n",
            "2/2 - 0s - loss: 0.6859 - accuracy: 0.5278 - val_loss: 0.7216 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 49/1000\n",
            "2/2 - 0s - loss: 0.6763 - accuracy: 0.5278 - val_loss: 0.7216 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 50/1000\n",
            "2/2 - 0s - loss: 0.6862 - accuracy: 0.5278 - val_loss: 0.7209 - val_accuracy: 0.4375 - 29ms/epoch - 15ms/step\n",
            "Epoch 51/1000\n",
            "2/2 - 0s - loss: 0.6742 - accuracy: 0.5278 - val_loss: 0.7207 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 52/1000\n",
            "2/2 - 0s - loss: 0.6781 - accuracy: 0.5278 - val_loss: 0.7207 - val_accuracy: 0.4375 - 53ms/epoch - 27ms/step\n",
            "Epoch 53/1000\n",
            "2/2 - 0s - loss: 0.6725 - accuracy: 0.5278 - val_loss: 0.7211 - val_accuracy: 0.4375 - 28ms/epoch - 14ms/step\n",
            "Epoch 54/1000\n",
            "2/2 - 0s - loss: 0.6782 - accuracy: 0.5278 - val_loss: 0.7220 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 55/1000\n",
            "2/2 - 0s - loss: 0.6725 - accuracy: 0.5278 - val_loss: 0.7223 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 56/1000\n",
            "2/2 - 0s - loss: 0.6796 - accuracy: 0.5278 - val_loss: 0.7228 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 57/1000\n",
            "2/2 - 0s - loss: 0.6710 - accuracy: 0.5278 - val_loss: 0.7237 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 58/1000\n",
            "2/2 - 0s - loss: 0.6730 - accuracy: 0.5278 - val_loss: 0.7248 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 59/1000\n",
            "2/2 - 0s - loss: 0.6773 - accuracy: 0.5278 - val_loss: 0.7256 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 60/1000\n",
            "2/2 - 0s - loss: 0.6769 - accuracy: 0.5278 - val_loss: 0.7264 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 61/1000\n",
            "2/2 - 0s - loss: 0.6757 - accuracy: 0.6032 - val_loss: 0.7267 - val_accuracy: 0.4531 - 29ms/epoch - 15ms/step\n",
            "Epoch 62/1000\n",
            "2/2 - 0s - loss: 0.6764 - accuracy: 0.5992 - val_loss: 0.7268 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 63/1000\n",
            "2/2 - 0s - loss: 0.6660 - accuracy: 0.6111 - val_loss: 0.7269 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 64/1000\n",
            "2/2 - 0s - loss: 0.6749 - accuracy: 0.5952 - val_loss: 0.7268 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 65/1000\n",
            "2/2 - 0s - loss: 0.6762 - accuracy: 0.5952 - val_loss: 0.7260 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 66/1000\n",
            "2/2 - 0s - loss: 0.6704 - accuracy: 0.6111 - val_loss: 0.7253 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 67/1000\n",
            "2/2 - 0s - loss: 0.6701 - accuracy: 0.6111 - val_loss: 0.7254 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 68/1000\n",
            "2/2 - 0s - loss: 0.6639 - accuracy: 0.6270 - val_loss: 0.7256 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 69/1000\n",
            "2/2 - 0s - loss: 0.6659 - accuracy: 0.6032 - val_loss: 0.7250 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 70/1000\n",
            "2/2 - 0s - loss: 0.6751 - accuracy: 0.6389 - val_loss: 0.7251 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 71/1000\n",
            "2/2 - 0s - loss: 0.6665 - accuracy: 0.6349 - val_loss: 0.7257 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 72/1000\n",
            "2/2 - 0s - loss: 0.6772 - accuracy: 0.6111 - val_loss: 0.7262 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 73/1000\n",
            "2/2 - 0s - loss: 0.6598 - accuracy: 0.6468 - val_loss: 0.7261 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 74/1000\n",
            "2/2 - 0s - loss: 0.6609 - accuracy: 0.6310 - val_loss: 0.7268 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 75/1000\n",
            "2/2 - 0s - loss: 0.6636 - accuracy: 0.5873 - val_loss: 0.7278 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 76/1000\n",
            "2/2 - 0s - loss: 0.6644 - accuracy: 0.6190 - val_loss: 0.7293 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 77/1000\n",
            "2/2 - 0s - loss: 0.6647 - accuracy: 0.5992 - val_loss: 0.7307 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 78/1000\n",
            "2/2 - 0s - loss: 0.6643 - accuracy: 0.6270 - val_loss: 0.7312 - val_accuracy: 0.4688 - 41ms/epoch - 21ms/step\n",
            "Epoch 79/1000\n",
            "2/2 - 0s - loss: 0.6636 - accuracy: 0.5873 - val_loss: 0.7318 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 80/1000\n",
            "2/2 - 0s - loss: 0.6737 - accuracy: 0.5992 - val_loss: 0.7308 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 81/1000\n",
            "2/2 - 0s - loss: 0.6650 - accuracy: 0.5913 - val_loss: 0.7300 - val_accuracy: 0.4844 - 56ms/epoch - 28ms/step\n",
            "Epoch 82/1000\n",
            "2/2 - 0s - loss: 0.6662 - accuracy: 0.6032 - val_loss: 0.7291 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 83/1000\n",
            "2/2 - 0s - loss: 0.6723 - accuracy: 0.6111 - val_loss: 0.7288 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 84/1000\n",
            "2/2 - 0s - loss: 0.6625 - accuracy: 0.6389 - val_loss: 0.7289 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 85/1000\n",
            "2/2 - 0s - loss: 0.6609 - accuracy: 0.6230 - val_loss: 0.7292 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 86/1000\n",
            "2/2 - 0s - loss: 0.6693 - accuracy: 0.6151 - val_loss: 0.7273 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 87/1000\n",
            "2/2 - 0s - loss: 0.6617 - accuracy: 0.6111 - val_loss: 0.7278 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 88/1000\n",
            "2/2 - 0s - loss: 0.6610 - accuracy: 0.6071 - val_loss: 0.7275 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 89/1000\n",
            "2/2 - 0s - loss: 0.6655 - accuracy: 0.6270 - val_loss: 0.7275 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 90/1000\n",
            "2/2 - 0s - loss: 0.6646 - accuracy: 0.6190 - val_loss: 0.7282 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 91/1000\n",
            "2/2 - 0s - loss: 0.6524 - accuracy: 0.6190 - val_loss: 0.7297 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 92/1000\n",
            "2/2 - 0s - loss: 0.6599 - accuracy: 0.6746 - val_loss: 0.7319 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 93/1000\n",
            "2/2 - 0s - loss: 0.6599 - accuracy: 0.6349 - val_loss: 0.7338 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 94/1000\n",
            "2/2 - 0s - loss: 0.6625 - accuracy: 0.6429 - val_loss: 0.7355 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 95/1000\n",
            "2/2 - 0s - loss: 0.6562 - accuracy: 0.6071 - val_loss: 0.7375 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 96/1000\n",
            "2/2 - 0s - loss: 0.6526 - accuracy: 0.6270 - val_loss: 0.7392 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 97/1000\n",
            "2/2 - 0s - loss: 0.6501 - accuracy: 0.6389 - val_loss: 0.7407 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 98/1000\n",
            "2/2 - 0s - loss: 0.6513 - accuracy: 0.6389 - val_loss: 0.7425 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 99/1000\n",
            "2/2 - 0s - loss: 0.6674 - accuracy: 0.6230 - val_loss: 0.7421 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 100/1000\n",
            "2/2 - 0s - loss: 0.6548 - accuracy: 0.6468 - val_loss: 0.7408 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 101/1000\n",
            "2/2 - 0s - loss: 0.6538 - accuracy: 0.6310 - val_loss: 0.7410 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 102/1000\n",
            "2/2 - 0s - loss: 0.6565 - accuracy: 0.6310 - val_loss: 0.7403 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 103/1000\n",
            "2/2 - 0s - loss: 0.6560 - accuracy: 0.6032 - val_loss: 0.7389 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 104/1000\n",
            "2/2 - 0s - loss: 0.6627 - accuracy: 0.6111 - val_loss: 0.7360 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 105/1000\n",
            "2/2 - 0s - loss: 0.6383 - accuracy: 0.6825 - val_loss: 0.7363 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 106/1000\n",
            "2/2 - 0s - loss: 0.6659 - accuracy: 0.6270 - val_loss: 0.7371 - val_accuracy: 0.4375 - 42ms/epoch - 21ms/step\n",
            "Epoch 107/1000\n",
            "2/2 - 0s - loss: 0.6564 - accuracy: 0.6746 - val_loss: 0.7389 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 108/1000\n",
            "2/2 - 0s - loss: 0.6557 - accuracy: 0.6032 - val_loss: 0.7406 - val_accuracy: 0.4531 - 29ms/epoch - 15ms/step\n",
            "Epoch 109/1000\n",
            "2/2 - 0s - loss: 0.6453 - accuracy: 0.6349 - val_loss: 0.7416 - val_accuracy: 0.4688 - 29ms/epoch - 14ms/step\n",
            "Epoch 110/1000\n",
            "2/2 - 0s - loss: 0.6449 - accuracy: 0.6508 - val_loss: 0.7442 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 111/1000\n",
            "2/2 - 0s - loss: 0.6413 - accuracy: 0.6310 - val_loss: 0.7466 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 112/1000\n",
            "2/2 - 0s - loss: 0.6522 - accuracy: 0.6548 - val_loss: 0.7465 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 113/1000\n",
            "2/2 - 0s - loss: 0.6540 - accuracy: 0.5952 - val_loss: 0.7459 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 114/1000\n",
            "2/2 - 0s - loss: 0.6596 - accuracy: 0.6706 - val_loss: 0.7429 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 115/1000\n",
            "2/2 - 0s - loss: 0.6560 - accuracy: 0.6270 - val_loss: 0.7382 - val_accuracy: 0.4219 - 35ms/epoch - 18ms/step\n",
            "Epoch 116/1000\n",
            "2/2 - 0s - loss: 0.6563 - accuracy: 0.6310 - val_loss: 0.7346 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 117/1000\n",
            "2/2 - 0s - loss: 0.6405 - accuracy: 0.6746 - val_loss: 0.7344 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 118/1000\n",
            "2/2 - 0s - loss: 0.6400 - accuracy: 0.6587 - val_loss: 0.7364 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 119/1000\n",
            "2/2 - 0s - loss: 0.6468 - accuracy: 0.6429 - val_loss: 0.7389 - val_accuracy: 0.4219 - 35ms/epoch - 18ms/step\n",
            "Epoch 120/1000\n",
            "2/2 - 0s - loss: 0.6640 - accuracy: 0.5992 - val_loss: 0.7419 - val_accuracy: 0.4219 - 49ms/epoch - 25ms/step\n",
            "Epoch 121/1000\n",
            "2/2 - 0s - loss: 0.6235 - accuracy: 0.6468 - val_loss: 0.7453 - val_accuracy: 0.4219 - 38ms/epoch - 19ms/step\n",
            "Epoch 122/1000\n",
            "2/2 - 0s - loss: 0.6579 - accuracy: 0.6667 - val_loss: 0.7518 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 123/1000\n",
            "2/2 - 0s - loss: 0.6410 - accuracy: 0.6429 - val_loss: 0.7582 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 124/1000\n",
            "2/2 - 0s - loss: 0.6380 - accuracy: 0.6548 - val_loss: 0.7633 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 125/1000\n",
            "2/2 - 0s - loss: 0.6367 - accuracy: 0.6508 - val_loss: 0.7652 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 126/1000\n",
            "2/2 - 0s - loss: 0.6463 - accuracy: 0.6667 - val_loss: 0.7631 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 127/1000\n",
            "2/2 - 0s - loss: 0.6488 - accuracy: 0.6548 - val_loss: 0.7625 - val_accuracy: 0.4219 - 30ms/epoch - 15ms/step\n",
            "Epoch 128/1000\n",
            "2/2 - 0s - loss: 0.6344 - accuracy: 0.6627 - val_loss: 0.7636 - val_accuracy: 0.4219 - 32ms/epoch - 16ms/step\n",
            "Epoch 129/1000\n",
            "2/2 - 0s - loss: 0.6316 - accuracy: 0.6508 - val_loss: 0.7635 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 130/1000\n",
            "2/2 - 0s - loss: 0.6552 - accuracy: 0.6270 - val_loss: 0.7609 - val_accuracy: 0.4219 - 36ms/epoch - 18ms/step\n",
            "Epoch 131/1000\n",
            "2/2 - 0s - loss: 0.6316 - accuracy: 0.6468 - val_loss: 0.7580 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 132/1000\n",
            "2/2 - 0s - loss: 0.6144 - accuracy: 0.6548 - val_loss: 0.7574 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 133/1000\n",
            "2/2 - 0s - loss: 0.6405 - accuracy: 0.6667 - val_loss: 0.7581 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 134/1000\n",
            "2/2 - 0s - loss: 0.6456 - accuracy: 0.6706 - val_loss: 0.7587 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 135/1000\n",
            "2/2 - 0s - loss: 0.6379 - accuracy: 0.6349 - val_loss: 0.7565 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 136/1000\n",
            "2/2 - 0s - loss: 0.6428 - accuracy: 0.6389 - val_loss: 0.7548 - val_accuracy: 0.4531 - 28ms/epoch - 14ms/step\n",
            "Epoch 137/1000\n",
            "2/2 - 0s - loss: 0.6530 - accuracy: 0.6667 - val_loss: 0.7537 - val_accuracy: 0.4531 - 29ms/epoch - 14ms/step\n",
            "Epoch 138/1000\n",
            "2/2 - 0s - loss: 0.6368 - accuracy: 0.6667 - val_loss: 0.7508 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 139/1000\n",
            "2/2 - 0s - loss: 0.6312 - accuracy: 0.6627 - val_loss: 0.7490 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 140/1000\n",
            "2/2 - 0s - loss: 0.6529 - accuracy: 0.6389 - val_loss: 0.7493 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 141/1000\n",
            "2/2 - 0s - loss: 0.6355 - accuracy: 0.6548 - val_loss: 0.7504 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 142/1000\n",
            "2/2 - 0s - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.7525 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 143/1000\n",
            "2/2 - 0s - loss: 0.6401 - accuracy: 0.6429 - val_loss: 0.7560 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 144/1000\n",
            "2/2 - 0s - loss: 0.6290 - accuracy: 0.6548 - val_loss: 0.7583 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 145/1000\n",
            "2/2 - 0s - loss: 0.6308 - accuracy: 0.6548 - val_loss: 0.7611 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 146/1000\n",
            "2/2 - 0s - loss: 0.6374 - accuracy: 0.6310 - val_loss: 0.7648 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 147/1000\n",
            "2/2 - 0s - loss: 0.6338 - accuracy: 0.6548 - val_loss: 0.7685 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 148/1000\n",
            "2/2 - 0s - loss: 0.6527 - accuracy: 0.6349 - val_loss: 0.7718 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 149/1000\n",
            "2/2 - 0s - loss: 0.6328 - accuracy: 0.6627 - val_loss: 0.7747 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 150/1000\n",
            "2/2 - 0s - loss: 0.6232 - accuracy: 0.6786 - val_loss: 0.7768 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 151/1000\n",
            "2/2 - 0s - loss: 0.6487 - accuracy: 0.6468 - val_loss: 0.7782 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 152/1000\n",
            "2/2 - 0s - loss: 0.6334 - accuracy: 0.6865 - val_loss: 0.7769 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 153/1000\n",
            "2/2 - 0s - loss: 0.6453 - accuracy: 0.6627 - val_loss: 0.7709 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 154/1000\n",
            "2/2 - 0s - loss: 0.6163 - accuracy: 0.6825 - val_loss: 0.7660 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 155/1000\n",
            "2/2 - 0s - loss: 0.6245 - accuracy: 0.6706 - val_loss: 0.7627 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 156/1000\n",
            "2/2 - 0s - loss: 0.6288 - accuracy: 0.6548 - val_loss: 0.7592 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 157/1000\n",
            "2/2 - 0s - loss: 0.6237 - accuracy: 0.6508 - val_loss: 0.7594 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 158/1000\n",
            "2/2 - 0s - loss: 0.6428 - accuracy: 0.6230 - val_loss: 0.7605 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 159/1000\n",
            "2/2 - 0s - loss: 0.6450 - accuracy: 0.6429 - val_loss: 0.7601 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 160/1000\n",
            "2/2 - 0s - loss: 0.6184 - accuracy: 0.6786 - val_loss: 0.7633 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 161/1000\n",
            "2/2 - 0s - loss: 0.6416 - accuracy: 0.6032 - val_loss: 0.7639 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 162/1000\n",
            "2/2 - 0s - loss: 0.6199 - accuracy: 0.6548 - val_loss: 0.7676 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 163/1000\n",
            "2/2 - 0s - loss: 0.6258 - accuracy: 0.6706 - val_loss: 0.7710 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 164/1000\n",
            "2/2 - 0s - loss: 0.6349 - accuracy: 0.6627 - val_loss: 0.7742 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 165/1000\n",
            "2/2 - 0s - loss: 0.6284 - accuracy: 0.6667 - val_loss: 0.7740 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 166/1000\n",
            "2/2 - 0s - loss: 0.6199 - accuracy: 0.6865 - val_loss: 0.7734 - val_accuracy: 0.5156 - 30ms/epoch - 15ms/step\n",
            "Epoch 167/1000\n",
            "2/2 - 0s - loss: 0.6465 - accuracy: 0.6429 - val_loss: 0.7690 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 168/1000\n",
            "2/2 - 0s - loss: 0.6203 - accuracy: 0.6706 - val_loss: 0.7652 - val_accuracy: 0.5000 - 29ms/epoch - 15ms/step\n",
            "Epoch 169/1000\n",
            "2/2 - 0s - loss: 0.6296 - accuracy: 0.6310 - val_loss: 0.7621 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 170/1000\n",
            "2/2 - 0s - loss: 0.6483 - accuracy: 0.6230 - val_loss: 0.7597 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 171/1000\n",
            "2/2 - 0s - loss: 0.6236 - accuracy: 0.6944 - val_loss: 0.7618 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 172/1000\n",
            "2/2 - 0s - loss: 0.6400 - accuracy: 0.6508 - val_loss: 0.7622 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 173/1000\n",
            "2/2 - 0s - loss: 0.6379 - accuracy: 0.6627 - val_loss: 0.7630 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 174/1000\n",
            "2/2 - 0s - loss: 0.6221 - accuracy: 0.6627 - val_loss: 0.7650 - val_accuracy: 0.5000 - 29ms/epoch - 14ms/step\n",
            "Epoch 175/1000\n",
            "2/2 - 0s - loss: 0.6256 - accuracy: 0.6706 - val_loss: 0.7677 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 176/1000\n",
            "2/2 - 0s - loss: 0.6390 - accuracy: 0.6825 - val_loss: 0.7698 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 177/1000\n",
            "2/2 - 0s - loss: 0.6449 - accuracy: 0.6468 - val_loss: 0.7698 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 178/1000\n",
            "2/2 - 0s - loss: 0.6484 - accuracy: 0.6349 - val_loss: 0.7681 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 179/1000\n",
            "2/2 - 0s - loss: 0.6432 - accuracy: 0.6468 - val_loss: 0.7640 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 180/1000\n",
            "2/2 - 0s - loss: 0.6477 - accuracy: 0.6746 - val_loss: 0.7593 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 181/1000\n",
            "2/2 - 0s - loss: 0.6473 - accuracy: 0.6468 - val_loss: 0.7558 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 182/1000\n",
            "2/2 - 0s - loss: 0.6575 - accuracy: 0.6429 - val_loss: 0.7545 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 183/1000\n",
            "2/2 - 0s - loss: 0.6236 - accuracy: 0.6627 - val_loss: 0.7546 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 184/1000\n",
            "2/2 - 0s - loss: 0.6302 - accuracy: 0.6746 - val_loss: 0.7556 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 185/1000\n",
            "2/2 - 0s - loss: 0.6343 - accuracy: 0.6508 - val_loss: 0.7563 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 186/1000\n",
            "2/2 - 0s - loss: 0.6389 - accuracy: 0.6270 - val_loss: 0.7573 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 187/1000\n",
            "2/2 - 0s - loss: 0.6321 - accuracy: 0.6627 - val_loss: 0.7568 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 188/1000\n",
            "2/2 - 0s - loss: 0.6353 - accuracy: 0.6349 - val_loss: 0.7571 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 189/1000\n",
            "2/2 - 0s - loss: 0.6542 - accuracy: 0.6587 - val_loss: 0.7577 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 190/1000\n",
            "2/2 - 0s - loss: 0.6420 - accuracy: 0.6746 - val_loss: 0.7558 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 191/1000\n",
            "2/2 - 0s - loss: 0.6228 - accuracy: 0.6508 - val_loss: 0.7563 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 192/1000\n",
            "2/2 - 0s - loss: 0.6280 - accuracy: 0.6548 - val_loss: 0.7560 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 193/1000\n",
            "2/2 - 0s - loss: 0.6315 - accuracy: 0.6190 - val_loss: 0.7566 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 194/1000\n",
            "2/2 - 0s - loss: 0.6237 - accuracy: 0.6825 - val_loss: 0.7579 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 195/1000\n",
            "2/2 - 0s - loss: 0.6417 - accuracy: 0.6310 - val_loss: 0.7615 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 196/1000\n",
            "2/2 - 0s - loss: 0.6413 - accuracy: 0.6508 - val_loss: 0.7620 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 197/1000\n",
            "2/2 - 0s - loss: 0.6380 - accuracy: 0.6429 - val_loss: 0.7640 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 198/1000\n",
            "2/2 - 0s - loss: 0.6221 - accuracy: 0.6825 - val_loss: 0.7671 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 199/1000\n",
            "2/2 - 0s - loss: 0.6392 - accuracy: 0.6587 - val_loss: 0.7682 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 200/1000\n",
            "2/2 - 0s - loss: 0.6312 - accuracy: 0.6429 - val_loss: 0.7668 - val_accuracy: 0.4688 - 41ms/epoch - 21ms/step\n",
            "Epoch 201/1000\n",
            "2/2 - 0s - loss: 0.6235 - accuracy: 0.6667 - val_loss: 0.7673 - val_accuracy: 0.4531 - 29ms/epoch - 14ms/step\n",
            "Epoch 202/1000\n",
            "2/2 - 0s - loss: 0.6436 - accuracy: 0.6548 - val_loss: 0.7667 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 203/1000\n",
            "2/2 - 0s - loss: 0.6273 - accuracy: 0.6508 - val_loss: 0.7665 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 204/1000\n",
            "2/2 - 0s - loss: 0.6244 - accuracy: 0.6746 - val_loss: 0.7663 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 205/1000\n",
            "2/2 - 0s - loss: 0.6351 - accuracy: 0.6429 - val_loss: 0.7659 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 206/1000\n",
            "2/2 - 0s - loss: 0.6460 - accuracy: 0.6587 - val_loss: 0.7624 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 207/1000\n",
            "2/2 - 0s - loss: 0.6252 - accuracy: 0.6587 - val_loss: 0.7597 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 208/1000\n",
            "2/2 - 0s - loss: 0.6250 - accuracy: 0.6587 - val_loss: 0.7601 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 209/1000\n",
            "2/2 - 0s - loss: 0.6334 - accuracy: 0.6746 - val_loss: 0.7632 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 210/1000\n",
            "2/2 - 0s - loss: 0.6547 - accuracy: 0.6508 - val_loss: 0.7642 - val_accuracy: 0.4688 - 29ms/epoch - 14ms/step\n",
            "Epoch 211/1000\n",
            "2/2 - 0s - loss: 0.6228 - accuracy: 0.6508 - val_loss: 0.7654 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 212/1000\n",
            "2/2 - 0s - loss: 0.6249 - accuracy: 0.6786 - val_loss: 0.7684 - val_accuracy: 0.4844 - 28ms/epoch - 14ms/step\n",
            "Epoch 213/1000\n",
            "2/2 - 0s - loss: 0.6370 - accuracy: 0.6389 - val_loss: 0.7704 - val_accuracy: 0.4688 - 29ms/epoch - 14ms/step\n",
            "Epoch 214/1000\n",
            "2/2 - 0s - loss: 0.6153 - accuracy: 0.6746 - val_loss: 0.7720 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 215/1000\n",
            "2/2 - 0s - loss: 0.6340 - accuracy: 0.6746 - val_loss: 0.7710 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 216/1000\n",
            "2/2 - 0s - loss: 0.6456 - accuracy: 0.6429 - val_loss: 0.7699 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 217/1000\n",
            "2/2 - 0s - loss: 0.6416 - accuracy: 0.6468 - val_loss: 0.7679 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 218/1000\n",
            "2/2 - 0s - loss: 0.6183 - accuracy: 0.6865 - val_loss: 0.7658 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 219/1000\n",
            "2/2 - 0s - loss: 0.6228 - accuracy: 0.7024 - val_loss: 0.7671 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 220/1000\n",
            "2/2 - 0s - loss: 0.6250 - accuracy: 0.7024 - val_loss: 0.7713 - val_accuracy: 0.4219 - 33ms/epoch - 17ms/step\n",
            "Epoch 221/1000\n",
            "2/2 - 0s - loss: 0.6266 - accuracy: 0.6667 - val_loss: 0.7772 - val_accuracy: 0.4219 - 29ms/epoch - 15ms/step\n",
            "Epoch 222/1000\n",
            "2/2 - 0s - loss: 0.6279 - accuracy: 0.6508 - val_loss: 0.7824 - val_accuracy: 0.4219 - 51ms/epoch - 26ms/step\n",
            "Epoch 223/1000\n",
            "2/2 - 0s - loss: 0.6348 - accuracy: 0.6468 - val_loss: 0.7870 - val_accuracy: 0.4062 - 34ms/epoch - 17ms/step\n",
            "Epoch 224/1000\n",
            "2/2 - 0s - loss: 0.6236 - accuracy: 0.6984 - val_loss: 0.7906 - val_accuracy: 0.4219 - 30ms/epoch - 15ms/step\n",
            "Epoch 225/1000\n",
            "2/2 - 0s - loss: 0.6406 - accuracy: 0.6548 - val_loss: 0.7891 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 226/1000\n",
            "2/2 - 0s - loss: 0.6149 - accuracy: 0.6706 - val_loss: 0.7903 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 227/1000\n",
            "2/2 - 0s - loss: 0.6285 - accuracy: 0.6587 - val_loss: 0.7892 - val_accuracy: 0.4531 - 45ms/epoch - 23ms/step\n",
            "Epoch 228/1000\n",
            "2/2 - 0s - loss: 0.6042 - accuracy: 0.6825 - val_loss: 0.7889 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 229/1000\n",
            "2/2 - 0s - loss: 0.6310 - accuracy: 0.6825 - val_loss: 0.7885 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 230/1000\n",
            "2/2 - 0s - loss: 0.6120 - accuracy: 0.6587 - val_loss: 0.7895 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 231/1000\n",
            "2/2 - 0s - loss: 0.6379 - accuracy: 0.6865 - val_loss: 0.7909 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 232/1000\n",
            "2/2 - 0s - loss: 0.6206 - accuracy: 0.6944 - val_loss: 0.7870 - val_accuracy: 0.4531 - 28ms/epoch - 14ms/step\n",
            "Epoch 233/1000\n",
            "2/2 - 0s - loss: 0.6195 - accuracy: 0.6667 - val_loss: 0.7825 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 234/1000\n",
            "2/2 - 0s - loss: 0.6229 - accuracy: 0.6587 - val_loss: 0.7767 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 235/1000\n",
            "2/2 - 0s - loss: 0.6270 - accuracy: 0.6587 - val_loss: 0.7724 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 236/1000\n",
            "2/2 - 0s - loss: 0.6152 - accuracy: 0.6825 - val_loss: 0.7715 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 237/1000\n",
            "2/2 - 0s - loss: 0.6319 - accuracy: 0.6468 - val_loss: 0.7692 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 238/1000\n",
            "2/2 - 0s - loss: 0.6332 - accuracy: 0.6310 - val_loss: 0.7692 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 239/1000\n",
            "2/2 - 0s - loss: 0.6271 - accuracy: 0.6667 - val_loss: 0.7703 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 240/1000\n",
            "2/2 - 0s - loss: 0.6382 - accuracy: 0.6548 - val_loss: 0.7690 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 241/1000\n",
            "2/2 - 0s - loss: 0.6415 - accuracy: 0.6786 - val_loss: 0.7677 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 242/1000\n",
            "2/2 - 0s - loss: 0.6356 - accuracy: 0.6230 - val_loss: 0.7675 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 243/1000\n",
            "2/2 - 0s - loss: 0.6165 - accuracy: 0.6706 - val_loss: 0.7682 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 244/1000\n",
            "2/2 - 0s - loss: 0.6254 - accuracy: 0.6548 - val_loss: 0.7674 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 245/1000\n",
            "2/2 - 0s - loss: 0.6209 - accuracy: 0.6548 - val_loss: 0.7679 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 246/1000\n",
            "2/2 - 0s - loss: 0.6325 - accuracy: 0.6548 - val_loss: 0.7683 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 247/1000\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6627 - val_loss: 0.7679 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 248/1000\n",
            "2/2 - 0s - loss: 0.6332 - accuracy: 0.6587 - val_loss: 0.7693 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 249/1000\n",
            "2/2 - 0s - loss: 0.6168 - accuracy: 0.7063 - val_loss: 0.7696 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 250/1000\n",
            "2/2 - 0s - loss: 0.6239 - accuracy: 0.6349 - val_loss: 0.7714 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 251/1000\n",
            "2/2 - 0s - loss: 0.6664 - accuracy: 0.6587 - val_loss: 0.7701 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 252/1000\n",
            "2/2 - 0s - loss: 0.6207 - accuracy: 0.6627 - val_loss: 0.7675 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 253/1000\n",
            "2/2 - 0s - loss: 0.6215 - accuracy: 0.6587 - val_loss: 0.7646 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 254/1000\n",
            "2/2 - 0s - loss: 0.6359 - accuracy: 0.6389 - val_loss: 0.7648 - val_accuracy: 0.4688 - 41ms/epoch - 21ms/step\n",
            "Epoch 255/1000\n",
            "2/2 - 0s - loss: 0.6392 - accuracy: 0.6905 - val_loss: 0.7658 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 256/1000\n",
            "2/2 - 0s - loss: 0.6205 - accuracy: 0.6508 - val_loss: 0.7700 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 257/1000\n",
            "2/2 - 0s - loss: 0.6215 - accuracy: 0.6429 - val_loss: 0.7734 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 258/1000\n",
            "2/2 - 0s - loss: 0.6431 - accuracy: 0.6468 - val_loss: 0.7746 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 259/1000\n",
            "2/2 - 0s - loss: 0.6569 - accuracy: 0.6587 - val_loss: 0.7744 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 260/1000\n",
            "2/2 - 0s - loss: 0.6024 - accuracy: 0.6944 - val_loss: 0.7759 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 261/1000\n",
            "2/2 - 0s - loss: 0.6256 - accuracy: 0.6389 - val_loss: 0.7789 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 262/1000\n",
            "2/2 - 0s - loss: 0.6259 - accuracy: 0.6746 - val_loss: 0.7836 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 263/1000\n",
            "2/2 - 0s - loss: 0.6384 - accuracy: 0.6627 - val_loss: 0.7870 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 264/1000\n",
            "2/2 - 0s - loss: 0.6248 - accuracy: 0.6310 - val_loss: 0.7889 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 265/1000\n",
            "2/2 - 0s - loss: 0.6114 - accuracy: 0.6627 - val_loss: 0.7921 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 266/1000\n",
            "2/2 - 0s - loss: 0.6313 - accuracy: 0.6548 - val_loss: 0.7944 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 267/1000\n",
            "2/2 - 0s - loss: 0.6082 - accuracy: 0.6825 - val_loss: 0.7943 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 268/1000\n",
            "2/2 - 0s - loss: 0.6145 - accuracy: 0.6627 - val_loss: 0.7936 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 269/1000\n",
            "2/2 - 0s - loss: 0.6149 - accuracy: 0.6786 - val_loss: 0.7901 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 270/1000\n",
            "2/2 - 0s - loss: 0.6235 - accuracy: 0.6468 - val_loss: 0.7854 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 271/1000\n",
            "2/2 - 0s - loss: 0.6109 - accuracy: 0.6667 - val_loss: 0.7837 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 272/1000\n",
            "2/2 - 0s - loss: 0.6321 - accuracy: 0.6865 - val_loss: 0.7841 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 273/1000\n",
            "2/2 - 0s - loss: 0.6461 - accuracy: 0.6587 - val_loss: 0.7810 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 274/1000\n",
            "2/2 - 0s - loss: 0.5844 - accuracy: 0.6865 - val_loss: 0.7817 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 275/1000\n",
            "2/2 - 0s - loss: 0.6307 - accuracy: 0.6310 - val_loss: 0.7825 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 276/1000\n",
            "2/2 - 0s - loss: 0.6376 - accuracy: 0.6667 - val_loss: 0.7820 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 277/1000\n",
            "2/2 - 0s - loss: 0.6211 - accuracy: 0.6667 - val_loss: 0.7834 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 278/1000\n",
            "2/2 - 0s - loss: 0.6397 - accuracy: 0.6706 - val_loss: 0.7802 - val_accuracy: 0.4844 - 52ms/epoch - 26ms/step\n",
            "Epoch 279/1000\n",
            "2/2 - 0s - loss: 0.6091 - accuracy: 0.6746 - val_loss: 0.7778 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 280/1000\n",
            "2/2 - 0s - loss: 0.6348 - accuracy: 0.6627 - val_loss: 0.7774 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 281/1000\n",
            "2/2 - 0s - loss: 0.6118 - accuracy: 0.6865 - val_loss: 0.7780 - val_accuracy: 0.4844 - 29ms/epoch - 14ms/step\n",
            "Epoch 282/1000\n",
            "2/2 - 0s - loss: 0.6182 - accuracy: 0.6667 - val_loss: 0.7775 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 283/1000\n",
            "2/2 - 0s - loss: 0.6125 - accuracy: 0.7143 - val_loss: 0.7802 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 284/1000\n",
            "2/2 - 0s - loss: 0.6403 - accuracy: 0.6548 - val_loss: 0.7801 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 285/1000\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6627 - val_loss: 0.7794 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 286/1000\n",
            "2/2 - 0s - loss: 0.6113 - accuracy: 0.6627 - val_loss: 0.7781 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 287/1000\n",
            "2/2 - 0s - loss: 0.6488 - accuracy: 0.6310 - val_loss: 0.7760 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 288/1000\n",
            "2/2 - 0s - loss: 0.6128 - accuracy: 0.6865 - val_loss: 0.7777 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 289/1000\n",
            "2/2 - 0s - loss: 0.5998 - accuracy: 0.6429 - val_loss: 0.7814 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 290/1000\n",
            "2/2 - 0s - loss: 0.6208 - accuracy: 0.6468 - val_loss: 0.7855 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 291/1000\n",
            "2/2 - 0s - loss: 0.6195 - accuracy: 0.6865 - val_loss: 0.7901 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 292/1000\n",
            "2/2 - 0s - loss: 0.6277 - accuracy: 0.6746 - val_loss: 0.7933 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 293/1000\n",
            "2/2 - 0s - loss: 0.6207 - accuracy: 0.6468 - val_loss: 0.7916 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 294/1000\n",
            "2/2 - 0s - loss: 0.6025 - accuracy: 0.6984 - val_loss: 0.7926 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 295/1000\n",
            "2/2 - 0s - loss: 0.6054 - accuracy: 0.6984 - val_loss: 0.7935 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 296/1000\n",
            "2/2 - 0s - loss: 0.6439 - accuracy: 0.6706 - val_loss: 0.7949 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 297/1000\n",
            "2/2 - 0s - loss: 0.6368 - accuracy: 0.6786 - val_loss: 0.7871 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 298/1000\n",
            "2/2 - 0s - loss: 0.6038 - accuracy: 0.6944 - val_loss: 0.7811 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 299/1000\n",
            "2/2 - 0s - loss: 0.6101 - accuracy: 0.6548 - val_loss: 0.7776 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 300/1000\n",
            "2/2 - 0s - loss: 0.6105 - accuracy: 0.6468 - val_loss: 0.7751 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 301/1000\n",
            "2/2 - 0s - loss: 0.6134 - accuracy: 0.6587 - val_loss: 0.7767 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 302/1000\n",
            "2/2 - 0s - loss: 0.6157 - accuracy: 0.6667 - val_loss: 0.7797 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 303/1000\n",
            "2/2 - 0s - loss: 0.6383 - accuracy: 0.6429 - val_loss: 0.7815 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 304/1000\n",
            "2/2 - 0s - loss: 0.5940 - accuracy: 0.6865 - val_loss: 0.7851 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 305/1000\n",
            "2/2 - 0s - loss: 0.6168 - accuracy: 0.6627 - val_loss: 0.7901 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 306/1000\n",
            "2/2 - 0s - loss: 0.6029 - accuracy: 0.6825 - val_loss: 0.7943 - val_accuracy: 0.5000 - 30ms/epoch - 15ms/step\n",
            "Epoch 307/1000\n",
            "2/2 - 0s - loss: 0.6147 - accuracy: 0.6508 - val_loss: 0.7995 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 308/1000\n",
            "2/2 - 0s - loss: 0.5980 - accuracy: 0.6905 - val_loss: 0.8081 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 309/1000\n",
            "2/2 - 0s - loss: 0.6129 - accuracy: 0.6627 - val_loss: 0.8115 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 310/1000\n",
            "2/2 - 0s - loss: 0.6211 - accuracy: 0.7024 - val_loss: 0.8116 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 311/1000\n",
            "2/2 - 0s - loss: 0.6332 - accuracy: 0.6468 - val_loss: 0.8106 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 312/1000\n",
            "2/2 - 0s - loss: 0.6160 - accuracy: 0.6905 - val_loss: 0.8036 - val_accuracy: 0.4688 - 44ms/epoch - 22ms/step\n",
            "Epoch 313/1000\n",
            "2/2 - 0s - loss: 0.6304 - accuracy: 0.6667 - val_loss: 0.7977 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 314/1000\n",
            "2/2 - 0s - loss: 0.6297 - accuracy: 0.6587 - val_loss: 0.7912 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 315/1000\n",
            "2/2 - 0s - loss: 0.6158 - accuracy: 0.6786 - val_loss: 0.7885 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 316/1000\n",
            "2/2 - 0s - loss: 0.6164 - accuracy: 0.7024 - val_loss: 0.7891 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 317/1000\n",
            "2/2 - 0s - loss: 0.5938 - accuracy: 0.6984 - val_loss: 0.7889 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 318/1000\n",
            "2/2 - 0s - loss: 0.6193 - accuracy: 0.6786 - val_loss: 0.7899 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 319/1000\n",
            "2/2 - 0s - loss: 0.6011 - accuracy: 0.6786 - val_loss: 0.7937 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 320/1000\n",
            "2/2 - 0s - loss: 0.6288 - accuracy: 0.6905 - val_loss: 0.7958 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 321/1000\n",
            "2/2 - 0s - loss: 0.6151 - accuracy: 0.6825 - val_loss: 0.7997 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 322/1000\n",
            "2/2 - 0s - loss: 0.6234 - accuracy: 0.7103 - val_loss: 0.7988 - val_accuracy: 0.4688 - 28ms/epoch - 14ms/step\n",
            "Epoch 323/1000\n",
            "2/2 - 0s - loss: 0.6004 - accuracy: 0.7024 - val_loss: 0.7995 - val_accuracy: 0.4531 - 29ms/epoch - 15ms/step\n",
            "Epoch 324/1000\n",
            "2/2 - 0s - loss: 0.6211 - accuracy: 0.6786 - val_loss: 0.7961 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 325/1000\n",
            "2/2 - 0s - loss: 0.6223 - accuracy: 0.6548 - val_loss: 0.7965 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 326/1000\n",
            "2/2 - 0s - loss: 0.6108 - accuracy: 0.6825 - val_loss: 0.7958 - val_accuracy: 0.4531 - 29ms/epoch - 15ms/step\n",
            "Epoch 327/1000\n",
            "2/2 - 0s - loss: 0.6160 - accuracy: 0.6984 - val_loss: 0.7942 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 328/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6984 - val_loss: 0.7936 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 329/1000\n",
            "2/2 - 0s - loss: 0.6221 - accuracy: 0.6746 - val_loss: 0.7944 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 330/1000\n",
            "2/2 - 0s - loss: 0.6218 - accuracy: 0.6627 - val_loss: 0.7969 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 331/1000\n",
            "2/2 - 0s - loss: 0.6427 - accuracy: 0.6627 - val_loss: 0.7945 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 332/1000\n",
            "2/2 - 0s - loss: 0.6075 - accuracy: 0.6865 - val_loss: 0.7947 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 333/1000\n",
            "2/2 - 0s - loss: 0.6120 - accuracy: 0.6587 - val_loss: 0.7948 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 334/1000\n",
            "2/2 - 0s - loss: 0.5883 - accuracy: 0.7103 - val_loss: 0.8019 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 335/1000\n",
            "2/2 - 0s - loss: 0.6161 - accuracy: 0.6508 - val_loss: 0.8062 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 336/1000\n",
            "2/2 - 0s - loss: 0.6083 - accuracy: 0.6905 - val_loss: 0.8097 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 337/1000\n",
            "2/2 - 0s - loss: 0.6131 - accuracy: 0.6984 - val_loss: 0.8122 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 338/1000\n",
            "2/2 - 0s - loss: 0.6286 - accuracy: 0.6548 - val_loss: 0.8107 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 339/1000\n",
            "2/2 - 0s - loss: 0.6292 - accuracy: 0.6825 - val_loss: 0.8066 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 340/1000\n",
            "2/2 - 0s - loss: 0.6135 - accuracy: 0.6786 - val_loss: 0.7999 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 341/1000\n",
            "2/2 - 0s - loss: 0.5940 - accuracy: 0.6984 - val_loss: 0.7990 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 342/1000\n",
            "2/2 - 0s - loss: 0.6233 - accuracy: 0.6349 - val_loss: 0.7995 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 343/1000\n",
            "2/2 - 0s - loss: 0.6141 - accuracy: 0.6548 - val_loss: 0.7983 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 344/1000\n",
            "2/2 - 0s - loss: 0.6158 - accuracy: 0.6706 - val_loss: 0.7971 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 345/1000\n",
            "2/2 - 0s - loss: 0.5981 - accuracy: 0.6587 - val_loss: 0.7982 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 346/1000\n",
            "2/2 - 0s - loss: 0.5967 - accuracy: 0.6786 - val_loss: 0.8006 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 347/1000\n",
            "2/2 - 0s - loss: 0.5862 - accuracy: 0.7222 - val_loss: 0.8026 - val_accuracy: 0.4375 - 39ms/epoch - 19ms/step\n",
            "Epoch 348/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6865 - val_loss: 0.8062 - val_accuracy: 0.4375 - 29ms/epoch - 15ms/step\n",
            "Epoch 349/1000\n",
            "2/2 - 0s - loss: 0.6351 - accuracy: 0.6468 - val_loss: 0.8072 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 350/1000\n",
            "2/2 - 0s - loss: 0.6077 - accuracy: 0.6746 - val_loss: 0.8088 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 351/1000\n",
            "2/2 - 0s - loss: 0.6071 - accuracy: 0.6825 - val_loss: 0.8123 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 352/1000\n",
            "2/2 - 0s - loss: 0.5930 - accuracy: 0.6944 - val_loss: 0.8172 - val_accuracy: 0.4219 - 30ms/epoch - 15ms/step\n",
            "Epoch 353/1000\n",
            "2/2 - 0s - loss: 0.5840 - accuracy: 0.6944 - val_loss: 0.8210 - val_accuracy: 0.4062 - 38ms/epoch - 19ms/step\n",
            "Epoch 354/1000\n",
            "2/2 - 0s - loss: 0.6117 - accuracy: 0.6984 - val_loss: 0.8257 - val_accuracy: 0.4062 - 34ms/epoch - 17ms/step\n",
            "Epoch 355/1000\n",
            "2/2 - 0s - loss: 0.6032 - accuracy: 0.7024 - val_loss: 0.8284 - val_accuracy: 0.4219 - 37ms/epoch - 18ms/step\n",
            "Epoch 356/1000\n",
            "2/2 - 0s - loss: 0.6103 - accuracy: 0.6429 - val_loss: 0.8262 - val_accuracy: 0.4219 - 32ms/epoch - 16ms/step\n",
            "Epoch 357/1000\n",
            "2/2 - 0s - loss: 0.6217 - accuracy: 0.6786 - val_loss: 0.8234 - val_accuracy: 0.4219 - 30ms/epoch - 15ms/step\n",
            "Epoch 358/1000\n",
            "2/2 - 0s - loss: 0.6213 - accuracy: 0.6984 - val_loss: 0.8184 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 359/1000\n",
            "2/2 - 0s - loss: 0.5857 - accuracy: 0.6746 - val_loss: 0.8134 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 360/1000\n",
            "2/2 - 0s - loss: 0.6151 - accuracy: 0.6905 - val_loss: 0.8104 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 361/1000\n",
            "2/2 - 0s - loss: 0.6038 - accuracy: 0.6746 - val_loss: 0.8073 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 362/1000\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6786 - val_loss: 0.8047 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 363/1000\n",
            "2/2 - 0s - loss: 0.6066 - accuracy: 0.6944 - val_loss: 0.8022 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 364/1000\n",
            "2/2 - 0s - loss: 0.6174 - accuracy: 0.6508 - val_loss: 0.8032 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 365/1000\n",
            "2/2 - 0s - loss: 0.6199 - accuracy: 0.6667 - val_loss: 0.8029 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 366/1000\n",
            "2/2 - 0s - loss: 0.6065 - accuracy: 0.6746 - val_loss: 0.8033 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 367/1000\n",
            "2/2 - 0s - loss: 0.6285 - accuracy: 0.7024 - val_loss: 0.8029 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 368/1000\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6667 - val_loss: 0.7975 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 369/1000\n",
            "2/2 - 0s - loss: 0.6193 - accuracy: 0.6865 - val_loss: 0.7959 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 370/1000\n",
            "2/2 - 0s - loss: 0.6150 - accuracy: 0.6706 - val_loss: 0.7932 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 371/1000\n",
            "2/2 - 0s - loss: 0.6355 - accuracy: 0.6468 - val_loss: 0.7854 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 372/1000\n",
            "2/2 - 0s - loss: 0.6263 - accuracy: 0.6746 - val_loss: 0.7839 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 373/1000\n",
            "2/2 - 0s - loss: 0.6027 - accuracy: 0.6786 - val_loss: 0.7862 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 374/1000\n",
            "2/2 - 0s - loss: 0.6391 - accuracy: 0.6667 - val_loss: 0.7854 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 375/1000\n",
            "2/2 - 0s - loss: 0.6006 - accuracy: 0.6944 - val_loss: 0.7837 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 376/1000\n",
            "2/2 - 0s - loss: 0.6339 - accuracy: 0.6786 - val_loss: 0.7816 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 377/1000\n",
            "2/2 - 0s - loss: 0.5961 - accuracy: 0.6905 - val_loss: 0.7804 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 378/1000\n",
            "2/2 - 0s - loss: 0.6484 - accuracy: 0.6151 - val_loss: 0.7774 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 379/1000\n",
            "2/2 - 0s - loss: 0.5993 - accuracy: 0.7063 - val_loss: 0.7802 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 380/1000\n",
            "2/2 - 0s - loss: 0.6159 - accuracy: 0.6706 - val_loss: 0.7846 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 381/1000\n",
            "2/2 - 0s - loss: 0.6290 - accuracy: 0.6865 - val_loss: 0.7880 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 382/1000\n",
            "2/2 - 0s - loss: 0.5965 - accuracy: 0.6905 - val_loss: 0.7951 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 383/1000\n",
            "2/2 - 0s - loss: 0.6073 - accuracy: 0.6984 - val_loss: 0.7993 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 384/1000\n",
            "2/2 - 0s - loss: 0.5843 - accuracy: 0.6905 - val_loss: 0.8068 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 385/1000\n",
            "2/2 - 0s - loss: 0.5923 - accuracy: 0.6905 - val_loss: 0.8154 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 386/1000\n",
            "2/2 - 0s - loss: 0.5927 - accuracy: 0.6984 - val_loss: 0.8243 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 387/1000\n",
            "2/2 - 0s - loss: 0.6288 - accuracy: 0.7024 - val_loss: 0.8260 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 388/1000\n",
            "2/2 - 0s - loss: 0.6005 - accuracy: 0.6865 - val_loss: 0.8261 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 389/1000\n",
            "2/2 - 0s - loss: 0.6239 - accuracy: 0.6548 - val_loss: 0.8237 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 390/1000\n",
            "2/2 - 0s - loss: 0.6066 - accuracy: 0.6627 - val_loss: 0.8207 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 391/1000\n",
            "2/2 - 0s - loss: 0.6193 - accuracy: 0.6825 - val_loss: 0.8139 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 392/1000\n",
            "2/2 - 0s - loss: 0.6147 - accuracy: 0.6706 - val_loss: 0.8084 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 393/1000\n",
            "2/2 - 0s - loss: 0.6185 - accuracy: 0.6786 - val_loss: 0.8019 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 394/1000\n",
            "2/2 - 0s - loss: 0.6122 - accuracy: 0.6349 - val_loss: 0.7965 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 395/1000\n",
            "2/2 - 0s - loss: 0.6108 - accuracy: 0.6627 - val_loss: 0.7938 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 396/1000\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.6825 - val_loss: 0.7931 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 397/1000\n",
            "2/2 - 0s - loss: 0.6175 - accuracy: 0.6786 - val_loss: 0.7935 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 398/1000\n",
            "2/2 - 0s - loss: 0.6181 - accuracy: 0.6825 - val_loss: 0.7925 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 399/1000\n",
            "2/2 - 0s - loss: 0.6288 - accuracy: 0.6667 - val_loss: 0.7940 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 400/1000\n",
            "2/2 - 0s - loss: 0.6119 - accuracy: 0.6944 - val_loss: 0.7973 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 401/1000\n",
            "2/2 - 0s - loss: 0.5817 - accuracy: 0.7063 - val_loss: 0.8057 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 402/1000\n",
            "2/2 - 0s - loss: 0.5889 - accuracy: 0.7063 - val_loss: 0.8153 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 403/1000\n",
            "2/2 - 0s - loss: 0.6264 - accuracy: 0.6825 - val_loss: 0.8235 - val_accuracy: 0.4219 - 32ms/epoch - 16ms/step\n",
            "Epoch 404/1000\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6706 - val_loss: 0.8248 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 405/1000\n",
            "2/2 - 0s - loss: 0.6215 - accuracy: 0.6786 - val_loss: 0.8255 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 406/1000\n",
            "2/2 - 0s - loss: 0.6040 - accuracy: 0.6786 - val_loss: 0.8241 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 407/1000\n",
            "2/2 - 0s - loss: 0.6039 - accuracy: 0.6786 - val_loss: 0.8229 - val_accuracy: 0.4219 - 40ms/epoch - 20ms/step\n",
            "Epoch 408/1000\n",
            "2/2 - 0s - loss: 0.6269 - accuracy: 0.6667 - val_loss: 0.8204 - val_accuracy: 0.4219 - 33ms/epoch - 17ms/step\n",
            "Epoch 409/1000\n",
            "2/2 - 0s - loss: 0.6112 - accuracy: 0.6746 - val_loss: 0.8156 - val_accuracy: 0.4219 - 44ms/epoch - 22ms/step\n",
            "Epoch 410/1000\n",
            "2/2 - 0s - loss: 0.5671 - accuracy: 0.7103 - val_loss: 0.8144 - val_accuracy: 0.4375 - 41ms/epoch - 21ms/step\n",
            "Epoch 411/1000\n",
            "2/2 - 0s - loss: 0.6013 - accuracy: 0.7103 - val_loss: 0.8179 - val_accuracy: 0.4375 - 47ms/epoch - 24ms/step\n",
            "Epoch 412/1000\n",
            "2/2 - 0s - loss: 0.6001 - accuracy: 0.6786 - val_loss: 0.8208 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 413/1000\n",
            "2/2 - 0s - loss: 0.6045 - accuracy: 0.6905 - val_loss: 0.8207 - val_accuracy: 0.4375 - 41ms/epoch - 21ms/step\n",
            "Epoch 414/1000\n",
            "2/2 - 0s - loss: 0.5778 - accuracy: 0.6944 - val_loss: 0.8250 - val_accuracy: 0.4219 - 38ms/epoch - 19ms/step\n",
            "Epoch 415/1000\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6905 - val_loss: 0.8256 - val_accuracy: 0.4219 - 55ms/epoch - 28ms/step\n",
            "Epoch 416/1000\n",
            "2/2 - 0s - loss: 0.6026 - accuracy: 0.6548 - val_loss: 0.8263 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 417/1000\n",
            "2/2 - 0s - loss: 0.6055 - accuracy: 0.6667 - val_loss: 0.8238 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 418/1000\n",
            "2/2 - 0s - loss: 0.5865 - accuracy: 0.6865 - val_loss: 0.8247 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 419/1000\n",
            "2/2 - 0s - loss: 0.5900 - accuracy: 0.6706 - val_loss: 0.8239 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 420/1000\n",
            "2/2 - 0s - loss: 0.6197 - accuracy: 0.6746 - val_loss: 0.8253 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 421/1000\n",
            "2/2 - 0s - loss: 0.6294 - accuracy: 0.6587 - val_loss: 0.8246 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 422/1000\n",
            "2/2 - 0s - loss: 0.5969 - accuracy: 0.6944 - val_loss: 0.8234 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 423/1000\n",
            "2/2 - 0s - loss: 0.6235 - accuracy: 0.6627 - val_loss: 0.8196 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 424/1000\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.7063 - val_loss: 0.8147 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 425/1000\n",
            "2/2 - 0s - loss: 0.5994 - accuracy: 0.6825 - val_loss: 0.8110 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 426/1000\n",
            "2/2 - 0s - loss: 0.6143 - accuracy: 0.6548 - val_loss: 0.8118 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 427/1000\n",
            "2/2 - 0s - loss: 0.6239 - accuracy: 0.6548 - val_loss: 0.8114 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 428/1000\n",
            "2/2 - 0s - loss: 0.6126 - accuracy: 0.6706 - val_loss: 0.8103 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 429/1000\n",
            "2/2 - 0s - loss: 0.5811 - accuracy: 0.7024 - val_loss: 0.8102 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 430/1000\n",
            "2/2 - 0s - loss: 0.6256 - accuracy: 0.6825 - val_loss: 0.8068 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 431/1000\n",
            "2/2 - 0s - loss: 0.6148 - accuracy: 0.7024 - val_loss: 0.8049 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 432/1000\n",
            "2/2 - 0s - loss: 0.5954 - accuracy: 0.6786 - val_loss: 0.8027 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 433/1000\n",
            "2/2 - 0s - loss: 0.6198 - accuracy: 0.6825 - val_loss: 0.8027 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 434/1000\n",
            "2/2 - 0s - loss: 0.6168 - accuracy: 0.7143 - val_loss: 0.8048 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 435/1000\n",
            "2/2 - 0s - loss: 0.5892 - accuracy: 0.6944 - val_loss: 0.8048 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 436/1000\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.7024 - val_loss: 0.8064 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 437/1000\n",
            "2/2 - 0s - loss: 0.6232 - accuracy: 0.6627 - val_loss: 0.8066 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 438/1000\n",
            "2/2 - 0s - loss: 0.5829 - accuracy: 0.7262 - val_loss: 0.8082 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 439/1000\n",
            "2/2 - 0s - loss: 0.5930 - accuracy: 0.6984 - val_loss: 0.8116 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 440/1000\n",
            "2/2 - 0s - loss: 0.5962 - accuracy: 0.7024 - val_loss: 0.8158 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 441/1000\n",
            "2/2 - 0s - loss: 0.6043 - accuracy: 0.6786 - val_loss: 0.8201 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 442/1000\n",
            "2/2 - 0s - loss: 0.5849 - accuracy: 0.6865 - val_loss: 0.8214 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 443/1000\n",
            "2/2 - 0s - loss: 0.6018 - accuracy: 0.6786 - val_loss: 0.8223 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 444/1000\n",
            "2/2 - 0s - loss: 0.6281 - accuracy: 0.7063 - val_loss: 0.8167 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 445/1000\n",
            "2/2 - 0s - loss: 0.6329 - accuracy: 0.6548 - val_loss: 0.8050 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 446/1000\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6587 - val_loss: 0.7945 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 447/1000\n",
            "2/2 - 0s - loss: 0.6029 - accuracy: 0.6706 - val_loss: 0.7892 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 448/1000\n",
            "2/2 - 0s - loss: 0.5842 - accuracy: 0.6905 - val_loss: 0.7875 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 449/1000\n",
            "2/2 - 0s - loss: 0.6172 - accuracy: 0.6667 - val_loss: 0.7900 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 450/1000\n",
            "2/2 - 0s - loss: 0.6026 - accuracy: 0.6786 - val_loss: 0.7943 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 451/1000\n",
            "2/2 - 0s - loss: 0.5834 - accuracy: 0.7063 - val_loss: 0.8004 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 452/1000\n",
            "2/2 - 0s - loss: 0.6215 - accuracy: 0.6667 - val_loss: 0.8090 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 453/1000\n",
            "2/2 - 0s - loss: 0.5910 - accuracy: 0.6786 - val_loss: 0.8176 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 454/1000\n",
            "2/2 - 0s - loss: 0.6212 - accuracy: 0.6667 - val_loss: 0.8240 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 455/1000\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6706 - val_loss: 0.8297 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 456/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6746 - val_loss: 0.8304 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 457/1000\n",
            "2/2 - 0s - loss: 0.5811 - accuracy: 0.7222 - val_loss: 0.8274 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 458/1000\n",
            "2/2 - 0s - loss: 0.5934 - accuracy: 0.6905 - val_loss: 0.8258 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 459/1000\n",
            "2/2 - 0s - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.8214 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 460/1000\n",
            "2/2 - 0s - loss: 0.5783 - accuracy: 0.7222 - val_loss: 0.8160 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 461/1000\n",
            "2/2 - 0s - loss: 0.6101 - accuracy: 0.6548 - val_loss: 0.8130 - val_accuracy: 0.4375 - 41ms/epoch - 20ms/step\n",
            "Epoch 462/1000\n",
            "2/2 - 0s - loss: 0.5956 - accuracy: 0.6905 - val_loss: 0.8123 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 463/1000\n",
            "2/2 - 0s - loss: 0.5962 - accuracy: 0.6944 - val_loss: 0.8113 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 464/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.7024 - val_loss: 0.8173 - val_accuracy: 0.4375 - 29ms/epoch - 15ms/step\n",
            "Epoch 465/1000\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6548 - val_loss: 0.8236 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 466/1000\n",
            "2/2 - 0s - loss: 0.6230 - accuracy: 0.6825 - val_loss: 0.8233 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 467/1000\n",
            "2/2 - 0s - loss: 0.6117 - accuracy: 0.7024 - val_loss: 0.8222 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 468/1000\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6706 - val_loss: 0.8188 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 469/1000\n",
            "2/2 - 0s - loss: 0.5885 - accuracy: 0.7103 - val_loss: 0.8168 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 470/1000\n",
            "2/2 - 0s - loss: 0.5995 - accuracy: 0.6706 - val_loss: 0.8171 - val_accuracy: 0.4531 - 49ms/epoch - 25ms/step\n",
            "Epoch 471/1000\n",
            "2/2 - 0s - loss: 0.6099 - accuracy: 0.6905 - val_loss: 0.8136 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 472/1000\n",
            "2/2 - 0s - loss: 0.6009 - accuracy: 0.6905 - val_loss: 0.8095 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 473/1000\n",
            "2/2 - 0s - loss: 0.6174 - accuracy: 0.6905 - val_loss: 0.8029 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 474/1000\n",
            "2/2 - 0s - loss: 0.5761 - accuracy: 0.7222 - val_loss: 0.8014 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 475/1000\n",
            "2/2 - 0s - loss: 0.5896 - accuracy: 0.7024 - val_loss: 0.8014 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 476/1000\n",
            "2/2 - 0s - loss: 0.5957 - accuracy: 0.6944 - val_loss: 0.8022 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 477/1000\n",
            "2/2 - 0s - loss: 0.5854 - accuracy: 0.7103 - val_loss: 0.8059 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 478/1000\n",
            "2/2 - 0s - loss: 0.6294 - accuracy: 0.6746 - val_loss: 0.8091 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 479/1000\n",
            "2/2 - 0s - loss: 0.6144 - accuracy: 0.6865 - val_loss: 0.8110 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 480/1000\n",
            "2/2 - 0s - loss: 0.6137 - accuracy: 0.6746 - val_loss: 0.8136 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 481/1000\n",
            "2/2 - 0s - loss: 0.6149 - accuracy: 0.6627 - val_loss: 0.8145 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 482/1000\n",
            "2/2 - 0s - loss: 0.5923 - accuracy: 0.6786 - val_loss: 0.8188 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 483/1000\n",
            "2/2 - 0s - loss: 0.5969 - accuracy: 0.6667 - val_loss: 0.8226 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 484/1000\n",
            "2/2 - 0s - loss: 0.5872 - accuracy: 0.7103 - val_loss: 0.8286 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 485/1000\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6786 - val_loss: 0.8283 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 486/1000\n",
            "2/2 - 0s - loss: 0.6032 - accuracy: 0.7222 - val_loss: 0.8275 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 487/1000\n",
            "2/2 - 0s - loss: 0.5878 - accuracy: 0.7024 - val_loss: 0.8237 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 488/1000\n",
            "2/2 - 0s - loss: 0.6350 - accuracy: 0.6548 - val_loss: 0.8207 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 489/1000\n",
            "2/2 - 0s - loss: 0.6061 - accuracy: 0.6984 - val_loss: 0.8185 - val_accuracy: 0.4375 - 42ms/epoch - 21ms/step\n",
            "Epoch 490/1000\n",
            "2/2 - 0s - loss: 0.6067 - accuracy: 0.7063 - val_loss: 0.8201 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 491/1000\n",
            "2/2 - 0s - loss: 0.6164 - accuracy: 0.7143 - val_loss: 0.8216 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 492/1000\n",
            "2/2 - 0s - loss: 0.6066 - accuracy: 0.6905 - val_loss: 0.8225 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 493/1000\n",
            "2/2 - 0s - loss: 0.5818 - accuracy: 0.6825 - val_loss: 0.8230 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 494/1000\n",
            "2/2 - 0s - loss: 0.6332 - accuracy: 0.6627 - val_loss: 0.8220 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 495/1000\n",
            "2/2 - 0s - loss: 0.6162 - accuracy: 0.7103 - val_loss: 0.8195 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 496/1000\n",
            "2/2 - 0s - loss: 0.5824 - accuracy: 0.7063 - val_loss: 0.8184 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 497/1000\n",
            "2/2 - 0s - loss: 0.6009 - accuracy: 0.6786 - val_loss: 0.8207 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 498/1000\n",
            "2/2 - 0s - loss: 0.6224 - accuracy: 0.6587 - val_loss: 0.8237 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 499/1000\n",
            "2/2 - 0s - loss: 0.6011 - accuracy: 0.6825 - val_loss: 0.8243 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 500/1000\n",
            "2/2 - 0s - loss: 0.6061 - accuracy: 0.6627 - val_loss: 0.8228 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 501/1000\n",
            "2/2 - 0s - loss: 0.6328 - accuracy: 0.6548 - val_loss: 0.8193 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 502/1000\n",
            "2/2 - 0s - loss: 0.5828 - accuracy: 0.7222 - val_loss: 0.8230 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 503/1000\n",
            "2/2 - 0s - loss: 0.6021 - accuracy: 0.6746 - val_loss: 0.8245 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 504/1000\n",
            "2/2 - 0s - loss: 0.5981 - accuracy: 0.7262 - val_loss: 0.8259 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 505/1000\n",
            "2/2 - 0s - loss: 0.5811 - accuracy: 0.7222 - val_loss: 0.8310 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 506/1000\n",
            "2/2 - 0s - loss: 0.6170 - accuracy: 0.7024 - val_loss: 0.8301 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 507/1000\n",
            "2/2 - 0s - loss: 0.5854 - accuracy: 0.7024 - val_loss: 0.8304 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 508/1000\n",
            "2/2 - 0s - loss: 0.6109 - accuracy: 0.6944 - val_loss: 0.8286 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 509/1000\n",
            "2/2 - 0s - loss: 0.6087 - accuracy: 0.6786 - val_loss: 0.8223 - val_accuracy: 0.4219 - 31ms/epoch - 15ms/step\n",
            "Epoch 510/1000\n",
            "2/2 - 0s - loss: 0.5892 - accuracy: 0.7341 - val_loss: 0.8161 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 511/1000\n",
            "2/2 - 0s - loss: 0.5905 - accuracy: 0.7063 - val_loss: 0.8105 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 512/1000\n",
            "2/2 - 0s - loss: 0.5737 - accuracy: 0.6984 - val_loss: 0.8076 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 513/1000\n",
            "2/2 - 0s - loss: 0.5962 - accuracy: 0.6825 - val_loss: 0.8053 - val_accuracy: 0.4531 - 29ms/epoch - 14ms/step\n",
            "Epoch 514/1000\n",
            "2/2 - 0s - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.8061 - val_accuracy: 0.4531 - 42ms/epoch - 21ms/step\n",
            "Epoch 515/1000\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6627 - val_loss: 0.8042 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 516/1000\n",
            "2/2 - 0s - loss: 0.6177 - accuracy: 0.6667 - val_loss: 0.8006 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 517/1000\n",
            "2/2 - 0s - loss: 0.5983 - accuracy: 0.7024 - val_loss: 0.8015 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 518/1000\n",
            "2/2 - 0s - loss: 0.6074 - accuracy: 0.6508 - val_loss: 0.8001 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 519/1000\n",
            "2/2 - 0s - loss: 0.6188 - accuracy: 0.6587 - val_loss: 0.8000 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 520/1000\n",
            "2/2 - 0s - loss: 0.5791 - accuracy: 0.7262 - val_loss: 0.8007 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 521/1000\n",
            "2/2 - 0s - loss: 0.6122 - accuracy: 0.6746 - val_loss: 0.7970 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 522/1000\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.7063 - val_loss: 0.7950 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 523/1000\n",
            "2/2 - 0s - loss: 0.5839 - accuracy: 0.6865 - val_loss: 0.7965 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 524/1000\n",
            "2/2 - 0s - loss: 0.5981 - accuracy: 0.6786 - val_loss: 0.7941 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 525/1000\n",
            "2/2 - 0s - loss: 0.5939 - accuracy: 0.6786 - val_loss: 0.7946 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 526/1000\n",
            "2/2 - 0s - loss: 0.6376 - accuracy: 0.6667 - val_loss: 0.7940 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 527/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.6905 - val_loss: 0.7921 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 528/1000\n",
            "2/2 - 0s - loss: 0.6053 - accuracy: 0.6786 - val_loss: 0.7924 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 529/1000\n",
            "2/2 - 0s - loss: 0.5723 - accuracy: 0.7103 - val_loss: 0.7934 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 530/1000\n",
            "2/2 - 0s - loss: 0.6034 - accuracy: 0.6944 - val_loss: 0.7955 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 531/1000\n",
            "2/2 - 0s - loss: 0.5649 - accuracy: 0.7222 - val_loss: 0.8028 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 532/1000\n",
            "2/2 - 0s - loss: 0.5896 - accuracy: 0.7183 - val_loss: 0.8140 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 533/1000\n",
            "2/2 - 0s - loss: 0.5787 - accuracy: 0.7103 - val_loss: 0.8265 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 534/1000\n",
            "2/2 - 0s - loss: 0.6066 - accuracy: 0.6825 - val_loss: 0.8421 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 535/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.7063 - val_loss: 0.8502 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 536/1000\n",
            "2/2 - 0s - loss: 0.5817 - accuracy: 0.6944 - val_loss: 0.8540 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 537/1000\n",
            "2/2 - 0s - loss: 0.5749 - accuracy: 0.7103 - val_loss: 0.8502 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 538/1000\n",
            "2/2 - 0s - loss: 0.5863 - accuracy: 0.7103 - val_loss: 0.8449 - val_accuracy: 0.4375 - 41ms/epoch - 20ms/step\n",
            "Epoch 539/1000\n",
            "2/2 - 0s - loss: 0.5699 - accuracy: 0.6944 - val_loss: 0.8447 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 540/1000\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.6706 - val_loss: 0.8432 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 541/1000\n",
            "2/2 - 0s - loss: 0.5787 - accuracy: 0.7063 - val_loss: 0.8373 - val_accuracy: 0.4375 - 50ms/epoch - 25ms/step\n",
            "Epoch 542/1000\n",
            "2/2 - 0s - loss: 0.5956 - accuracy: 0.7222 - val_loss: 0.8336 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 543/1000\n",
            "2/2 - 0s - loss: 0.5957 - accuracy: 0.6905 - val_loss: 0.8304 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 544/1000\n",
            "2/2 - 0s - loss: 0.6213 - accuracy: 0.6825 - val_loss: 0.8208 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 545/1000\n",
            "2/2 - 0s - loss: 0.5952 - accuracy: 0.6905 - val_loss: 0.8120 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 546/1000\n",
            "2/2 - 0s - loss: 0.5998 - accuracy: 0.7103 - val_loss: 0.8081 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 547/1000\n",
            "2/2 - 0s - loss: 0.5935 - accuracy: 0.6905 - val_loss: 0.8083 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 548/1000\n",
            "2/2 - 0s - loss: 0.6095 - accuracy: 0.6905 - val_loss: 0.8103 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 549/1000\n",
            "2/2 - 0s - loss: 0.5614 - accuracy: 0.7421 - val_loss: 0.8197 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 550/1000\n",
            "2/2 - 0s - loss: 0.5614 - accuracy: 0.7183 - val_loss: 0.8335 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 551/1000\n",
            "2/2 - 0s - loss: 0.5752 - accuracy: 0.6984 - val_loss: 0.8435 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 552/1000\n",
            "2/2 - 0s - loss: 0.5786 - accuracy: 0.6944 - val_loss: 0.8492 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 553/1000\n",
            "2/2 - 0s - loss: 0.5682 - accuracy: 0.7183 - val_loss: 0.8501 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 554/1000\n",
            "2/2 - 0s - loss: 0.5999 - accuracy: 0.6865 - val_loss: 0.8507 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 555/1000\n",
            "2/2 - 0s - loss: 0.5914 - accuracy: 0.6706 - val_loss: 0.8483 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 556/1000\n",
            "2/2 - 0s - loss: 0.6152 - accuracy: 0.6746 - val_loss: 0.8410 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 557/1000\n",
            "2/2 - 0s - loss: 0.6100 - accuracy: 0.6905 - val_loss: 0.8324 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 558/1000\n",
            "2/2 - 0s - loss: 0.5967 - accuracy: 0.6905 - val_loss: 0.8221 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 559/1000\n",
            "2/2 - 0s - loss: 0.5750 - accuracy: 0.7103 - val_loss: 0.8172 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 560/1000\n",
            "2/2 - 0s - loss: 0.6214 - accuracy: 0.6627 - val_loss: 0.8139 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 561/1000\n",
            "2/2 - 0s - loss: 0.6081 - accuracy: 0.6905 - val_loss: 0.8090 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 562/1000\n",
            "2/2 - 0s - loss: 0.5934 - accuracy: 0.7143 - val_loss: 0.8083 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 563/1000\n",
            "2/2 - 0s - loss: 0.6069 - accuracy: 0.7302 - val_loss: 0.8091 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 564/1000\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6786 - val_loss: 0.8116 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 565/1000\n",
            "2/2 - 0s - loss: 0.6178 - accuracy: 0.6984 - val_loss: 0.8110 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 566/1000\n",
            "2/2 - 0s - loss: 0.5863 - accuracy: 0.7143 - val_loss: 0.8135 - val_accuracy: 0.4531 - 45ms/epoch - 22ms/step\n",
            "Epoch 567/1000\n",
            "2/2 - 0s - loss: 0.6201 - accuracy: 0.6627 - val_loss: 0.8207 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 568/1000\n",
            "2/2 - 0s - loss: 0.5764 - accuracy: 0.7222 - val_loss: 0.8252 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 569/1000\n",
            "2/2 - 0s - loss: 0.6109 - accuracy: 0.7024 - val_loss: 0.8255 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 570/1000\n",
            "2/2 - 0s - loss: 0.5927 - accuracy: 0.6984 - val_loss: 0.8217 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 571/1000\n",
            "2/2 - 0s - loss: 0.6110 - accuracy: 0.6905 - val_loss: 0.8163 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 572/1000\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6825 - val_loss: 0.8146 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 573/1000\n",
            "2/2 - 0s - loss: 0.5739 - accuracy: 0.7302 - val_loss: 0.8166 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 574/1000\n",
            "2/2 - 0s - loss: 0.5550 - accuracy: 0.7262 - val_loss: 0.8196 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 575/1000\n",
            "2/2 - 0s - loss: 0.6111 - accuracy: 0.6627 - val_loss: 0.8245 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 576/1000\n",
            "2/2 - 0s - loss: 0.6191 - accuracy: 0.6825 - val_loss: 0.8248 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 577/1000\n",
            "2/2 - 0s - loss: 0.5902 - accuracy: 0.7103 - val_loss: 0.8196 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 578/1000\n",
            "2/2 - 0s - loss: 0.5839 - accuracy: 0.6984 - val_loss: 0.8171 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 579/1000\n",
            "2/2 - 0s - loss: 0.5787 - accuracy: 0.6944 - val_loss: 0.8203 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 580/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.7103 - val_loss: 0.8278 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 581/1000\n",
            "2/2 - 0s - loss: 0.5889 - accuracy: 0.7063 - val_loss: 0.8324 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 582/1000\n",
            "2/2 - 0s - loss: 0.5942 - accuracy: 0.6905 - val_loss: 0.8421 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 583/1000\n",
            "2/2 - 0s - loss: 0.5860 - accuracy: 0.6984 - val_loss: 0.8526 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 584/1000\n",
            "2/2 - 0s - loss: 0.5880 - accuracy: 0.7143 - val_loss: 0.8589 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 585/1000\n",
            "2/2 - 0s - loss: 0.6085 - accuracy: 0.6627 - val_loss: 0.8632 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 586/1000\n",
            "2/2 - 0s - loss: 0.5825 - accuracy: 0.7262 - val_loss: 0.8552 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 587/1000\n",
            "2/2 - 0s - loss: 0.6135 - accuracy: 0.6944 - val_loss: 0.8394 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 588/1000\n",
            "2/2 - 0s - loss: 0.5681 - accuracy: 0.7143 - val_loss: 0.8252 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 589/1000\n",
            "2/2 - 0s - loss: 0.6028 - accuracy: 0.7262 - val_loss: 0.8151 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 590/1000\n",
            "2/2 - 0s - loss: 0.6491 - accuracy: 0.6627 - val_loss: 0.8036 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 591/1000\n",
            "2/2 - 0s - loss: 0.5649 - accuracy: 0.7421 - val_loss: 0.7975 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 592/1000\n",
            "2/2 - 0s - loss: 0.6106 - accuracy: 0.6905 - val_loss: 0.7949 - val_accuracy: 0.4531 - 43ms/epoch - 22ms/step\n",
            "Epoch 593/1000\n",
            "2/2 - 0s - loss: 0.5920 - accuracy: 0.7103 - val_loss: 0.7950 - val_accuracy: 0.4375 - 47ms/epoch - 24ms/step\n",
            "Epoch 594/1000\n",
            "2/2 - 0s - loss: 0.6189 - accuracy: 0.6627 - val_loss: 0.7976 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 595/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6825 - val_loss: 0.8017 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 596/1000\n",
            "2/2 - 0s - loss: 0.5849 - accuracy: 0.7063 - val_loss: 0.8089 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 597/1000\n",
            "2/2 - 0s - loss: 0.5718 - accuracy: 0.7063 - val_loss: 0.8172 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 598/1000\n",
            "2/2 - 0s - loss: 0.6188 - accuracy: 0.6627 - val_loss: 0.8259 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 599/1000\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.7024 - val_loss: 0.8330 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 600/1000\n",
            "2/2 - 0s - loss: 0.5859 - accuracy: 0.6865 - val_loss: 0.8399 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 601/1000\n",
            "2/2 - 0s - loss: 0.5846 - accuracy: 0.6984 - val_loss: 0.8479 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 602/1000\n",
            "2/2 - 0s - loss: 0.5924 - accuracy: 0.7262 - val_loss: 0.8525 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 603/1000\n",
            "2/2 - 0s - loss: 0.5991 - accuracy: 0.6746 - val_loss: 0.8511 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 604/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.6865 - val_loss: 0.8449 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 605/1000\n",
            "2/2 - 0s - loss: 0.5813 - accuracy: 0.7024 - val_loss: 0.8421 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 606/1000\n",
            "2/2 - 0s - loss: 0.5721 - accuracy: 0.7143 - val_loss: 0.8433 - val_accuracy: 0.4531 - 72ms/epoch - 36ms/step\n",
            "Epoch 607/1000\n",
            "2/2 - 0s - loss: 0.5822 - accuracy: 0.7143 - val_loss: 0.8452 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 608/1000\n",
            "2/2 - 0s - loss: 0.5844 - accuracy: 0.6905 - val_loss: 0.8424 - val_accuracy: 0.4688 - 29ms/epoch - 14ms/step\n",
            "Epoch 609/1000\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.7024 - val_loss: 0.8350 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 610/1000\n",
            "2/2 - 0s - loss: 0.5753 - accuracy: 0.7222 - val_loss: 0.8296 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 611/1000\n",
            "2/2 - 0s - loss: 0.5727 - accuracy: 0.7063 - val_loss: 0.8246 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 612/1000\n",
            "2/2 - 0s - loss: 0.5679 - accuracy: 0.7143 - val_loss: 0.8299 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 613/1000\n",
            "2/2 - 0s - loss: 0.5874 - accuracy: 0.7103 - val_loss: 0.8392 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 614/1000\n",
            "2/2 - 0s - loss: 0.5754 - accuracy: 0.7103 - val_loss: 0.8528 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 615/1000\n",
            "2/2 - 0s - loss: 0.5691 - accuracy: 0.7302 - val_loss: 0.8673 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 616/1000\n",
            "2/2 - 0s - loss: 0.5789 - accuracy: 0.7063 - val_loss: 0.8803 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 617/1000\n",
            "2/2 - 0s - loss: 0.6083 - accuracy: 0.6865 - val_loss: 0.8837 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 618/1000\n",
            "2/2 - 0s - loss: 0.5742 - accuracy: 0.7341 - val_loss: 0.8758 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 619/1000\n",
            "2/2 - 0s - loss: 0.5946 - accuracy: 0.6944 - val_loss: 0.8671 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 620/1000\n",
            "2/2 - 0s - loss: 0.5939 - accuracy: 0.7103 - val_loss: 0.8623 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 621/1000\n",
            "2/2 - 0s - loss: 0.5932 - accuracy: 0.6865 - val_loss: 0.8644 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 622/1000\n",
            "2/2 - 0s - loss: 0.5822 - accuracy: 0.7024 - val_loss: 0.8648 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 623/1000\n",
            "2/2 - 0s - loss: 0.6176 - accuracy: 0.6865 - val_loss: 0.8564 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 624/1000\n",
            "2/2 - 0s - loss: 0.5829 - accuracy: 0.6984 - val_loss: 0.8558 - val_accuracy: 0.4688 - 48ms/epoch - 24ms/step\n",
            "Epoch 625/1000\n",
            "2/2 - 0s - loss: 0.5840 - accuracy: 0.6786 - val_loss: 0.8639 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 626/1000\n",
            "2/2 - 0s - loss: 0.6097 - accuracy: 0.6627 - val_loss: 0.8628 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 627/1000\n",
            "2/2 - 0s - loss: 0.5725 - accuracy: 0.7143 - val_loss: 0.8584 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 628/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7143 - val_loss: 0.8560 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 629/1000\n",
            "2/2 - 0s - loss: 0.5963 - accuracy: 0.7183 - val_loss: 0.8574 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 630/1000\n",
            "2/2 - 0s - loss: 0.6045 - accuracy: 0.6825 - val_loss: 0.8501 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 631/1000\n",
            "2/2 - 0s - loss: 0.5989 - accuracy: 0.6706 - val_loss: 0.8431 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 632/1000\n",
            "2/2 - 0s - loss: 0.5893 - accuracy: 0.7143 - val_loss: 0.8371 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 633/1000\n",
            "2/2 - 0s - loss: 0.5981 - accuracy: 0.6984 - val_loss: 0.8283 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 634/1000\n",
            "2/2 - 0s - loss: 0.5696 - accuracy: 0.7103 - val_loss: 0.8213 - val_accuracy: 0.4219 - 56ms/epoch - 28ms/step\n",
            "Epoch 635/1000\n",
            "2/2 - 0s - loss: 0.5715 - accuracy: 0.7024 - val_loss: 0.8175 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 636/1000\n",
            "2/2 - 0s - loss: 0.5823 - accuracy: 0.7183 - val_loss: 0.8144 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 637/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7183 - val_loss: 0.8145 - val_accuracy: 0.4375 - 33ms/epoch - 17ms/step\n",
            "Epoch 638/1000\n",
            "2/2 - 0s - loss: 0.5779 - accuracy: 0.7024 - val_loss: 0.8178 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 639/1000\n",
            "2/2 - 0s - loss: 0.5705 - accuracy: 0.7063 - val_loss: 0.8226 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 640/1000\n",
            "2/2 - 0s - loss: 0.5734 - accuracy: 0.7024 - val_loss: 0.8274 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 641/1000\n",
            "2/2 - 0s - loss: 0.5822 - accuracy: 0.6865 - val_loss: 0.8287 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 642/1000\n",
            "2/2 - 0s - loss: 0.5605 - accuracy: 0.7302 - val_loss: 0.8338 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 643/1000\n",
            "2/2 - 0s - loss: 0.6098 - accuracy: 0.6944 - val_loss: 0.8377 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 644/1000\n",
            "2/2 - 0s - loss: 0.5706 - accuracy: 0.6944 - val_loss: 0.8416 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 645/1000\n",
            "2/2 - 0s - loss: 0.5968 - accuracy: 0.6944 - val_loss: 0.8452 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 646/1000\n",
            "2/2 - 0s - loss: 0.6110 - accuracy: 0.6746 - val_loss: 0.8496 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 647/1000\n",
            "2/2 - 0s - loss: 0.6074 - accuracy: 0.6984 - val_loss: 0.8520 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 648/1000\n",
            "2/2 - 0s - loss: 0.5758 - accuracy: 0.7103 - val_loss: 0.8553 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 649/1000\n",
            "2/2 - 0s - loss: 0.5898 - accuracy: 0.7262 - val_loss: 0.8536 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 650/1000\n",
            "2/2 - 0s - loss: 0.5856 - accuracy: 0.7063 - val_loss: 0.8483 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 651/1000\n",
            "2/2 - 0s - loss: 0.5941 - accuracy: 0.6944 - val_loss: 0.8381 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 652/1000\n",
            "2/2 - 0s - loss: 0.5879 - accuracy: 0.6905 - val_loss: 0.8274 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 653/1000\n",
            "2/2 - 0s - loss: 0.5793 - accuracy: 0.7063 - val_loss: 0.8218 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 654/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.6944 - val_loss: 0.8222 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 655/1000\n",
            "2/2 - 0s - loss: 0.5626 - accuracy: 0.6984 - val_loss: 0.8242 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 656/1000\n",
            "2/2 - 0s - loss: 0.6256 - accuracy: 0.6825 - val_loss: 0.8280 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 657/1000\n",
            "2/2 - 0s - loss: 0.5986 - accuracy: 0.6706 - val_loss: 0.8328 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 658/1000\n",
            "2/2 - 0s - loss: 0.5752 - accuracy: 0.7143 - val_loss: 0.8389 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 659/1000\n",
            "2/2 - 0s - loss: 0.5798 - accuracy: 0.6944 - val_loss: 0.8425 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 660/1000\n",
            "2/2 - 0s - loss: 0.6093 - accuracy: 0.6627 - val_loss: 0.8453 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 661/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7262 - val_loss: 0.8494 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 662/1000\n",
            "2/2 - 0s - loss: 0.5787 - accuracy: 0.7262 - val_loss: 0.8539 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 663/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7381 - val_loss: 0.8578 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 664/1000\n",
            "2/2 - 0s - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.8590 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 665/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.6905 - val_loss: 0.8516 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 666/1000\n",
            "2/2 - 0s - loss: 0.5928 - accuracy: 0.7103 - val_loss: 0.8388 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 667/1000\n",
            "2/2 - 0s - loss: 0.5768 - accuracy: 0.7302 - val_loss: 0.8264 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 668/1000\n",
            "2/2 - 0s - loss: 0.6031 - accuracy: 0.6786 - val_loss: 0.8147 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 669/1000\n",
            "2/2 - 0s - loss: 0.5928 - accuracy: 0.7024 - val_loss: 0.8094 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 670/1000\n",
            "2/2 - 0s - loss: 0.5953 - accuracy: 0.6905 - val_loss: 0.8090 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 671/1000\n",
            "2/2 - 0s - loss: 0.5808 - accuracy: 0.6944 - val_loss: 0.8114 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 672/1000\n",
            "2/2 - 0s - loss: 0.5816 - accuracy: 0.6627 - val_loss: 0.8192 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 673/1000\n",
            "2/2 - 0s - loss: 0.5846 - accuracy: 0.7103 - val_loss: 0.8272 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 674/1000\n",
            "2/2 - 0s - loss: 0.5770 - accuracy: 0.7183 - val_loss: 0.8352 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 675/1000\n",
            "2/2 - 0s - loss: 0.6002 - accuracy: 0.7143 - val_loss: 0.8406 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 676/1000\n",
            "2/2 - 0s - loss: 0.6161 - accuracy: 0.6786 - val_loss: 0.8406 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 677/1000\n",
            "2/2 - 0s - loss: 0.5569 - accuracy: 0.7222 - val_loss: 0.8416 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 678/1000\n",
            "2/2 - 0s - loss: 0.5742 - accuracy: 0.7143 - val_loss: 0.8478 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 679/1000\n",
            "2/2 - 0s - loss: 0.5959 - accuracy: 0.7063 - val_loss: 0.8504 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 680/1000\n",
            "2/2 - 0s - loss: 0.5712 - accuracy: 0.7143 - val_loss: 0.8471 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 681/1000\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.6746 - val_loss: 0.8374 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 682/1000\n",
            "2/2 - 0s - loss: 0.5911 - accuracy: 0.6706 - val_loss: 0.8346 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 683/1000\n",
            "2/2 - 0s - loss: 0.5802 - accuracy: 0.6944 - val_loss: 0.8341 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 684/1000\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.6905 - val_loss: 0.8292 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 685/1000\n",
            "2/2 - 0s - loss: 0.5645 - accuracy: 0.6984 - val_loss: 0.8291 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 686/1000\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7262 - val_loss: 0.8354 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 687/1000\n",
            "2/2 - 0s - loss: 0.5928 - accuracy: 0.7222 - val_loss: 0.8453 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 688/1000\n",
            "2/2 - 0s - loss: 0.6004 - accuracy: 0.6984 - val_loss: 0.8546 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 689/1000\n",
            "2/2 - 0s - loss: 0.5801 - accuracy: 0.7024 - val_loss: 0.8641 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 690/1000\n",
            "2/2 - 0s - loss: 0.5847 - accuracy: 0.7183 - val_loss: 0.8756 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 691/1000\n",
            "2/2 - 0s - loss: 0.5992 - accuracy: 0.6905 - val_loss: 0.8860 - val_accuracy: 0.4375 - 45ms/epoch - 23ms/step\n",
            "Epoch 692/1000\n",
            "2/2 - 0s - loss: 0.5939 - accuracy: 0.6865 - val_loss: 0.8872 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 693/1000\n",
            "2/2 - 0s - loss: 0.5917 - accuracy: 0.7024 - val_loss: 0.8896 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 694/1000\n",
            "2/2 - 0s - loss: 0.6192 - accuracy: 0.6627 - val_loss: 0.8755 - val_accuracy: 0.4375 - 39ms/epoch - 19ms/step\n",
            "Epoch 695/1000\n",
            "2/2 - 0s - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.8602 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 696/1000\n",
            "2/2 - 0s - loss: 0.5841 - accuracy: 0.7024 - val_loss: 0.8489 - val_accuracy: 0.4531 - 42ms/epoch - 21ms/step\n",
            "Epoch 697/1000\n",
            "2/2 - 0s - loss: 0.5735 - accuracy: 0.7183 - val_loss: 0.8442 - val_accuracy: 0.4219 - 41ms/epoch - 20ms/step\n",
            "Epoch 698/1000\n",
            "2/2 - 0s - loss: 0.5878 - accuracy: 0.7262 - val_loss: 0.8433 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 699/1000\n",
            "2/2 - 0s - loss: 0.5879 - accuracy: 0.6865 - val_loss: 0.8439 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 700/1000\n",
            "2/2 - 0s - loss: 0.5566 - accuracy: 0.7381 - val_loss: 0.8467 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 701/1000\n",
            "2/2 - 0s - loss: 0.5885 - accuracy: 0.7024 - val_loss: 0.8448 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 702/1000\n",
            "2/2 - 0s - loss: 0.5762 - accuracy: 0.7143 - val_loss: 0.8359 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 703/1000\n",
            "2/2 - 0s - loss: 0.5941 - accuracy: 0.7143 - val_loss: 0.8323 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 704/1000\n",
            "2/2 - 0s - loss: 0.5871 - accuracy: 0.6865 - val_loss: 0.8327 - val_accuracy: 0.4531 - 50ms/epoch - 25ms/step\n",
            "Epoch 705/1000\n",
            "2/2 - 0s - loss: 0.6070 - accuracy: 0.6746 - val_loss: 0.8367 - val_accuracy: 0.4375 - 39ms/epoch - 20ms/step\n",
            "Epoch 706/1000\n",
            "2/2 - 0s - loss: 0.5657 - accuracy: 0.7262 - val_loss: 0.8388 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 707/1000\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.7143 - val_loss: 0.8406 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 708/1000\n",
            "2/2 - 0s - loss: 0.5860 - accuracy: 0.6905 - val_loss: 0.8441 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 709/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.7063 - val_loss: 0.8497 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 710/1000\n",
            "2/2 - 0s - loss: 0.5935 - accuracy: 0.6984 - val_loss: 0.8528 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 711/1000\n",
            "2/2 - 0s - loss: 0.5681 - accuracy: 0.7143 - val_loss: 0.8567 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 712/1000\n",
            "2/2 - 0s - loss: 0.5778 - accuracy: 0.7143 - val_loss: 0.8669 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 713/1000\n",
            "2/2 - 0s - loss: 0.5923 - accuracy: 0.6905 - val_loss: 0.8716 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 714/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.6944 - val_loss: 0.8751 - val_accuracy: 0.4375 - 41ms/epoch - 20ms/step\n",
            "Epoch 715/1000\n",
            "2/2 - 0s - loss: 0.5560 - accuracy: 0.7302 - val_loss: 0.8744 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 716/1000\n",
            "2/2 - 0s - loss: 0.6030 - accuracy: 0.6905 - val_loss: 0.8629 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 717/1000\n",
            "2/2 - 0s - loss: 0.6249 - accuracy: 0.6905 - val_loss: 0.8469 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 718/1000\n",
            "2/2 - 0s - loss: 0.5821 - accuracy: 0.7024 - val_loss: 0.8350 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 719/1000\n",
            "2/2 - 0s - loss: 0.5458 - accuracy: 0.7183 - val_loss: 0.8336 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 720/1000\n",
            "2/2 - 0s - loss: 0.5917 - accuracy: 0.7143 - val_loss: 0.8349 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 721/1000\n",
            "2/2 - 0s - loss: 0.6081 - accuracy: 0.6865 - val_loss: 0.8358 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 722/1000\n",
            "2/2 - 0s - loss: 0.5872 - accuracy: 0.7341 - val_loss: 0.8414 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 723/1000\n",
            "2/2 - 0s - loss: 0.5513 - accuracy: 0.7421 - val_loss: 0.8562 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 724/1000\n",
            "2/2 - 0s - loss: 0.5456 - accuracy: 0.7262 - val_loss: 0.8788 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 725/1000\n",
            "2/2 - 0s - loss: 0.5797 - accuracy: 0.6984 - val_loss: 0.8991 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 726/1000\n",
            "2/2 - 0s - loss: 0.5440 - accuracy: 0.7460 - val_loss: 0.9146 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 727/1000\n",
            "2/2 - 0s - loss: 0.5709 - accuracy: 0.7103 - val_loss: 0.9224 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 728/1000\n",
            "2/2 - 0s - loss: 0.5950 - accuracy: 0.6667 - val_loss: 0.9171 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 729/1000\n",
            "2/2 - 0s - loss: 0.5848 - accuracy: 0.6944 - val_loss: 0.9079 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 730/1000\n",
            "2/2 - 0s - loss: 0.5699 - accuracy: 0.6944 - val_loss: 0.9018 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 731/1000\n",
            "2/2 - 0s - loss: 0.5698 - accuracy: 0.7302 - val_loss: 0.8985 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 732/1000\n",
            "2/2 - 0s - loss: 0.5790 - accuracy: 0.7302 - val_loss: 0.8896 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 733/1000\n",
            "2/2 - 0s - loss: 0.5657 - accuracy: 0.7222 - val_loss: 0.8830 - val_accuracy: 0.4688 - 29ms/epoch - 15ms/step\n",
            "Epoch 734/1000\n",
            "2/2 - 0s - loss: 0.5675 - accuracy: 0.7341 - val_loss: 0.8747 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 735/1000\n",
            "2/2 - 0s - loss: 0.5836 - accuracy: 0.7103 - val_loss: 0.8704 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 736/1000\n",
            "2/2 - 0s - loss: 0.5670 - accuracy: 0.7302 - val_loss: 0.8617 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 737/1000\n",
            "2/2 - 0s - loss: 0.5552 - accuracy: 0.7341 - val_loss: 0.8575 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 738/1000\n",
            "2/2 - 0s - loss: 0.5491 - accuracy: 0.7341 - val_loss: 0.8546 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 739/1000\n",
            "2/2 - 0s - loss: 0.5995 - accuracy: 0.6786 - val_loss: 0.8544 - val_accuracy: 0.4531 - 43ms/epoch - 22ms/step\n",
            "Epoch 740/1000\n",
            "2/2 - 0s - loss: 0.5409 - accuracy: 0.7460 - val_loss: 0.8610 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 741/1000\n",
            "2/2 - 0s - loss: 0.5790 - accuracy: 0.6905 - val_loss: 0.8656 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 742/1000\n",
            "2/2 - 0s - loss: 0.5606 - accuracy: 0.7222 - val_loss: 0.8748 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 743/1000\n",
            "2/2 - 0s - loss: 0.5491 - accuracy: 0.7500 - val_loss: 0.8875 - val_accuracy: 0.4375 - 39ms/epoch - 20ms/step\n",
            "Epoch 744/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.7024 - val_loss: 0.8961 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 745/1000\n",
            "2/2 - 0s - loss: 0.5740 - accuracy: 0.7103 - val_loss: 0.8988 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 746/1000\n",
            "2/2 - 0s - loss: 0.5569 - accuracy: 0.7500 - val_loss: 0.9020 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 747/1000\n",
            "2/2 - 0s - loss: 0.5644 - accuracy: 0.7302 - val_loss: 0.9089 - val_accuracy: 0.4531 - 42ms/epoch - 21ms/step\n",
            "Epoch 748/1000\n",
            "2/2 - 0s - loss: 0.5626 - accuracy: 0.7341 - val_loss: 0.9169 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 749/1000\n",
            "2/2 - 0s - loss: 0.5663 - accuracy: 0.7063 - val_loss: 0.9261 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 750/1000\n",
            "2/2 - 0s - loss: 0.5651 - accuracy: 0.7143 - val_loss: 0.9317 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 751/1000\n",
            "2/2 - 0s - loss: 0.6049 - accuracy: 0.6944 - val_loss: 0.9184 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 752/1000\n",
            "2/2 - 0s - loss: 0.5826 - accuracy: 0.6865 - val_loss: 0.9078 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 753/1000\n",
            "2/2 - 0s - loss: 0.5513 - accuracy: 0.7381 - val_loss: 0.8982 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 754/1000\n",
            "2/2 - 0s - loss: 0.6129 - accuracy: 0.7063 - val_loss: 0.8914 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 755/1000\n",
            "2/2 - 0s - loss: 0.5613 - accuracy: 0.7183 - val_loss: 0.8913 - val_accuracy: 0.4688 - 46ms/epoch - 23ms/step\n",
            "Epoch 756/1000\n",
            "2/2 - 0s - loss: 0.5465 - accuracy: 0.7103 - val_loss: 0.9047 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 757/1000\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.6944 - val_loss: 0.9061 - val_accuracy: 0.4219 - 40ms/epoch - 20ms/step\n",
            "Epoch 758/1000\n",
            "2/2 - 0s - loss: 0.5581 - accuracy: 0.7421 - val_loss: 0.9068 - val_accuracy: 0.4219 - 37ms/epoch - 19ms/step\n",
            "Epoch 759/1000\n",
            "2/2 - 0s - loss: 0.5541 - accuracy: 0.7302 - val_loss: 0.9002 - val_accuracy: 0.4219 - 37ms/epoch - 18ms/step\n",
            "Epoch 760/1000\n",
            "2/2 - 0s - loss: 0.5864 - accuracy: 0.6984 - val_loss: 0.8937 - val_accuracy: 0.4219 - 35ms/epoch - 17ms/step\n",
            "Epoch 761/1000\n",
            "2/2 - 0s - loss: 0.5813 - accuracy: 0.7421 - val_loss: 0.8825 - val_accuracy: 0.4375 - 39ms/epoch - 20ms/step\n",
            "Epoch 762/1000\n",
            "2/2 - 0s - loss: 0.5695 - accuracy: 0.7302 - val_loss: 0.8747 - val_accuracy: 0.4375 - 39ms/epoch - 19ms/step\n",
            "Epoch 763/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7302 - val_loss: 0.8692 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 764/1000\n",
            "2/2 - 0s - loss: 0.5465 - accuracy: 0.7024 - val_loss: 0.8643 - val_accuracy: 0.4531 - 43ms/epoch - 22ms/step\n",
            "Epoch 765/1000\n",
            "2/2 - 0s - loss: 0.5800 - accuracy: 0.7063 - val_loss: 0.8652 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 766/1000\n",
            "2/2 - 0s - loss: 0.5653 - accuracy: 0.7302 - val_loss: 0.8691 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 767/1000\n",
            "2/2 - 0s - loss: 0.6005 - accuracy: 0.7143 - val_loss: 0.8737 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 768/1000\n",
            "2/2 - 0s - loss: 0.5802 - accuracy: 0.6905 - val_loss: 0.8738 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 769/1000\n",
            "2/2 - 0s - loss: 0.5911 - accuracy: 0.6865 - val_loss: 0.8787 - val_accuracy: 0.4375 - 33ms/epoch - 16ms/step\n",
            "Epoch 770/1000\n",
            "2/2 - 0s - loss: 0.5800 - accuracy: 0.6944 - val_loss: 0.8765 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 771/1000\n",
            "2/2 - 0s - loss: 0.5854 - accuracy: 0.7302 - val_loss: 0.8803 - val_accuracy: 0.4531 - 59ms/epoch - 29ms/step\n",
            "Epoch 772/1000\n",
            "2/2 - 0s - loss: 0.5674 - accuracy: 0.7302 - val_loss: 0.8861 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 773/1000\n",
            "2/2 - 0s - loss: 0.5877 - accuracy: 0.7103 - val_loss: 0.8879 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 774/1000\n",
            "2/2 - 0s - loss: 0.5670 - accuracy: 0.7063 - val_loss: 0.8809 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 775/1000\n",
            "2/2 - 0s - loss: 0.5885 - accuracy: 0.7024 - val_loss: 0.8795 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 776/1000\n",
            "2/2 - 0s - loss: 0.5600 - accuracy: 0.7460 - val_loss: 0.8837 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 777/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.7183 - val_loss: 0.8817 - val_accuracy: 0.4531 - 60ms/epoch - 30ms/step\n",
            "Epoch 778/1000\n",
            "2/2 - 0s - loss: 0.5448 - accuracy: 0.7262 - val_loss: 0.8842 - val_accuracy: 0.4531 - 61ms/epoch - 31ms/step\n",
            "Epoch 779/1000\n",
            "2/2 - 0s - loss: 0.5693 - accuracy: 0.6905 - val_loss: 0.8871 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 780/1000\n",
            "2/2 - 0s - loss: 0.5490 - accuracy: 0.7421 - val_loss: 0.8970 - val_accuracy: 0.4375 - 30ms/epoch - 15ms/step\n",
            "Epoch 781/1000\n",
            "2/2 - 0s - loss: 0.5527 - accuracy: 0.7302 - val_loss: 0.9037 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 782/1000\n",
            "2/2 - 0s - loss: 0.5459 - accuracy: 0.7183 - val_loss: 0.9076 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 783/1000\n",
            "2/2 - 0s - loss: 0.5422 - accuracy: 0.7262 - val_loss: 0.9120 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 784/1000\n",
            "2/2 - 0s - loss: 0.5647 - accuracy: 0.7341 - val_loss: 0.9149 - val_accuracy: 0.4219 - 32ms/epoch - 16ms/step\n",
            "Epoch 785/1000\n",
            "2/2 - 0s - loss: 0.5831 - accuracy: 0.7063 - val_loss: 0.9180 - val_accuracy: 0.4219 - 35ms/epoch - 17ms/step\n",
            "Epoch 786/1000\n",
            "2/2 - 0s - loss: 0.6092 - accuracy: 0.6905 - val_loss: 0.9088 - val_accuracy: 0.4219 - 38ms/epoch - 19ms/step\n",
            "Epoch 787/1000\n",
            "2/2 - 0s - loss: 0.5784 - accuracy: 0.7381 - val_loss: 0.8946 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 788/1000\n",
            "2/2 - 0s - loss: 0.5704 - accuracy: 0.7024 - val_loss: 0.8795 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 789/1000\n",
            "2/2 - 0s - loss: 0.5594 - accuracy: 0.7381 - val_loss: 0.8670 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 790/1000\n",
            "2/2 - 0s - loss: 0.5963 - accuracy: 0.6984 - val_loss: 0.8543 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 791/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7262 - val_loss: 0.8444 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 792/1000\n",
            "2/2 - 0s - loss: 0.5428 - accuracy: 0.7262 - val_loss: 0.8441 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 793/1000\n",
            "2/2 - 0s - loss: 0.5822 - accuracy: 0.6944 - val_loss: 0.8514 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 794/1000\n",
            "2/2 - 0s - loss: 0.5831 - accuracy: 0.7143 - val_loss: 0.8622 - val_accuracy: 0.4531 - 48ms/epoch - 24ms/step\n",
            "Epoch 795/1000\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.7063 - val_loss: 0.8716 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 796/1000\n",
            "2/2 - 0s - loss: 0.5862 - accuracy: 0.7183 - val_loss: 0.8687 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 797/1000\n",
            "2/2 - 0s - loss: 0.6058 - accuracy: 0.7103 - val_loss: 0.8639 - val_accuracy: 0.4688 - 31ms/epoch - 15ms/step\n",
            "Epoch 798/1000\n",
            "2/2 - 0s - loss: 0.5585 - accuracy: 0.7103 - val_loss: 0.8613 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 799/1000\n",
            "2/2 - 0s - loss: 0.5901 - accuracy: 0.7262 - val_loss: 0.8631 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 800/1000\n",
            "2/2 - 0s - loss: 0.5850 - accuracy: 0.7183 - val_loss: 0.8629 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 801/1000\n",
            "2/2 - 0s - loss: 0.5582 - accuracy: 0.7381 - val_loss: 0.8615 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 802/1000\n",
            "2/2 - 0s - loss: 0.5440 - accuracy: 0.7540 - val_loss: 0.8658 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 803/1000\n",
            "2/2 - 0s - loss: 0.5474 - accuracy: 0.7024 - val_loss: 0.8739 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 804/1000\n",
            "2/2 - 0s - loss: 0.5552 - accuracy: 0.6944 - val_loss: 0.8828 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 805/1000\n",
            "2/2 - 0s - loss: 0.5799 - accuracy: 0.7143 - val_loss: 0.8900 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 806/1000\n",
            "2/2 - 0s - loss: 0.5626 - accuracy: 0.7381 - val_loss: 0.9021 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 807/1000\n",
            "2/2 - 0s - loss: 0.5565 - accuracy: 0.7460 - val_loss: 0.9166 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 808/1000\n",
            "2/2 - 0s - loss: 0.5831 - accuracy: 0.7302 - val_loss: 0.9257 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 809/1000\n",
            "2/2 - 0s - loss: 0.5781 - accuracy: 0.7302 - val_loss: 0.9194 - val_accuracy: 0.4219 - 35ms/epoch - 17ms/step\n",
            "Epoch 810/1000\n",
            "2/2 - 0s - loss: 0.5555 - accuracy: 0.6984 - val_loss: 0.9151 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 811/1000\n",
            "2/2 - 0s - loss: 0.5835 - accuracy: 0.7143 - val_loss: 0.8985 - val_accuracy: 0.4219 - 34ms/epoch - 17ms/step\n",
            "Epoch 812/1000\n",
            "2/2 - 0s - loss: 0.5840 - accuracy: 0.7024 - val_loss: 0.8855 - val_accuracy: 0.4219 - 40ms/epoch - 20ms/step\n",
            "Epoch 813/1000\n",
            "2/2 - 0s - loss: 0.5483 - accuracy: 0.7341 - val_loss: 0.8781 - val_accuracy: 0.4375 - 51ms/epoch - 26ms/step\n",
            "Epoch 814/1000\n",
            "2/2 - 0s - loss: 0.5725 - accuracy: 0.7143 - val_loss: 0.8728 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 815/1000\n",
            "2/2 - 0s - loss: 0.5797 - accuracy: 0.6825 - val_loss: 0.8654 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 816/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7063 - val_loss: 0.8620 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 817/1000\n",
            "2/2 - 0s - loss: 0.5732 - accuracy: 0.7103 - val_loss: 0.8691 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 818/1000\n",
            "2/2 - 0s - loss: 0.5489 - accuracy: 0.7381 - val_loss: 0.8830 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 819/1000\n",
            "2/2 - 0s - loss: 0.5548 - accuracy: 0.7460 - val_loss: 0.8896 - val_accuracy: 0.4531 - 49ms/epoch - 25ms/step\n",
            "Epoch 820/1000\n",
            "2/2 - 0s - loss: 0.5869 - accuracy: 0.7103 - val_loss: 0.8858 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 821/1000\n",
            "2/2 - 0s - loss: 0.5759 - accuracy: 0.7063 - val_loss: 0.8789 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 822/1000\n",
            "2/2 - 0s - loss: 0.5788 - accuracy: 0.7143 - val_loss: 0.8750 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 823/1000\n",
            "2/2 - 0s - loss: 0.5767 - accuracy: 0.6905 - val_loss: 0.8705 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 824/1000\n",
            "2/2 - 0s - loss: 0.5489 - accuracy: 0.7222 - val_loss: 0.8694 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 825/1000\n",
            "2/2 - 0s - loss: 0.5696 - accuracy: 0.7262 - val_loss: 0.8721 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 826/1000\n",
            "2/2 - 0s - loss: 0.5591 - accuracy: 0.7103 - val_loss: 0.8802 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 827/1000\n",
            "2/2 - 0s - loss: 0.5559 - accuracy: 0.7063 - val_loss: 0.8844 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 828/1000\n",
            "2/2 - 0s - loss: 0.5678 - accuracy: 0.7460 - val_loss: 0.8901 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 829/1000\n",
            "2/2 - 0s - loss: 0.5454 - accuracy: 0.7341 - val_loss: 0.8904 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 830/1000\n",
            "2/2 - 0s - loss: 0.5553 - accuracy: 0.7302 - val_loss: 0.8864 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 831/1000\n",
            "2/2 - 0s - loss: 0.5311 - accuracy: 0.7381 - val_loss: 0.8834 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 832/1000\n",
            "2/2 - 0s - loss: 0.5688 - accuracy: 0.7222 - val_loss: 0.8733 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 833/1000\n",
            "2/2 - 0s - loss: 0.5636 - accuracy: 0.7341 - val_loss: 0.8674 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 834/1000\n",
            "2/2 - 0s - loss: 0.6039 - accuracy: 0.6944 - val_loss: 0.8616 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 835/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.7460 - val_loss: 0.8580 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 836/1000\n",
            "2/2 - 0s - loss: 0.5659 - accuracy: 0.7222 - val_loss: 0.8690 - val_accuracy: 0.4531 - 42ms/epoch - 21ms/step\n",
            "Epoch 837/1000\n",
            "2/2 - 0s - loss: 0.5525 - accuracy: 0.7103 - val_loss: 0.8751 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 838/1000\n",
            "2/2 - 0s - loss: 0.5869 - accuracy: 0.7222 - val_loss: 0.8800 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 839/1000\n",
            "2/2 - 0s - loss: 0.5809 - accuracy: 0.7063 - val_loss: 0.8781 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 840/1000\n",
            "2/2 - 0s - loss: 0.5625 - accuracy: 0.7143 - val_loss: 0.8762 - val_accuracy: 0.4375 - 37ms/epoch - 19ms/step\n",
            "Epoch 841/1000\n",
            "2/2 - 0s - loss: 0.6114 - accuracy: 0.6865 - val_loss: 0.8724 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 842/1000\n",
            "2/2 - 0s - loss: 0.5743 - accuracy: 0.7341 - val_loss: 0.8669 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 843/1000\n",
            "2/2 - 0s - loss: 0.5734 - accuracy: 0.7143 - val_loss: 0.8687 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 844/1000\n",
            "2/2 - 0s - loss: 0.5539 - accuracy: 0.6944 - val_loss: 0.8753 - val_accuracy: 0.4531 - 50ms/epoch - 25ms/step\n",
            "Epoch 845/1000\n",
            "2/2 - 0s - loss: 0.5998 - accuracy: 0.7103 - val_loss: 0.8800 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 846/1000\n",
            "2/2 - 0s - loss: 0.5289 - accuracy: 0.7500 - val_loss: 0.8841 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 847/1000\n",
            "2/2 - 0s - loss: 0.5502 - accuracy: 0.7063 - val_loss: 0.8859 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 848/1000\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.7183 - val_loss: 0.8897 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 849/1000\n",
            "2/2 - 0s - loss: 0.5417 - accuracy: 0.7341 - val_loss: 0.8965 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 850/1000\n",
            "2/2 - 0s - loss: 0.5604 - accuracy: 0.7262 - val_loss: 0.9058 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 851/1000\n",
            "2/2 - 0s - loss: 0.5819 - accuracy: 0.7143 - val_loss: 0.8922 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 852/1000\n",
            "2/2 - 0s - loss: 0.5814 - accuracy: 0.6944 - val_loss: 0.8717 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 853/1000\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7183 - val_loss: 0.8544 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 854/1000\n",
            "2/2 - 0s - loss: 0.5524 - accuracy: 0.7063 - val_loss: 0.8429 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 855/1000\n",
            "2/2 - 0s - loss: 0.5700 - accuracy: 0.7103 - val_loss: 0.8318 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 856/1000\n",
            "2/2 - 0s - loss: 0.5779 - accuracy: 0.7183 - val_loss: 0.8314 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 857/1000\n",
            "2/2 - 0s - loss: 0.5556 - accuracy: 0.7460 - val_loss: 0.8329 - val_accuracy: 0.4688 - 61ms/epoch - 30ms/step\n",
            "Epoch 858/1000\n",
            "2/2 - 0s - loss: 0.5694 - accuracy: 0.7183 - val_loss: 0.8476 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 859/1000\n",
            "2/2 - 0s - loss: 0.5518 - accuracy: 0.7500 - val_loss: 0.8735 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 860/1000\n",
            "2/2 - 0s - loss: 0.5659 - accuracy: 0.6905 - val_loss: 0.8991 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 861/1000\n",
            "2/2 - 0s - loss: 0.5641 - accuracy: 0.7222 - val_loss: 0.9171 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 862/1000\n",
            "2/2 - 0s - loss: 0.5498 - accuracy: 0.7381 - val_loss: 0.9277 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 863/1000\n",
            "2/2 - 0s - loss: 0.5606 - accuracy: 0.7222 - val_loss: 0.9314 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 864/1000\n",
            "2/2 - 0s - loss: 0.5671 - accuracy: 0.6984 - val_loss: 0.9381 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 865/1000\n",
            "2/2 - 0s - loss: 0.5637 - accuracy: 0.7421 - val_loss: 0.9413 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 866/1000\n",
            "2/2 - 0s - loss: 0.6019 - accuracy: 0.6905 - val_loss: 0.9380 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 867/1000\n",
            "2/2 - 0s - loss: 0.5799 - accuracy: 0.7024 - val_loss: 0.9314 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 868/1000\n",
            "2/2 - 0s - loss: 0.5960 - accuracy: 0.6944 - val_loss: 0.9242 - val_accuracy: 0.4531 - 43ms/epoch - 21ms/step\n",
            "Epoch 869/1000\n",
            "2/2 - 0s - loss: 0.5812 - accuracy: 0.6944 - val_loss: 0.9197 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 870/1000\n",
            "2/2 - 0s - loss: 0.6033 - accuracy: 0.7381 - val_loss: 0.9137 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 871/1000\n",
            "2/2 - 0s - loss: 0.5531 - accuracy: 0.7183 - val_loss: 0.9123 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 872/1000\n",
            "2/2 - 0s - loss: 0.5458 - accuracy: 0.7183 - val_loss: 0.9219 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 873/1000\n",
            "2/2 - 0s - loss: 0.5558 - accuracy: 0.7103 - val_loss: 0.9359 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 874/1000\n",
            "2/2 - 0s - loss: 0.5396 - accuracy: 0.7460 - val_loss: 0.9481 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 875/1000\n",
            "2/2 - 0s - loss: 0.6037 - accuracy: 0.6786 - val_loss: 0.9490 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 876/1000\n",
            "2/2 - 0s - loss: 0.5460 - accuracy: 0.7381 - val_loss: 0.9314 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 877/1000\n",
            "2/2 - 0s - loss: 0.5684 - accuracy: 0.6984 - val_loss: 0.9129 - val_accuracy: 0.4688 - 41ms/epoch - 21ms/step\n",
            "Epoch 878/1000\n",
            "2/2 - 0s - loss: 0.5458 - accuracy: 0.7381 - val_loss: 0.8952 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 879/1000\n",
            "2/2 - 0s - loss: 0.5762 - accuracy: 0.6944 - val_loss: 0.8787 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 880/1000\n",
            "2/2 - 0s - loss: 0.5707 - accuracy: 0.7302 - val_loss: 0.8682 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 881/1000\n",
            "2/2 - 0s - loss: 0.5322 - accuracy: 0.7540 - val_loss: 0.8707 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 882/1000\n",
            "2/2 - 0s - loss: 0.5663 - accuracy: 0.7063 - val_loss: 0.8735 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 883/1000\n",
            "2/2 - 0s - loss: 0.5588 - accuracy: 0.7183 - val_loss: 0.8801 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 884/1000\n",
            "2/2 - 0s - loss: 0.5820 - accuracy: 0.7063 - val_loss: 0.8901 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 885/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.6905 - val_loss: 0.9000 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 886/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7222 - val_loss: 0.9082 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 887/1000\n",
            "2/2 - 0s - loss: 0.5516 - accuracy: 0.7262 - val_loss: 0.9119 - val_accuracy: 0.4688 - 44ms/epoch - 22ms/step\n",
            "Epoch 888/1000\n",
            "2/2 - 0s - loss: 0.5483 - accuracy: 0.7341 - val_loss: 0.9140 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 889/1000\n",
            "2/2 - 0s - loss: 0.5465 - accuracy: 0.6944 - val_loss: 0.9133 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 890/1000\n",
            "2/2 - 0s - loss: 0.5475 - accuracy: 0.7540 - val_loss: 0.9127 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 891/1000\n",
            "2/2 - 0s - loss: 0.5711 - accuracy: 0.7222 - val_loss: 0.9083 - val_accuracy: 0.4531 - 31ms/epoch - 16ms/step\n",
            "Epoch 892/1000\n",
            "2/2 - 0s - loss: 0.5465 - accuracy: 0.7460 - val_loss: 0.9037 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 893/1000\n",
            "2/2 - 0s - loss: 0.5460 - accuracy: 0.7302 - val_loss: 0.9045 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 894/1000\n",
            "2/2 - 0s - loss: 0.5320 - accuracy: 0.7302 - val_loss: 0.9103 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 895/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.7063 - val_loss: 0.9131 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 896/1000\n",
            "2/2 - 0s - loss: 0.5511 - accuracy: 0.7500 - val_loss: 0.9158 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 897/1000\n",
            "2/2 - 0s - loss: 0.5615 - accuracy: 0.7302 - val_loss: 0.9186 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 898/1000\n",
            "2/2 - 0s - loss: 0.5488 - accuracy: 0.7183 - val_loss: 0.9218 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 899/1000\n",
            "2/2 - 0s - loss: 0.5637 - accuracy: 0.7183 - val_loss: 0.9250 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 900/1000\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7143 - val_loss: 0.9254 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 901/1000\n",
            "2/2 - 0s - loss: 0.5523 - accuracy: 0.7460 - val_loss: 0.9216 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 902/1000\n",
            "2/2 - 0s - loss: 0.5598 - accuracy: 0.7222 - val_loss: 0.9190 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 903/1000\n",
            "2/2 - 0s - loss: 0.5571 - accuracy: 0.7183 - val_loss: 0.9247 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 904/1000\n",
            "2/2 - 0s - loss: 0.5347 - accuracy: 0.7341 - val_loss: 0.9302 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 905/1000\n",
            "2/2 - 0s - loss: 0.5552 - accuracy: 0.7302 - val_loss: 0.9356 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 906/1000\n",
            "2/2 - 0s - loss: 0.5717 - accuracy: 0.6825 - val_loss: 0.9319 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 907/1000\n",
            "2/2 - 0s - loss: 0.5825 - accuracy: 0.6944 - val_loss: 0.9226 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 908/1000\n",
            "2/2 - 0s - loss: 0.5512 - accuracy: 0.7222 - val_loss: 0.9129 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 909/1000\n",
            "2/2 - 0s - loss: 0.5382 - accuracy: 0.7540 - val_loss: 0.9088 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 910/1000\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.7143 - val_loss: 0.9090 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 911/1000\n",
            "2/2 - 0s - loss: 0.5631 - accuracy: 0.6825 - val_loss: 0.9166 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 912/1000\n",
            "2/2 - 0s - loss: 0.5514 - accuracy: 0.7341 - val_loss: 0.9197 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 913/1000\n",
            "2/2 - 0s - loss: 0.5741 - accuracy: 0.7063 - val_loss: 0.9242 - val_accuracy: 0.4844 - 29ms/epoch - 15ms/step\n",
            "Epoch 914/1000\n",
            "2/2 - 0s - loss: 0.5961 - accuracy: 0.7183 - val_loss: 0.9177 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 915/1000\n",
            "2/2 - 0s - loss: 0.5962 - accuracy: 0.6905 - val_loss: 0.8871 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 916/1000\n",
            "2/2 - 0s - loss: 0.5534 - accuracy: 0.7183 - val_loss: 0.8669 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 917/1000\n",
            "2/2 - 0s - loss: 0.5460 - accuracy: 0.7222 - val_loss: 0.8547 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 918/1000\n",
            "2/2 - 0s - loss: 0.5923 - accuracy: 0.7222 - val_loss: 0.8505 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 919/1000\n",
            "2/2 - 0s - loss: 0.5563 - accuracy: 0.7143 - val_loss: 0.8559 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 920/1000\n",
            "2/2 - 0s - loss: 0.5764 - accuracy: 0.7103 - val_loss: 0.8646 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 921/1000\n",
            "2/2 - 0s - loss: 0.5663 - accuracy: 0.7183 - val_loss: 0.8819 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 922/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7262 - val_loss: 0.9051 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 923/1000\n",
            "2/2 - 0s - loss: 0.5642 - accuracy: 0.7262 - val_loss: 0.9262 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 924/1000\n",
            "2/2 - 0s - loss: 0.5247 - accuracy: 0.7460 - val_loss: 0.9506 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 925/1000\n",
            "2/2 - 0s - loss: 0.5379 - accuracy: 0.7262 - val_loss: 0.9714 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 926/1000\n",
            "2/2 - 0s - loss: 0.5225 - accuracy: 0.7381 - val_loss: 0.9889 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 927/1000\n",
            "2/2 - 0s - loss: 0.5648 - accuracy: 0.7103 - val_loss: 0.9844 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 928/1000\n",
            "2/2 - 0s - loss: 0.5569 - accuracy: 0.7460 - val_loss: 0.9708 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 929/1000\n",
            "2/2 - 0s - loss: 0.5352 - accuracy: 0.7302 - val_loss: 0.9619 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 930/1000\n",
            "2/2 - 0s - loss: 0.5531 - accuracy: 0.7302 - val_loss: 0.9434 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 931/1000\n",
            "2/2 - 0s - loss: 0.5652 - accuracy: 0.6984 - val_loss: 0.9247 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 932/1000\n",
            "2/2 - 0s - loss: 0.5553 - accuracy: 0.7341 - val_loss: 0.9071 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 933/1000\n",
            "2/2 - 0s - loss: 0.5847 - accuracy: 0.7183 - val_loss: 0.8857 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 934/1000\n",
            "2/2 - 0s - loss: 0.5473 - accuracy: 0.7222 - val_loss: 0.8689 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 935/1000\n",
            "2/2 - 0s - loss: 0.5499 - accuracy: 0.7143 - val_loss: 0.8668 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 936/1000\n",
            "2/2 - 0s - loss: 0.5209 - accuracy: 0.7619 - val_loss: 0.8736 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 937/1000\n",
            "2/2 - 0s - loss: 0.5563 - accuracy: 0.7222 - val_loss: 0.8895 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 938/1000\n",
            "2/2 - 0s - loss: 0.5543 - accuracy: 0.7341 - val_loss: 0.9044 - val_accuracy: 0.4844 - 46ms/epoch - 23ms/step\n",
            "Epoch 939/1000\n",
            "2/2 - 0s - loss: 0.5449 - accuracy: 0.7540 - val_loss: 0.9177 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 940/1000\n",
            "2/2 - 0s - loss: 0.5438 - accuracy: 0.7262 - val_loss: 0.9271 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 941/1000\n",
            "2/2 - 0s - loss: 0.5572 - accuracy: 0.7063 - val_loss: 0.9214 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 942/1000\n",
            "2/2 - 0s - loss: 0.5413 - accuracy: 0.7262 - val_loss: 0.9124 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 943/1000\n",
            "2/2 - 0s - loss: 0.5318 - accuracy: 0.7579 - val_loss: 0.9014 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 944/1000\n",
            "2/2 - 0s - loss: 0.5816 - accuracy: 0.7063 - val_loss: 0.8861 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 945/1000\n",
            "2/2 - 0s - loss: 0.5453 - accuracy: 0.7579 - val_loss: 0.8721 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 946/1000\n",
            "2/2 - 0s - loss: 0.5435 - accuracy: 0.7500 - val_loss: 0.8636 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 947/1000\n",
            "2/2 - 0s - loss: 0.5587 - accuracy: 0.7341 - val_loss: 0.8621 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 948/1000\n",
            "2/2 - 0s - loss: 0.5505 - accuracy: 0.7460 - val_loss: 0.8580 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 949/1000\n",
            "2/2 - 0s - loss: 0.5578 - accuracy: 0.7183 - val_loss: 0.8599 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 950/1000\n",
            "2/2 - 0s - loss: 0.5631 - accuracy: 0.7024 - val_loss: 0.8716 - val_accuracy: 0.5000 - 43ms/epoch - 21ms/step\n",
            "Epoch 951/1000\n",
            "2/2 - 0s - loss: 0.5364 - accuracy: 0.7262 - val_loss: 0.8941 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 952/1000\n",
            "2/2 - 0s - loss: 0.5408 - accuracy: 0.7500 - val_loss: 0.9167 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 953/1000\n",
            "2/2 - 0s - loss: 0.5418 - accuracy: 0.7421 - val_loss: 0.9340 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 954/1000\n",
            "2/2 - 0s - loss: 0.5495 - accuracy: 0.7222 - val_loss: 0.9504 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 955/1000\n",
            "2/2 - 0s - loss: 0.5366 - accuracy: 0.7302 - val_loss: 0.9550 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 956/1000\n",
            "2/2 - 0s - loss: 0.5584 - accuracy: 0.7063 - val_loss: 0.9620 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 957/1000\n",
            "2/2 - 0s - loss: 0.5361 - accuracy: 0.7460 - val_loss: 0.9691 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 958/1000\n",
            "2/2 - 0s - loss: 0.5704 - accuracy: 0.7302 - val_loss: 0.9684 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 959/1000\n",
            "2/2 - 0s - loss: 0.5718 - accuracy: 0.7063 - val_loss: 0.9471 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 960/1000\n",
            "2/2 - 0s - loss: 0.5062 - accuracy: 0.7619 - val_loss: 0.9398 - val_accuracy: 0.4531 - 41ms/epoch - 20ms/step\n",
            "Epoch 961/1000\n",
            "2/2 - 0s - loss: 0.5724 - accuracy: 0.7183 - val_loss: 0.9348 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 962/1000\n",
            "2/2 - 0s - loss: 0.5379 - accuracy: 0.7579 - val_loss: 0.9318 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 963/1000\n",
            "2/2 - 0s - loss: 0.5170 - accuracy: 0.7579 - val_loss: 0.9430 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 964/1000\n",
            "2/2 - 0s - loss: 0.5618 - accuracy: 0.7063 - val_loss: 0.9420 - val_accuracy: 0.4688 - 54ms/epoch - 27ms/step\n",
            "Epoch 965/1000\n",
            "2/2 - 0s - loss: 0.5361 - accuracy: 0.7381 - val_loss: 0.9414 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 966/1000\n",
            "2/2 - 0s - loss: 0.5788 - accuracy: 0.6984 - val_loss: 0.9222 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 967/1000\n",
            "2/2 - 0s - loss: 0.5388 - accuracy: 0.7619 - val_loss: 0.9096 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 968/1000\n",
            "2/2 - 0s - loss: 0.5502 - accuracy: 0.7500 - val_loss: 0.8961 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 969/1000\n",
            "2/2 - 0s - loss: 0.5253 - accuracy: 0.7698 - val_loss: 0.8941 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 970/1000\n",
            "2/2 - 0s - loss: 0.5473 - accuracy: 0.7302 - val_loss: 0.8972 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 971/1000\n",
            "2/2 - 0s - loss: 0.5897 - accuracy: 0.6865 - val_loss: 0.9055 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 972/1000\n",
            "2/2 - 0s - loss: 0.5433 - accuracy: 0.7381 - val_loss: 0.9129 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 973/1000\n",
            "2/2 - 0s - loss: 0.5452 - accuracy: 0.7341 - val_loss: 0.9218 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 974/1000\n",
            "2/2 - 0s - loss: 0.5351 - accuracy: 0.7540 - val_loss: 0.9327 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 975/1000\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7381 - val_loss: 0.9412 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 976/1000\n",
            "2/2 - 0s - loss: 0.5161 - accuracy: 0.7421 - val_loss: 0.9497 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 977/1000\n",
            "2/2 - 0s - loss: 0.5508 - accuracy: 0.7302 - val_loss: 0.9501 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 978/1000\n",
            "2/2 - 0s - loss: 0.5134 - accuracy: 0.7500 - val_loss: 0.9467 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 979/1000\n",
            "2/2 - 0s - loss: 0.5208 - accuracy: 0.7460 - val_loss: 0.9469 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 980/1000\n",
            "2/2 - 0s - loss: 0.5418 - accuracy: 0.7540 - val_loss: 0.9415 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 981/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7302 - val_loss: 0.9365 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 982/1000\n",
            "2/2 - 0s - loss: 0.5509 - accuracy: 0.7222 - val_loss: 0.9375 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 983/1000\n",
            "2/2 - 0s - loss: 0.5725 - accuracy: 0.7024 - val_loss: 0.9354 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 984/1000\n",
            "2/2 - 0s - loss: 0.5109 - accuracy: 0.7619 - val_loss: 0.9409 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 985/1000\n",
            "2/2 - 0s - loss: 0.5662 - accuracy: 0.7302 - val_loss: 0.9496 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 986/1000\n",
            "2/2 - 0s - loss: 0.5582 - accuracy: 0.7262 - val_loss: 0.9576 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 987/1000\n",
            "2/2 - 0s - loss: 0.5240 - accuracy: 0.7500 - val_loss: 0.9784 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 988/1000\n",
            "2/2 - 0s - loss: 0.5557 - accuracy: 0.7460 - val_loss: 0.9848 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 989/1000\n",
            "2/2 - 0s - loss: 0.5801 - accuracy: 0.6984 - val_loss: 0.9758 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 990/1000\n",
            "2/2 - 0s - loss: 0.4917 - accuracy: 0.7579 - val_loss: 0.9646 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 991/1000\n",
            "2/2 - 0s - loss: 0.5896 - accuracy: 0.7183 - val_loss: 0.9539 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 992/1000\n",
            "2/2 - 0s - loss: 0.5362 - accuracy: 0.7302 - val_loss: 0.9498 - val_accuracy: 0.5156 - 39ms/epoch - 19ms/step\n",
            "Epoch 993/1000\n",
            "2/2 - 0s - loss: 0.5483 - accuracy: 0.7421 - val_loss: 0.9481 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 994/1000\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.6905 - val_loss: 0.9395 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 995/1000\n",
            "2/2 - 0s - loss: 0.5536 - accuracy: 0.7222 - val_loss: 0.9222 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 996/1000\n",
            "2/2 - 0s - loss: 0.5788 - accuracy: 0.6865 - val_loss: 0.9105 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 997/1000\n",
            "2/2 - 0s - loss: 0.5582 - accuracy: 0.7262 - val_loss: 0.8969 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 998/1000\n",
            "2/2 - 0s - loss: 0.5546 - accuracy: 0.7222 - val_loss: 0.8933 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 999/1000\n",
            "2/2 - 0s - loss: 0.5315 - accuracy: 0.7619 - val_loss: 0.8944 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 1000/1000\n",
            "2/2 - 0s - loss: 0.5555 - accuracy: 0.7183 - val_loss: 0.9011 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9c2debc50>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evalaute evaluate Accury, and print out\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print()  \n",
        "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(score[1]*100.0)) \n",
        "#print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnctAHNo510",
        "outputId": "6c1620c1-fde8-494e-d6a8-3dcd6d79cd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0266 - accuracy: 0.5250\n",
            "\n",
            "\t[Info] Accuracy of testing data = 52.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 預測(prediction)\n",
        "# X = X_test[0:20,:]\n",
        "# #predictions = model.predict_classes(X)\n",
        "# mypredictions = model.predict(X).astype('int64')\n",
        "# classes_x = np.argmax(mypredictions, axis = 1)\n",
        "# classes_x\n",
        "\n",
        "#myPredict = model.predict_classes( X_test).astype('int64')\n",
        "myPredict=model.predict(X_test).astype('int64') \n",
        "classes_x=np.argmax(myPredict,axis=1)\n",
        "#print(classes_x)\n",
        "#classes_x"
      ],
      "metadata": {
        "id": "NQs9yzfqnE-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test\n",
        "#混淆矩陣 (confusion matrix)  -> cross table\n",
        "print(y_test_cross)\n",
        "print(classes_x)\n",
        "pd.crosstab(y_test_cross,classes_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "gipn3pzYpIQG",
        "outputId": "d897b1d6-4d60-497f-aa14-4fc5ea55ce34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0\n",
            " 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
            " 1 1 0 1 1 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0   0\n",
              "row_0    \n",
              "0      41\n",
              "1      39"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b229e684-a038-439a-b2d9-114101bc785a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b229e684-a038-439a-b2d9-114101bc785a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b229e684-a038-439a-b2d9-114101bc785a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b229e684-a038-439a-b2d9-114101bc785a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A8zpS7e7pGPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}