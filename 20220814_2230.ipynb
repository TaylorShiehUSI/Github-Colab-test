{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220814 2230.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2Qki/ggCl6RXvZxdZPDs9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaylorShiehUSI/Github-Colab-test/blob/main/20220814_2230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k8nXyuRd_S",
        "outputId": "8928e4a5-8d25-42d1-ee6f-28db4751e6b2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "cviUbaTWRSko"
      },
      "outputs": [],
      "source": [
        "# 下載資料套件\n",
        "import requests as r\n",
        "\n",
        "# 資料處理套件\n",
        "from lxml import etree\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "# 財經套件\n",
        "# import yfinance as yf\n",
        "\n",
        "# 畫圖套件\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## down load stock data\n",
        "def get_tw_stock_data(start_year, start_month, end_year, end_month, stock_code):\n",
        "    start_date = str(date(start_year, start_month, 1))\n",
        "    end_date = str(date(end_year, end_month, 1))\n",
        "    month_list = pd.date_range(start_date, end_date, freq='MS').strftime(\"%Y%m%d\").tolist()\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    for month in month_list:\n",
        "        url = \"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"+ month + \"&stockNo=\" + str(stock_code)\n",
        "        res = r.get(url)\n",
        "        stock_json = res.json()\n",
        "        stock_df = pd.DataFrame.from_dict(stock_json['data'])\n",
        "        df = df.append(stock_df, ignore_index = True)\n",
        "        \n",
        "    # 資料轉型\n",
        "    for col in [0, 1, 2, 3, 4, 5, 6, 8]:\n",
        "        for row in range(df.shape[0]):\n",
        "            # 把\"日期\"從字串(string)換成時間(datetime)，並將民國年換成西元年\n",
        "            if col == 0:\n",
        "                day = df.iloc[row,0].split('/')\n",
        "                df.iloc[row, 0] = datetime(int(day[0]) + 1911, int(day[1]), int(day[2]))  \n",
        "            # 把\"開盤價\", \"最高價\", \"最低價\", \"收盤價\"帶有逗號的字串(string)換成浮點數(float) \n",
        "            elif col != 0:\n",
        "                df.iloc[row, col] = float(df.iloc[row,col].replace(',', ''))\n",
        "    \n",
        "    df.columns = ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數']\n",
        "    return df"
      ],
      "metadata": {
        "id": "6IuqlNYjRvxb"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  input Start - End , and stock index\n",
        "stock_df = get_tw_stock_data(start_year = 2021, \n",
        "                start_month = 1, \n",
        "                end_year = 2022, \n",
        "                end_month = 8, \n",
        "                stock_code = 2330)\n",
        "stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tjxBWizKRyTK",
        "outputId": "0ba7b71e-cc61-4dc0-f2c0-695d6992ca7c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      日期        成交股數           成交金額    開盤價    最高價    最低價  \\\n",
              "0    2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0   \n",
              "1    2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0   \n",
              "2    2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0   \n",
              "3    2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0   \n",
              "4    2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0   \n",
              "..                   ...         ...            ...    ...    ...    ...   \n",
              "392  2022-08-15 00:00:00  22519886.0  11755494600.0  520.0  524.0  519.0   \n",
              "393  2022-08-16 00:00:00  21234122.0  11141160337.0  526.0  526.0  523.0   \n",
              "394  2022-08-17 00:00:00  28461939.0  14943047011.0  524.0  527.0  521.0   \n",
              "395  2022-08-18 00:00:00  18721898.0   9734756997.0  520.0  521.0  519.0   \n",
              "396  2022-08-19 00:00:00  13950000.0   7254815000.0  519.0  523.0  517.0   \n",
              "\n",
              "       收盤價    漲跌價差     成交筆數  \n",
              "0    536.0   +6.00  33316.0  \n",
              "1    542.0   +6.00  28512.0  \n",
              "2    549.0   +7.00  55462.0  \n",
              "3    565.0  +16.00  47905.0  \n",
              "4    580.0  +15.00  56426.0  \n",
              "..     ...     ...      ...  \n",
              "392  523.0   +6.00  27372.0  \n",
              "393  525.0   +2.00  20628.0  \n",
              "394  527.0   +2.00  26466.0  \n",
              "395  520.0   -7.00  24209.0  \n",
              "396  519.0   -1.00   6441.0  \n",
              "\n",
              "[397 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ec3b065-2502-459a-a236-2ac1376d2d44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>2022-08-15 00:00:00</td>\n",
              "      <td>22519886.0</td>\n",
              "      <td>11755494600.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>519.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>27372.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>2022-08-16 00:00:00</td>\n",
              "      <td>21234122.0</td>\n",
              "      <td>11141160337.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>+2.00</td>\n",
              "      <td>20628.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>2022-08-17 00:00:00</td>\n",
              "      <td>28461939.0</td>\n",
              "      <td>14943047011.0</td>\n",
              "      <td>524.0</td>\n",
              "      <td>527.0</td>\n",
              "      <td>521.0</td>\n",
              "      <td>527.0</td>\n",
              "      <td>+2.00</td>\n",
              "      <td>26466.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>2022-08-18 00:00:00</td>\n",
              "      <td>18721898.0</td>\n",
              "      <td>9734756997.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>521.0</td>\n",
              "      <td>519.0</td>\n",
              "      <td>520.0</td>\n",
              "      <td>-7.00</td>\n",
              "      <td>24209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>2022-08-19 00:00:00</td>\n",
              "      <td>13950000.0</td>\n",
              "      <td>7254815000.0</td>\n",
              "      <td>519.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>519.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>6441.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>397 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ec3b065-2502-459a-a236-2ac1376d2d44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ec3b065-2502-459a-a236-2ac1376d2d44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ec3b065-2502-459a-a236-2ac1376d2d44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save 2230 stock data to CSV\n",
        "stock_df.to_csv('2230.csv',encoding='utf-8_sig')"
      ],
      "metadata": {
        "id": "aa45vys1Vefv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Processing // Add is_up, (高低差，漲跌價差，單筆股數)，特徵\n",
        "import numpy as np\n",
        "\n",
        "stock_df['is_up'] = (stock_df['開盤價'].shift(-1) - stock_df['收盤價'] >0).astype('int')\n",
        "stock_df['高低差'] = (stock_df['最高價'] - stock_df['最低價']).astype('int')\n",
        "stock_df['漲跌價差'] = (stock_df['收盤價'] - stock_df['開盤價']).astype('int')\n",
        "stock_df['單筆股數'] = (stock_df['成交股數']/stock_df['成交筆數']).astype('int')\n",
        "\n",
        "## One Hot code for is_up \n",
        "def one_hot(targets, nb_classes):\n",
        "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "y_data = one_hot(stock_df['is_up'], 2)\n",
        "\n",
        "## 2230 Stock_df check\n",
        "stock_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s28R2AUsYOgW",
        "outputId": "588d15c0-6c83-4dce-dd99-44a0ef98bb70"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    日期        成交股數           成交金額    開盤價    最高價    最低價    收盤價  \\\n",
              "0  2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0  536.0   \n",
              "1  2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0  542.0   \n",
              "2  2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0  549.0   \n",
              "3  2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0  565.0   \n",
              "4  2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0  580.0   \n",
              "\n",
              "   漲跌價差     成交筆數  is_up  高低差  單筆股數  \n",
              "0     6  33316.0      0   12  1185  \n",
              "1     6  28512.0      1    7  1221  \n",
              "2    -6  55462.0      1   14  1002  \n",
              "3    11  47905.0      1   17  1114  \n",
              "4     0  56426.0      0    9  1115  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56a6ac68-dcc2-4b28-a594-5177af04cf61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>is_up</th>\n",
              "      <th>高低差</th>\n",
              "      <th>單筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>6</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>6</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>-6</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>11</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>0</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56a6ac68-dcc2-4b28-a594-5177af04cf61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56a6ac68-dcc2-4b28-a594-5177af04cf61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56a6ac68-dcc2-4b28-a594-5177af04cf61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stock Data Exploring\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '成交金額',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '成交筆數',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '單筆股數',kde=False )\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '高低差', kde=False)\n",
        "\n",
        "g = sns.FacetGrid(stock_df, col='is_up')\n",
        "g.map(sns.distplot, '漲跌價差', kde=False)\n",
        "\n",
        "## Feature Engineering\n",
        "# ##group = data.groupby(\"company\")\n",
        "# ##list(group)\n",
        "# ##data.groupby(\"company\").agg('mean')\n",
        "# ##data.groupby('company').agg({'salary':'median','age':'mean'})\n",
        "# ##avg_salary_dict = data.groupby('company')['salary'].mean().to_dict()\n",
        "# ​##data['avg_salary'] = data['company'].map(avg_salary_dict)\n",
        "\n",
        "# group1 = stock_df.groupby(\"is_up\").agg({'成交股數':'mean'})\n",
        "# print(group1)\n",
        "\n",
        "# group2 = stock_df.groupby(\"is_up\").agg({'成交金額':'mean'})\n",
        "# print(group2)\n",
        "\n",
        "# # As feature\n",
        "# group3 = stock_df.groupby(\"is_up\").agg({'漲跌價差':'mean'})\n",
        "# print(group3)\n",
        "\n",
        "# # As feature\n",
        "# group4 = stock_df.groupby(\"is_up\").agg({'高低差':'mean'})\n",
        "# print(group4)\n",
        "\n",
        "# # As feature\n",
        "# group5 = stock_df.groupby(\"is_up\").agg({'單筆股數':'mean'})\n",
        "# print(group5)\n",
        "\n",
        "# group6 = stock_df.groupby(\"is_up\").agg({'成交筆數':'mean'})\n",
        "# print(group6)\n",
        "\n",
        "# group7 = stock_df.groupby(\"is_up\").agg({'收盤價':'mean'})\n",
        "# print(group7)\n",
        "# ## data.groupby(\"company\").agg('mean')\n",
        "# ## data.groupby('company').agg({'salary':'median','age':'mean'})\n",
        "# ## avg_salary_dict = data.groupby('company')['salary'].mean().to_dict()\n",
        "# ​## data['avg_salary'] = data['company'].map(avg_salary_dict)\n",
        "# ## Prepare Feature Data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6L5IslyY-A0",
        "outputId": "b46ea7bb-39e7-49da-f782-9ce38ce5e649"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 28466 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36300 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20729 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fe9c8fbab90>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25104 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 37329 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38989 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31558 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 25976 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21934 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 32929 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 39640 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20302 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 24046 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 28466 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36300 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20729 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANg0lEQVR4nO3dbayk5V3H8e+vCwUNNEA9WVdgBQVbeSOYDaBV00CxayVlaygBDG4jZtPEJiUaCy1vamITiEkfYkzMKoRDAqWEtu4GUyvd0lCjLF0Qy8NKWVFwycIuAinE2Lrl74u5oQf2nD1n5+HMNTPfTzKZ+2lm/vdhL37nvuY6152qQpKk1rxt3AVIkrQYA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA6ohSf5p3DUcTpKTktyT5Mnu+cRx16TZMwHt5MNJHkvyWpIN465nkhlQDamqXx13Dcu4DthRVWcCO7p1aVVNQDt5FPgd4L5xFzLpDKiGJHm1e16X5L4kDyd5NMmvL/eabvnSJLd0y7ck+asku5J8L8nFQyjxEmC+W54HNg3hPaUj0no7qardVfXEoO8jOGrcBWhRVwJfr6rPJFkD/GSf73MacC7w88C9Sc6oqv99fWeS44FvL1VDVT3+lm1rq2pft/wcsLbPuqRhaLWdaEgMqDZ9B7g5ydHA31bVw32+z51V9RrwZJKngHcDb7xXVb0CnN3PG1dVJXEiR41T8+1Eg7GLr0FVdR/wG8CzwC1Jfu9why9YPvYw+w5ZT3J81z2y2OOsRT7r+STruteuA/av6ISkEWi4nWhIvIJqUJKfBfZW1V8nOQb4ZeDWJQ5/PskvAk8AHwJeWbDvw0nmgdOBn+uOeUMfvxluBzYDN3TP247gtdJQNdxONCQGVJveC/xJkv8DXgUO95vhdcDdwAFgF3Dcgn3PAA8A7wA+urBfvU83AHcmuRp4GrhswPeTBvFeGmwnST4E/AUwB/xdkoer6v2DvOesiveDmk7dKKW7q+qucdcitcp20ja/g5IkNckrqAmRZCdwzFs2X1VVj4yjHqlFtpPpYkBJkpq0ql18GzduLHpDOH34mIVHX2wnPmbwsahVDagXXnhhNT9Omki2E6nHQRKSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJhlQkqQmOVmspJlw+85nDrv/yvPWr1IlWimvoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNWvEoviRr6N0q+dmqujjJ6cAdwDuBB+ndc+WHoylTh7PY6CRHJEmadEdyBfVxYPeC9RuBz1XVGcBLwNXDLEySNNtWFFBJTgF+G/ibbj3ABcBd3SHzwKZRFChJmk0rvYL6PPAJ4LVu/Z3Ay1V1sFvfC5y82AuTbEmyK8muAwcODFSsNK1sJ9Khlg2oJBcD+6vqwX4+oKq2VtWGqtowNzfXz1tIU892Ih1qJYMk3gN8MMkHgGOBdwBfAE5IclR3FXUK8OzoypQkzZplr6Cq6pNVdUpVnQZcDnyzqn4XuBe4tDtsM7BtZFVKkmbOIH8HdS3wR0n20PtO6qbhlCRJ0hHOZl5V3wK+1S0/BZw7/JIkSXImCUlSowwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTDChJUpMMKElSkwwoSVKTjuh2Gxq/23c+M+4SJGlVeAUlSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlq0rIBleTYJA8k+dckjyX502776Ul2JtmT5EtJ3j76ciVJs2IlV1A/AC6oql8CzgY2JjkfuBH4XFWdAbwEXD26MiVJs2bZgKqeV7vVo7tHARcAd3Xb54FNI6lQkjSTVvQdVJI1SR4G9gP3AP8OvFxVB7tD9gInj6ZESdIsWtFs5lX1I+DsJCcAXwXevdIPSLIF2AKwfv36fmqcSc5aPltsJ4OzzUyfIxrFV1UvA/cCvwKckOT1gDsFeHaJ12ytqg1VtWFubm6gYqVpZTuRDrWSUXxz3ZUTSX4CuAjYTS+oLu0O2wxsG1WRkqTZs5IuvnXAfJI19ALtzqq6O8njwB1J/gz4F+CmEdYpSXbjzZhlA6qqvgucs8j2p4BzR1GUJEnOJCFJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWrSUcsdkORU4FZgLVDA1qr6QpKTgC8BpwH/CVxWVS+NrlRJGo/bdz5z2P1Xnrd+lSqZLSu5gjoI/HFVnQWcD/xhkrOA64AdVXUmsKNblyRpKJYNqKraV1UPdcuvALuBk4FLgPnusHlg06iKlCTNniP6DirJacA5wE5gbVXt63Y9R68LUJKkoVhxQCU5DvgycE1VfX/hvqoqet9PLfa6LUl2Jdl14MCBgYqVppXtRDrUigIqydH0wum2qvpKt/n5JOu6/euA/Yu9tqq2VtWGqtowNzc3jJqlqWM7kQ61bEAlCXATsLuqPrtg13Zgc7e8Gdg2/PIkSbNq2WHmwHuAq4BHkjzcbfsUcANwZ5KrgaeBy0ZTovqx2LBYh8JKS1tuKLlW37IBVVX/CGSJ3RcOtxxJknqcSUKS1CQDSpLUJANKktQkA0qS1CQDSpLUJANKktQkA0qS1CQDSpLUpJXMJKEp4ewSkiaJV1CSpCYZUJKkJhlQkqQmGVCSpCYZUJKkJjmKrwHeh0aabMu1YUfL9scrKElSkwwoSVKTDChJUpP8DkpSM/w+Vgt5BSVJapIBJUlqkgElSWqSASVJapIBJUlqkgElSWrSsgGV5OYk+5M8umDbSUnuSfJk93ziaMuUJM2alVxB3QJsfMu264AdVXUmsKNblyRpaJYNqKq6D3jxLZsvAea75Xlg05DrkiTNuH5nklhbVfu65eeAtUsdmGQLsAVg/frZmtF3sb+Kd1ZjLWaW24m0lIEHSVRVAXWY/VurakNVbZibmxv046SpZDuRDtVvQD2fZB1A97x/eCVJktR/QG0HNnfLm4FtwylHkqSelQwz/yLwz8C7kuxNcjVwA3BRkieB93XrkiQNzbKDJKrqiiV2XTjkWiRJeoP3g1pl3u9Gs8x//zoSTnUkSWqSASVJapIBJUlqkt9BSdKILffdmzPMLM4rKElSkwwoSVKT7OLTolY6HNiuCUmj4hWUJKlJBpQkqUl28c04/7JfUqu8gpIkNcmAkiQ1yYCSJDXJgJIkNcmAkiQ1yYCSJDXJYeZD4FDtN1vs5+GME7PBttCfw/3cZrnteAUlSWqSASVJatJMdvHZBSX1z248rRavoCRJTTKgJElNmskuvsXYbdGfQX9uk9DdutQ5jrPOQW4h7u3HNSkGuoJKsjHJE0n2JLluWEVJktR3QCVZA/wl8FvAWcAVSc4aVmGSpNk2yBXUucCeqnqqqn4I3AFcMpyyJEmzLlXV3wuTS4GNVfUH3fpVwHlV9bG3HLcF2NKtvgt4ov9yB/JTwAtj+uzV4Pm154Wq2riSA20nq2bazw8m8xwXbSsjHyRRVVuBraP+nOUk2VVVG8Zdx6h4fpPNdrI6pv38YLrOcZAuvmeBUxesn9JtkyRpYIME1HeAM5OcnuTtwOXA9uGUJUmadX138VXVwSQfA74OrAFurqrHhlbZ8I29+2TEPD8Nw7T/nKf9/GCKzrHvQRKSJI2SUx1JkppkQEmSmjTVAZXkz5P8W5LvJvlqkhMW7PtkN0XTE0neP846BzFt000lOTXJvUkeT/JYko93209Kck+SJ7vnE8dd6zSxrUyeWWgrU/0dVJLfBL7ZDei4EaCqru2mZPoivdkwfgb4BvALVfWj8VV75Lrppr4HXATspTey8oqqenyshQ0gyTpgXVU9lOR44EFgE/AR4MWquqH7n8uJVXXtGEudKraVyTMLbWWqr6Cq6h+q6mC3ej+9v9WC3pRMd1TVD6rqP4A99BrgpJm66aaqal9VPdQtvwLsBk6md17z3WHz9BqihsS2Mnlmoa1MdUC9xe8DX+uWTwb+a8G+vd22STMt57GoJKcB5wA7gbVVta/b9RywdkxlzQLbyoSZ1rYy8feDSvIN4KcX2XV9VW3rjrkeOAjctpq1qX9JjgO+DFxTVd9P8sa+qqok09s3PSK2lek0zW1l4gOqqt53uP1JPgJcDFxYP/7CbVqmaZqW83iTJEfTa3C3VdVXus3PJ1lXVfu6vvf946twMtlWpuI83mTa28pUd/El2Qh8AvhgVf3Pgl3bgcuTHJPkdOBM4IFx1DigqZtuKr1f/24CdlfVZxfs2g5s7pY3A9tWu7ZpZluZPLPQVqZ9FN8e4Bjgv7tN91fVR7t919Praz9I79L4a4u/S9uSfAD4PD+ebuozYy5pIEl+Dfg28AjwWrf5U/T61u8E1gNPA5dV1YtjKXIK2VYmzyy0lakOKEnS5JrqLj5J0uQyoCRJTTKgJElNMqAkSU0yoCRJTTKgJElNmviZJGZRkk8D59P7uxTo/Xe8f4ltHMn2qvr0qOqWVpttZbIZUJPr8qp6GaC7d881S2xb6tjDbZemiW1lQtnFJ0lqkgElSWqSASVJapIBJUlqkgElSWqSASVJapLDzCfTfuDWJK/fA+ZtwN8vsY0+tkvTwrYywbwflCSpSXbxSZKaZEBJkppkQEmSmmRASZKaZEBJkpr0/5DtaXYkk67oAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## try to implement code, check Fisher Score, but don't finish\n",
        "# data = pd.read_csv('data/data1to21.csv', header=None)\n",
        "\n",
        "# data[52] = data[52].astype(int).data\n",
        "\n",
        "# # # 計算fisher得分\n",
        "# items = list(range(52))\n",
        "\n",
        "# num_classes = len(set(data[52]))\n",
        "\n",
        "# fisher_score = []\n",
        "\n",
        "# grouped = data.groupby([52], as_index=False)\n",
        "\n",
        "# n = [len(data[data[52] == k+1]) for k in range(num_classes)]\n",
        "\n",
        "# for i in items:  # 遍歷所有特徵列\n",
        "#     temp = grouped[i].agg({str(i)+'_mean': 'mean',\n",
        "#                            str(i)+'_std': 'std'})     # 已求出特徵i在各類別k中的均值u_ik、方差p_ik\n",
        "\n",
        "#     numerator = 0\n",
        "#     denominator = 0\n",
        "\n",
        "#     u_i = data[i].mean()\n",
        "\n",
        "#     for k in range(num_classes):\n",
        "#         n_k = n[k]\n",
        "#         u_ik = temp.iloc[k, :][str(i)+'_mean']\n",
        "#         p_ik = temp.iloc[k, :][str(i)+'_std']\n",
        "\n",
        "#         numerator += n_k*(u_ik-u_i)**2\n",
        "#         denominator += n_k*p_ik**2\n",
        "\n",
        "#     fisher_score.append(numerator/denominator)\n",
        "\n",
        "# pd.DataFrame(fisher_score).to_csv('fisher_score.csv', index=False, header=None)"
      ],
      "metadata": {
        "id": "fwRsmXg4GsQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop Day and is_up, to prepare RAW 2230 stock data for Trainng\n",
        "X_data = stock_df.drop(['日期','is_up'], axis=1)\n",
        "X_data.head()\n",
        "X_data.columns"
      ],
      "metadata": {
        "id": "ZLkeXMcLxjrf",
        "outputId": "18236c1e-abec-4632-80b5-2811a0d26140",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數', '高低差',\n",
              "       '單筆股數'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalized 2230 stock data in columns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "scaled = scaler.fit_transform(X_data)\n",
        "X_data = pd.DataFrame(scaled, columns=X_data.columns)\n",
        "#print(X_data)\n",
        "X_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WeNiJCBNQ3x9",
        "outputId": "a6c39814-e7ee-4bab-ef19-e299dd6903df"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       成交股數      成交金額       開盤價       最高價       最低價       收盤價      漲跌價差  \\\n",
              "0  0.082927 -0.068866 -1.148434 -1.014559 -1.091790 -1.007840  1.014957   \n",
              "1 -0.131292 -0.244964 -1.014348 -0.969875 -0.934200 -0.873616  1.014957   \n",
              "2  0.825670  0.634200 -0.589740 -0.679430 -0.799122 -0.717020 -0.907609   \n",
              "3  0.723333  0.592951 -0.612087 -0.344302 -0.528968 -0.359088  1.816026   \n",
              "4  1.163898  1.063469 -0.031045 -0.120883 -0.123736 -0.023526  0.053674   \n",
              "\n",
              "       成交筆數       高低差      單筆股數  \n",
              "0 -0.376955  0.623192  0.722419  \n",
              "1 -0.485475 -0.379268  0.824338  \n",
              "2  0.123314  1.024176  0.204335  \n",
              "3 -0.047396  1.625652  0.521414  \n",
              "4  0.145090  0.021716  0.524245  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c719bcfa-3dc7-41c2-9ab3-d642ff0a90f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>高低差</th>\n",
              "      <th>單筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.082927</td>\n",
              "      <td>-0.068866</td>\n",
              "      <td>-1.148434</td>\n",
              "      <td>-1.014559</td>\n",
              "      <td>-1.091790</td>\n",
              "      <td>-1.007840</td>\n",
              "      <td>1.014957</td>\n",
              "      <td>-0.376955</td>\n",
              "      <td>0.623192</td>\n",
              "      <td>0.722419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.131292</td>\n",
              "      <td>-0.244964</td>\n",
              "      <td>-1.014348</td>\n",
              "      <td>-0.969875</td>\n",
              "      <td>-0.934200</td>\n",
              "      <td>-0.873616</td>\n",
              "      <td>1.014957</td>\n",
              "      <td>-0.485475</td>\n",
              "      <td>-0.379268</td>\n",
              "      <td>0.824338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.825670</td>\n",
              "      <td>0.634200</td>\n",
              "      <td>-0.589740</td>\n",
              "      <td>-0.679430</td>\n",
              "      <td>-0.799122</td>\n",
              "      <td>-0.717020</td>\n",
              "      <td>-0.907609</td>\n",
              "      <td>0.123314</td>\n",
              "      <td>1.024176</td>\n",
              "      <td>0.204335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.723333</td>\n",
              "      <td>0.592951</td>\n",
              "      <td>-0.612087</td>\n",
              "      <td>-0.344302</td>\n",
              "      <td>-0.528968</td>\n",
              "      <td>-0.359088</td>\n",
              "      <td>1.816026</td>\n",
              "      <td>-0.047396</td>\n",
              "      <td>1.625652</td>\n",
              "      <td>0.521414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.163898</td>\n",
              "      <td>1.063469</td>\n",
              "      <td>-0.031045</td>\n",
              "      <td>-0.120883</td>\n",
              "      <td>-0.123736</td>\n",
              "      <td>-0.023526</td>\n",
              "      <td>0.053674</td>\n",
              "      <td>0.145090</td>\n",
              "      <td>0.021716</td>\n",
              "      <td>0.524245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c719bcfa-3dc7-41c2-9ab3-d642ff0a90f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c719bcfa-3dc7-41c2-9ab3-d642ff0a90f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c719bcfa-3dc7-41c2-9ab3-d642ff0a90f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model, with preparing the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# keep one hot Encoding in y for Cross Table\n",
        "y_test_cross = y_test\n",
        "y_test_cross = np.argmax(y_test_cross,axis=1)\n",
        "print(y_test_cross)\n",
        "# print(y_test_cross)\n",
        "\n",
        "X_train = K.cast_to_floatx(X_train)\n",
        "y_train = K.cast_to_floatx(y_train)\n",
        "X_test = K.cast_to_floatx(X_test)\n",
        "y_test = K.cast_to_floatx(y_test)"
      ],
      "metadata": {
        "id": "dSxbm6ltjPHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5e857b-e55d-437e-d086-11e5d9c9358f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "## set up model, and print the model summary\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 128,\n",
        "                input_shape=X_train.shape[1:],\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "\n",
        "model.add(Dense(units = 2,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f98ijyGEjunx",
        "outputId": "23cf0b50-4ae9-49d7-9b12-217415693ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 128)               1408      \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 8)                 1032      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,530\n",
            "Trainable params: 2,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "model.fit(x = X_train,\n",
        "          y = y_train,\n",
        "          validation_split = 0.2,\n",
        "          batch_size=128,\n",
        "          epochs=1000,\n",
        "          verbose = 2) "
      ],
      "metadata": {
        "id": "Kd8QlzjZkAG4",
        "outputId": "03f4af9a-31de-4721-9c97-d4a71ccf131e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "2/2 - 1s - loss: 0.6932 - accuracy: 0.4901 - val_loss: 0.6928 - val_accuracy: 0.5938 - 981ms/epoch - 490ms/step\n",
            "Epoch 2/1000\n",
            "2/2 - 0s - loss: 0.6931 - accuracy: 0.5178 - val_loss: 0.6926 - val_accuracy: 0.5938 - 33ms/epoch - 16ms/step\n",
            "Epoch 3/1000\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5138 - val_loss: 0.6924 - val_accuracy: 0.5938 - 33ms/epoch - 16ms/step\n",
            "Epoch 4/1000\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5938 - 37ms/epoch - 18ms/step\n",
            "Epoch 5/1000\n",
            "2/2 - 0s - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6921 - val_accuracy: 0.5938 - 35ms/epoch - 18ms/step\n",
            "Epoch 6/1000\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5138 - val_loss: 0.6919 - val_accuracy: 0.5938 - 37ms/epoch - 18ms/step\n",
            "Epoch 7/1000\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5138 - val_loss: 0.6918 - val_accuracy: 0.5938 - 32ms/epoch - 16ms/step\n",
            "Epoch 8/1000\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5138 - val_loss: 0.6916 - val_accuracy: 0.5938 - 37ms/epoch - 19ms/step\n",
            "Epoch 9/1000\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5138 - val_loss: 0.6914 - val_accuracy: 0.5938 - 37ms/epoch - 19ms/step\n",
            "Epoch 10/1000\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5138 - val_loss: 0.6913 - val_accuracy: 0.5938 - 39ms/epoch - 19ms/step\n",
            "Epoch 11/1000\n",
            "2/2 - 0s - loss: 0.6926 - accuracy: 0.5178 - val_loss: 0.6912 - val_accuracy: 0.5938 - 35ms/epoch - 17ms/step\n",
            "Epoch 12/1000\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5138 - val_loss: 0.6912 - val_accuracy: 0.5938 - 36ms/epoch - 18ms/step\n",
            "Epoch 13/1000\n",
            "2/2 - 0s - loss: 0.6926 - accuracy: 0.5138 - val_loss: 0.6911 - val_accuracy: 0.5938 - 50ms/epoch - 25ms/step\n",
            "Epoch 14/1000\n",
            "2/2 - 0s - loss: 0.6924 - accuracy: 0.5099 - val_loss: 0.6910 - val_accuracy: 0.5938 - 32ms/epoch - 16ms/step\n",
            "Epoch 15/1000\n",
            "2/2 - 0s - loss: 0.6923 - accuracy: 0.5257 - val_loss: 0.6910 - val_accuracy: 0.5938 - 43ms/epoch - 21ms/step\n",
            "Epoch 16/1000\n",
            "2/2 - 0s - loss: 0.6919 - accuracy: 0.5257 - val_loss: 0.6909 - val_accuracy: 0.5938 - 35ms/epoch - 17ms/step\n",
            "Epoch 17/1000\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5336 - val_loss: 0.6908 - val_accuracy: 0.5938 - 37ms/epoch - 19ms/step\n",
            "Epoch 18/1000\n",
            "2/2 - 0s - loss: 0.6917 - accuracy: 0.5336 - val_loss: 0.6908 - val_accuracy: 0.5625 - 34ms/epoch - 17ms/step\n",
            "Epoch 19/1000\n",
            "2/2 - 0s - loss: 0.6913 - accuracy: 0.5178 - val_loss: 0.6907 - val_accuracy: 0.5625 - 35ms/epoch - 17ms/step\n",
            "Epoch 20/1000\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5375 - val_loss: 0.6907 - val_accuracy: 0.5469 - 41ms/epoch - 21ms/step\n",
            "Epoch 21/1000\n",
            "2/2 - 0s - loss: 0.6910 - accuracy: 0.5494 - val_loss: 0.6906 - val_accuracy: 0.5469 - 36ms/epoch - 18ms/step\n",
            "Epoch 22/1000\n",
            "2/2 - 0s - loss: 0.6907 - accuracy: 0.5494 - val_loss: 0.6905 - val_accuracy: 0.5625 - 33ms/epoch - 17ms/step\n",
            "Epoch 23/1000\n",
            "2/2 - 0s - loss: 0.6900 - accuracy: 0.5336 - val_loss: 0.6905 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 24/1000\n",
            "2/2 - 0s - loss: 0.6895 - accuracy: 0.5534 - val_loss: 0.6905 - val_accuracy: 0.5312 - 38ms/epoch - 19ms/step\n",
            "Epoch 25/1000\n",
            "2/2 - 0s - loss: 0.6888 - accuracy: 0.5494 - val_loss: 0.6905 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 26/1000\n",
            "2/2 - 0s - loss: 0.6879 - accuracy: 0.5613 - val_loss: 0.6905 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 27/1000\n",
            "2/2 - 0s - loss: 0.6875 - accuracy: 0.5731 - val_loss: 0.6905 - val_accuracy: 0.5312 - 37ms/epoch - 18ms/step\n",
            "Epoch 28/1000\n",
            "2/2 - 0s - loss: 0.6871 - accuracy: 0.5850 - val_loss: 0.6906 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 29/1000\n",
            "2/2 - 0s - loss: 0.6864 - accuracy: 0.5573 - val_loss: 0.6907 - val_accuracy: 0.5156 - 43ms/epoch - 21ms/step\n",
            "Epoch 30/1000\n",
            "2/2 - 0s - loss: 0.6842 - accuracy: 0.5652 - val_loss: 0.6908 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 31/1000\n",
            "2/2 - 0s - loss: 0.6854 - accuracy: 0.5534 - val_loss: 0.6909 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 32/1000\n",
            "2/2 - 0s - loss: 0.6835 - accuracy: 0.5810 - val_loss: 0.6911 - val_accuracy: 0.5156 - 31ms/epoch - 15ms/step\n",
            "Epoch 33/1000\n",
            "2/2 - 0s - loss: 0.6829 - accuracy: 0.5731 - val_loss: 0.6914 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 34/1000\n",
            "2/2 - 0s - loss: 0.6832 - accuracy: 0.5731 - val_loss: 0.6916 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 35/1000\n",
            "2/2 - 0s - loss: 0.6791 - accuracy: 0.5889 - val_loss: 0.6918 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 36/1000\n",
            "2/2 - 0s - loss: 0.6771 - accuracy: 0.5613 - val_loss: 0.6922 - val_accuracy: 0.5156 - 43ms/epoch - 21ms/step\n",
            "Epoch 37/1000\n",
            "2/2 - 0s - loss: 0.6810 - accuracy: 0.5613 - val_loss: 0.6925 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 38/1000\n",
            "2/2 - 0s - loss: 0.6769 - accuracy: 0.5810 - val_loss: 0.6929 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 39/1000\n",
            "2/2 - 0s - loss: 0.6719 - accuracy: 0.6087 - val_loss: 0.6935 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 40/1000\n",
            "2/2 - 0s - loss: 0.6753 - accuracy: 0.5652 - val_loss: 0.6943 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 41/1000\n",
            "2/2 - 0s - loss: 0.6763 - accuracy: 0.5968 - val_loss: 0.6953 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 42/1000\n",
            "2/2 - 0s - loss: 0.6746 - accuracy: 0.5613 - val_loss: 0.6962 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 43/1000\n",
            "2/2 - 0s - loss: 0.6742 - accuracy: 0.5652 - val_loss: 0.6974 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 44/1000\n",
            "2/2 - 0s - loss: 0.6657 - accuracy: 0.5850 - val_loss: 0.6987 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 45/1000\n",
            "2/2 - 0s - loss: 0.6643 - accuracy: 0.5692 - val_loss: 0.7000 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 46/1000\n",
            "2/2 - 0s - loss: 0.6669 - accuracy: 0.5534 - val_loss: 0.7014 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 47/1000\n",
            "2/2 - 0s - loss: 0.6568 - accuracy: 0.5889 - val_loss: 0.7032 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 48/1000\n",
            "2/2 - 0s - loss: 0.6679 - accuracy: 0.5731 - val_loss: 0.7047 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 49/1000\n",
            "2/2 - 0s - loss: 0.6636 - accuracy: 0.5810 - val_loss: 0.7066 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 50/1000\n",
            "2/2 - 0s - loss: 0.6683 - accuracy: 0.6008 - val_loss: 0.7081 - val_accuracy: 0.5156 - 56ms/epoch - 28ms/step\n",
            "Epoch 51/1000\n",
            "2/2 - 0s - loss: 0.6623 - accuracy: 0.5652 - val_loss: 0.7096 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 52/1000\n",
            "2/2 - 0s - loss: 0.6603 - accuracy: 0.5850 - val_loss: 0.7109 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 53/1000\n",
            "2/2 - 0s - loss: 0.6630 - accuracy: 0.5968 - val_loss: 0.7124 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 54/1000\n",
            "2/2 - 0s - loss: 0.6699 - accuracy: 0.5731 - val_loss: 0.7133 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 55/1000\n",
            "2/2 - 0s - loss: 0.6607 - accuracy: 0.6087 - val_loss: 0.7139 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 56/1000\n",
            "2/2 - 0s - loss: 0.6555 - accuracy: 0.6126 - val_loss: 0.7146 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 57/1000\n",
            "2/2 - 0s - loss: 0.6580 - accuracy: 0.6087 - val_loss: 0.7157 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 58/1000\n",
            "2/2 - 0s - loss: 0.6478 - accuracy: 0.6245 - val_loss: 0.7171 - val_accuracy: 0.4844 - 55ms/epoch - 28ms/step\n",
            "Epoch 59/1000\n",
            "2/2 - 0s - loss: 0.6514 - accuracy: 0.5929 - val_loss: 0.7193 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 60/1000\n",
            "2/2 - 0s - loss: 0.6630 - accuracy: 0.5929 - val_loss: 0.7203 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 61/1000\n",
            "2/2 - 0s - loss: 0.6546 - accuracy: 0.5810 - val_loss: 0.7212 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 62/1000\n",
            "2/2 - 0s - loss: 0.6505 - accuracy: 0.6008 - val_loss: 0.7224 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 63/1000\n",
            "2/2 - 0s - loss: 0.6480 - accuracy: 0.5968 - val_loss: 0.7234 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 64/1000\n",
            "2/2 - 0s - loss: 0.6526 - accuracy: 0.5889 - val_loss: 0.7240 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 65/1000\n",
            "2/2 - 0s - loss: 0.6626 - accuracy: 0.6047 - val_loss: 0.7241 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 66/1000\n",
            "2/2 - 0s - loss: 0.6520 - accuracy: 0.5771 - val_loss: 0.7245 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 67/1000\n",
            "2/2 - 0s - loss: 0.6509 - accuracy: 0.5850 - val_loss: 0.7250 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 68/1000\n",
            "2/2 - 0s - loss: 0.6603 - accuracy: 0.6087 - val_loss: 0.7254 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 69/1000\n",
            "2/2 - 0s - loss: 0.6507 - accuracy: 0.5929 - val_loss: 0.7259 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 70/1000\n",
            "2/2 - 0s - loss: 0.6597 - accuracy: 0.5534 - val_loss: 0.7257 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 71/1000\n",
            "2/2 - 0s - loss: 0.6528 - accuracy: 0.5889 - val_loss: 0.7259 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 72/1000\n",
            "2/2 - 0s - loss: 0.6633 - accuracy: 0.5850 - val_loss: 0.7257 - val_accuracy: 0.4531 - 33ms/epoch - 16ms/step\n",
            "Epoch 73/1000\n",
            "2/2 - 0s - loss: 0.6595 - accuracy: 0.5889 - val_loss: 0.7248 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 74/1000\n",
            "2/2 - 0s - loss: 0.6564 - accuracy: 0.6087 - val_loss: 0.7242 - val_accuracy: 0.4062 - 35ms/epoch - 18ms/step\n",
            "Epoch 75/1000\n",
            "2/2 - 0s - loss: 0.6444 - accuracy: 0.6482 - val_loss: 0.7244 - val_accuracy: 0.4062 - 33ms/epoch - 17ms/step\n",
            "Epoch 76/1000\n",
            "2/2 - 0s - loss: 0.6351 - accuracy: 0.6166 - val_loss: 0.7251 - val_accuracy: 0.4062 - 37ms/epoch - 18ms/step\n",
            "Epoch 77/1000\n",
            "2/2 - 0s - loss: 0.6470 - accuracy: 0.6206 - val_loss: 0.7250 - val_accuracy: 0.4219 - 42ms/epoch - 21ms/step\n",
            "Epoch 78/1000\n",
            "2/2 - 0s - loss: 0.6534 - accuracy: 0.6008 - val_loss: 0.7254 - val_accuracy: 0.4219 - 35ms/epoch - 18ms/step\n",
            "Epoch 79/1000\n",
            "2/2 - 0s - loss: 0.6393 - accuracy: 0.6245 - val_loss: 0.7257 - val_accuracy: 0.4219 - 57ms/epoch - 28ms/step\n",
            "Epoch 80/1000\n",
            "2/2 - 0s - loss: 0.6433 - accuracy: 0.6364 - val_loss: 0.7262 - val_accuracy: 0.4219 - 36ms/epoch - 18ms/step\n",
            "Epoch 81/1000\n",
            "2/2 - 0s - loss: 0.6402 - accuracy: 0.6285 - val_loss: 0.7270 - val_accuracy: 0.4219 - 36ms/epoch - 18ms/step\n",
            "Epoch 82/1000\n",
            "2/2 - 0s - loss: 0.6620 - accuracy: 0.5850 - val_loss: 0.7274 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 83/1000\n",
            "2/2 - 0s - loss: 0.6504 - accuracy: 0.5692 - val_loss: 0.7279 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 84/1000\n",
            "2/2 - 0s - loss: 0.6480 - accuracy: 0.5968 - val_loss: 0.7287 - val_accuracy: 0.4375 - 31ms/epoch - 15ms/step\n",
            "Epoch 85/1000\n",
            "2/2 - 0s - loss: 0.6402 - accuracy: 0.6166 - val_loss: 0.7304 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 86/1000\n",
            "2/2 - 0s - loss: 0.6520 - accuracy: 0.6126 - val_loss: 0.7310 - val_accuracy: 0.4375 - 38ms/epoch - 19ms/step\n",
            "Epoch 87/1000\n",
            "2/2 - 0s - loss: 0.6293 - accuracy: 0.6126 - val_loss: 0.7322 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 88/1000\n",
            "2/2 - 0s - loss: 0.6368 - accuracy: 0.6245 - val_loss: 0.7338 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 89/1000\n",
            "2/2 - 0s - loss: 0.6536 - accuracy: 0.6008 - val_loss: 0.7348 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 90/1000\n",
            "2/2 - 0s - loss: 0.6628 - accuracy: 0.5613 - val_loss: 0.7355 - val_accuracy: 0.4375 - 31ms/epoch - 16ms/step\n",
            "Epoch 91/1000\n",
            "2/2 - 0s - loss: 0.6214 - accuracy: 0.6482 - val_loss: 0.7366 - val_accuracy: 0.4531 - 30ms/epoch - 15ms/step\n",
            "Epoch 92/1000\n",
            "2/2 - 0s - loss: 0.6402 - accuracy: 0.6126 - val_loss: 0.7372 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 93/1000\n",
            "2/2 - 0s - loss: 0.6499 - accuracy: 0.5771 - val_loss: 0.7374 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 94/1000\n",
            "2/2 - 0s - loss: 0.6430 - accuracy: 0.5929 - val_loss: 0.7377 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 95/1000\n",
            "2/2 - 0s - loss: 0.6532 - accuracy: 0.5968 - val_loss: 0.7377 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 96/1000\n",
            "2/2 - 0s - loss: 0.6308 - accuracy: 0.6245 - val_loss: 0.7387 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 97/1000\n",
            "2/2 - 0s - loss: 0.6418 - accuracy: 0.6087 - val_loss: 0.7409 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 98/1000\n",
            "2/2 - 0s - loss: 0.6436 - accuracy: 0.6047 - val_loss: 0.7418 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 99/1000\n",
            "2/2 - 0s - loss: 0.6245 - accuracy: 0.6601 - val_loss: 0.7423 - val_accuracy: 0.4531 - 42ms/epoch - 21ms/step\n",
            "Epoch 100/1000\n",
            "2/2 - 0s - loss: 0.6365 - accuracy: 0.6166 - val_loss: 0.7422 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 101/1000\n",
            "2/2 - 0s - loss: 0.6463 - accuracy: 0.5968 - val_loss: 0.7421 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 102/1000\n",
            "2/2 - 0s - loss: 0.6325 - accuracy: 0.6087 - val_loss: 0.7418 - val_accuracy: 0.4531 - 41ms/epoch - 21ms/step\n",
            "Epoch 103/1000\n",
            "2/2 - 0s - loss: 0.6252 - accuracy: 0.6838 - val_loss: 0.7425 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 104/1000\n",
            "2/2 - 0s - loss: 0.6493 - accuracy: 0.5929 - val_loss: 0.7432 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 105/1000\n",
            "2/2 - 0s - loss: 0.6282 - accuracy: 0.6285 - val_loss: 0.7447 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 106/1000\n",
            "2/2 - 0s - loss: 0.6445 - accuracy: 0.6087 - val_loss: 0.7452 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 107/1000\n",
            "2/2 - 0s - loss: 0.6391 - accuracy: 0.6364 - val_loss: 0.7442 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 108/1000\n",
            "2/2 - 0s - loss: 0.6353 - accuracy: 0.6522 - val_loss: 0.7451 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 109/1000\n",
            "2/2 - 0s - loss: 0.6499 - accuracy: 0.6166 - val_loss: 0.7456 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 110/1000\n",
            "2/2 - 0s - loss: 0.6388 - accuracy: 0.6166 - val_loss: 0.7459 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 111/1000\n",
            "2/2 - 0s - loss: 0.6422 - accuracy: 0.6364 - val_loss: 0.7474 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 112/1000\n",
            "2/2 - 0s - loss: 0.6222 - accuracy: 0.6126 - val_loss: 0.7487 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 113/1000\n",
            "2/2 - 0s - loss: 0.6219 - accuracy: 0.6680 - val_loss: 0.7495 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 114/1000\n",
            "2/2 - 0s - loss: 0.6405 - accuracy: 0.5810 - val_loss: 0.7507 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 115/1000\n",
            "2/2 - 0s - loss: 0.6282 - accuracy: 0.6364 - val_loss: 0.7519 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 116/1000\n",
            "2/2 - 0s - loss: 0.6333 - accuracy: 0.6324 - val_loss: 0.7528 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 117/1000\n",
            "2/2 - 0s - loss: 0.6419 - accuracy: 0.6285 - val_loss: 0.7526 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 118/1000\n",
            "2/2 - 0s - loss: 0.6282 - accuracy: 0.6680 - val_loss: 0.7526 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 119/1000\n",
            "2/2 - 0s - loss: 0.6498 - accuracy: 0.6087 - val_loss: 0.7528 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 120/1000\n",
            "2/2 - 0s - loss: 0.6394 - accuracy: 0.6561 - val_loss: 0.7526 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 121/1000\n",
            "2/2 - 0s - loss: 0.6205 - accuracy: 0.6601 - val_loss: 0.7525 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 122/1000\n",
            "2/2 - 0s - loss: 0.6420 - accuracy: 0.6087 - val_loss: 0.7516 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 123/1000\n",
            "2/2 - 0s - loss: 0.6204 - accuracy: 0.6245 - val_loss: 0.7507 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 124/1000\n",
            "2/2 - 0s - loss: 0.6286 - accuracy: 0.6206 - val_loss: 0.7505 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 125/1000\n",
            "2/2 - 0s - loss: 0.6360 - accuracy: 0.6166 - val_loss: 0.7504 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 126/1000\n",
            "2/2 - 0s - loss: 0.6234 - accuracy: 0.6245 - val_loss: 0.7507 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 127/1000\n",
            "2/2 - 0s - loss: 0.6429 - accuracy: 0.6403 - val_loss: 0.7526 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 128/1000\n",
            "2/2 - 0s - loss: 0.6244 - accuracy: 0.6798 - val_loss: 0.7541 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 129/1000\n",
            "2/2 - 0s - loss: 0.6438 - accuracy: 0.6285 - val_loss: 0.7558 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 130/1000\n",
            "2/2 - 0s - loss: 0.6536 - accuracy: 0.6206 - val_loss: 0.7571 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 131/1000\n",
            "2/2 - 0s - loss: 0.6414 - accuracy: 0.6482 - val_loss: 0.7575 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 132/1000\n",
            "2/2 - 0s - loss: 0.6267 - accuracy: 0.6443 - val_loss: 0.7587 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 133/1000\n",
            "2/2 - 0s - loss: 0.6352 - accuracy: 0.6364 - val_loss: 0.7589 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 134/1000\n",
            "2/2 - 0s - loss: 0.6262 - accuracy: 0.6561 - val_loss: 0.7591 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 135/1000\n",
            "2/2 - 0s - loss: 0.6322 - accuracy: 0.6403 - val_loss: 0.7606 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 136/1000\n",
            "2/2 - 0s - loss: 0.6294 - accuracy: 0.6364 - val_loss: 0.7600 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 137/1000\n",
            "2/2 - 0s - loss: 0.6247 - accuracy: 0.6640 - val_loss: 0.7589 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 138/1000\n",
            "2/2 - 0s - loss: 0.6251 - accuracy: 0.6245 - val_loss: 0.7577 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 139/1000\n",
            "2/2 - 0s - loss: 0.6100 - accuracy: 0.6561 - val_loss: 0.7563 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 140/1000\n",
            "2/2 - 0s - loss: 0.6359 - accuracy: 0.6561 - val_loss: 0.7552 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 141/1000\n",
            "2/2 - 0s - loss: 0.6294 - accuracy: 0.6522 - val_loss: 0.7550 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 142/1000\n",
            "2/2 - 0s - loss: 0.6311 - accuracy: 0.6601 - val_loss: 0.7549 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 143/1000\n",
            "2/2 - 0s - loss: 0.6420 - accuracy: 0.6403 - val_loss: 0.7543 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 144/1000\n",
            "2/2 - 0s - loss: 0.6424 - accuracy: 0.6522 - val_loss: 0.7543 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 145/1000\n",
            "2/2 - 0s - loss: 0.6302 - accuracy: 0.6403 - val_loss: 0.7537 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 146/1000\n",
            "2/2 - 0s - loss: 0.6285 - accuracy: 0.6166 - val_loss: 0.7548 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 147/1000\n",
            "2/2 - 0s - loss: 0.6317 - accuracy: 0.6047 - val_loss: 0.7568 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 148/1000\n",
            "2/2 - 0s - loss: 0.6201 - accuracy: 0.6601 - val_loss: 0.7582 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 149/1000\n",
            "2/2 - 0s - loss: 0.6103 - accuracy: 0.6957 - val_loss: 0.7604 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 150/1000\n",
            "2/2 - 0s - loss: 0.6325 - accuracy: 0.6601 - val_loss: 0.7619 - val_accuracy: 0.4531 - 31ms/epoch - 15ms/step\n",
            "Epoch 151/1000\n",
            "2/2 - 0s - loss: 0.6316 - accuracy: 0.6443 - val_loss: 0.7630 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 152/1000\n",
            "2/2 - 0s - loss: 0.6470 - accuracy: 0.5889 - val_loss: 0.7630 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 153/1000\n",
            "2/2 - 0s - loss: 0.6263 - accuracy: 0.6324 - val_loss: 0.7626 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 154/1000\n",
            "2/2 - 0s - loss: 0.6151 - accuracy: 0.6798 - val_loss: 0.7627 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 155/1000\n",
            "2/2 - 0s - loss: 0.6314 - accuracy: 0.6324 - val_loss: 0.7613 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 156/1000\n",
            "2/2 - 0s - loss: 0.6268 - accuracy: 0.6522 - val_loss: 0.7595 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 157/1000\n",
            "2/2 - 0s - loss: 0.6189 - accuracy: 0.6759 - val_loss: 0.7587 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 158/1000\n",
            "2/2 - 0s - loss: 0.6283 - accuracy: 0.6206 - val_loss: 0.7593 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 159/1000\n",
            "2/2 - 0s - loss: 0.6252 - accuracy: 0.6482 - val_loss: 0.7602 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 160/1000\n",
            "2/2 - 0s - loss: 0.6370 - accuracy: 0.6403 - val_loss: 0.7603 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 161/1000\n",
            "2/2 - 0s - loss: 0.6373 - accuracy: 0.6047 - val_loss: 0.7603 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 162/1000\n",
            "2/2 - 0s - loss: 0.6436 - accuracy: 0.6245 - val_loss: 0.7596 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 163/1000\n",
            "2/2 - 0s - loss: 0.6228 - accuracy: 0.6522 - val_loss: 0.7593 - val_accuracy: 0.4688 - 30ms/epoch - 15ms/step\n",
            "Epoch 164/1000\n",
            "2/2 - 0s - loss: 0.6310 - accuracy: 0.6364 - val_loss: 0.7597 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 165/1000\n",
            "2/2 - 0s - loss: 0.6576 - accuracy: 0.6166 - val_loss: 0.7591 - val_accuracy: 0.4688 - 45ms/epoch - 22ms/step\n",
            "Epoch 166/1000\n",
            "2/2 - 0s - loss: 0.6315 - accuracy: 0.6285 - val_loss: 0.7592 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 167/1000\n",
            "2/2 - 0s - loss: 0.6112 - accuracy: 0.6680 - val_loss: 0.7608 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 168/1000\n",
            "2/2 - 0s - loss: 0.6311 - accuracy: 0.6245 - val_loss: 0.7612 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 169/1000\n",
            "2/2 - 0s - loss: 0.6344 - accuracy: 0.6364 - val_loss: 0.7610 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 170/1000\n",
            "2/2 - 0s - loss: 0.5978 - accuracy: 0.6798 - val_loss: 0.7608 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 171/1000\n",
            "2/2 - 0s - loss: 0.6449 - accuracy: 0.6206 - val_loss: 0.7604 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 172/1000\n",
            "2/2 - 0s - loss: 0.6267 - accuracy: 0.6759 - val_loss: 0.7599 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 173/1000\n",
            "2/2 - 0s - loss: 0.6312 - accuracy: 0.6482 - val_loss: 0.7601 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 174/1000\n",
            "2/2 - 0s - loss: 0.6364 - accuracy: 0.6324 - val_loss: 0.7598 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 175/1000\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6759 - val_loss: 0.7600 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 176/1000\n",
            "2/2 - 0s - loss: 0.6279 - accuracy: 0.6443 - val_loss: 0.7614 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 177/1000\n",
            "2/2 - 0s - loss: 0.6204 - accuracy: 0.6601 - val_loss: 0.7618 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 178/1000\n",
            "2/2 - 0s - loss: 0.6325 - accuracy: 0.6640 - val_loss: 0.7623 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 179/1000\n",
            "2/2 - 0s - loss: 0.6193 - accuracy: 0.6561 - val_loss: 0.7627 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 180/1000\n",
            "2/2 - 0s - loss: 0.6012 - accuracy: 0.6917 - val_loss: 0.7638 - val_accuracy: 0.4844 - 57ms/epoch - 29ms/step\n",
            "Epoch 181/1000\n",
            "2/2 - 0s - loss: 0.6259 - accuracy: 0.6443 - val_loss: 0.7653 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 182/1000\n",
            "2/2 - 0s - loss: 0.6146 - accuracy: 0.6522 - val_loss: 0.7668 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 183/1000\n",
            "2/2 - 0s - loss: 0.6271 - accuracy: 0.6324 - val_loss: 0.7690 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 184/1000\n",
            "2/2 - 0s - loss: 0.6038 - accuracy: 0.7075 - val_loss: 0.7706 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
            "Epoch 185/1000\n",
            "2/2 - 0s - loss: 0.6162 - accuracy: 0.6680 - val_loss: 0.7715 - val_accuracy: 0.5000 - 56ms/epoch - 28ms/step\n",
            "Epoch 186/1000\n",
            "2/2 - 0s - loss: 0.6106 - accuracy: 0.6719 - val_loss: 0.7721 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 187/1000\n",
            "2/2 - 0s - loss: 0.6183 - accuracy: 0.6640 - val_loss: 0.7724 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 188/1000\n",
            "2/2 - 0s - loss: 0.6275 - accuracy: 0.6601 - val_loss: 0.7721 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 189/1000\n",
            "2/2 - 0s - loss: 0.6052 - accuracy: 0.6680 - val_loss: 0.7724 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 190/1000\n",
            "2/2 - 0s - loss: 0.6211 - accuracy: 0.6877 - val_loss: 0.7723 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 191/1000\n",
            "2/2 - 0s - loss: 0.6263 - accuracy: 0.6640 - val_loss: 0.7713 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 192/1000\n",
            "2/2 - 0s - loss: 0.6103 - accuracy: 0.6759 - val_loss: 0.7701 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 193/1000\n",
            "2/2 - 0s - loss: 0.5932 - accuracy: 0.6640 - val_loss: 0.7708 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 194/1000\n",
            "2/2 - 0s - loss: 0.6131 - accuracy: 0.6759 - val_loss: 0.7724 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 195/1000\n",
            "2/2 - 0s - loss: 0.6440 - accuracy: 0.6087 - val_loss: 0.7727 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 196/1000\n",
            "2/2 - 0s - loss: 0.6224 - accuracy: 0.6443 - val_loss: 0.7716 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 197/1000\n",
            "2/2 - 0s - loss: 0.6245 - accuracy: 0.6522 - val_loss: 0.7701 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 198/1000\n",
            "2/2 - 0s - loss: 0.6108 - accuracy: 0.6601 - val_loss: 0.7701 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 199/1000\n",
            "2/2 - 0s - loss: 0.6107 - accuracy: 0.6640 - val_loss: 0.7697 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 200/1000\n",
            "2/2 - 0s - loss: 0.6194 - accuracy: 0.6443 - val_loss: 0.7685 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 201/1000\n",
            "2/2 - 0s - loss: 0.6168 - accuracy: 0.6680 - val_loss: 0.7687 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 202/1000\n",
            "2/2 - 0s - loss: 0.6245 - accuracy: 0.6364 - val_loss: 0.7702 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 203/1000\n",
            "2/2 - 0s - loss: 0.6200 - accuracy: 0.6364 - val_loss: 0.7715 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 204/1000\n",
            "2/2 - 0s - loss: 0.6129 - accuracy: 0.6601 - val_loss: 0.7741 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 205/1000\n",
            "2/2 - 0s - loss: 0.6181 - accuracy: 0.6482 - val_loss: 0.7753 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 206/1000\n",
            "2/2 - 0s - loss: 0.6179 - accuracy: 0.6364 - val_loss: 0.7761 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 207/1000\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6996 - val_loss: 0.7775 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 208/1000\n",
            "2/2 - 0s - loss: 0.6097 - accuracy: 0.6640 - val_loss: 0.7792 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 209/1000\n",
            "2/2 - 0s - loss: 0.6286 - accuracy: 0.6324 - val_loss: 0.7812 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 210/1000\n",
            "2/2 - 0s - loss: 0.6339 - accuracy: 0.5929 - val_loss: 0.7800 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 211/1000\n",
            "2/2 - 0s - loss: 0.6113 - accuracy: 0.6601 - val_loss: 0.7794 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 212/1000\n",
            "2/2 - 0s - loss: 0.6093 - accuracy: 0.6324 - val_loss: 0.7789 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 213/1000\n",
            "2/2 - 0s - loss: 0.6153 - accuracy: 0.6917 - val_loss: 0.7787 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 214/1000\n",
            "2/2 - 0s - loss: 0.6040 - accuracy: 0.6957 - val_loss: 0.7773 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 215/1000\n",
            "2/2 - 0s - loss: 0.6100 - accuracy: 0.6640 - val_loss: 0.7765 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 216/1000\n",
            "2/2 - 0s - loss: 0.6160 - accuracy: 0.6601 - val_loss: 0.7756 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 217/1000\n",
            "2/2 - 0s - loss: 0.5883 - accuracy: 0.7075 - val_loss: 0.7759 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 218/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6680 - val_loss: 0.7770 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 219/1000\n",
            "2/2 - 0s - loss: 0.6134 - accuracy: 0.6601 - val_loss: 0.7766 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 220/1000\n",
            "2/2 - 0s - loss: 0.6179 - accuracy: 0.6522 - val_loss: 0.7786 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 221/1000\n",
            "2/2 - 0s - loss: 0.6232 - accuracy: 0.6759 - val_loss: 0.7802 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 222/1000\n",
            "2/2 - 0s - loss: 0.6073 - accuracy: 0.6680 - val_loss: 0.7816 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 223/1000\n",
            "2/2 - 0s - loss: 0.6263 - accuracy: 0.6522 - val_loss: 0.7817 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 224/1000\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6482 - val_loss: 0.7806 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 225/1000\n",
            "2/2 - 0s - loss: 0.6221 - accuracy: 0.6324 - val_loss: 0.7803 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 226/1000\n",
            "2/2 - 0s - loss: 0.6179 - accuracy: 0.6680 - val_loss: 0.7793 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 227/1000\n",
            "2/2 - 0s - loss: 0.6201 - accuracy: 0.6640 - val_loss: 0.7770 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 228/1000\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6798 - val_loss: 0.7757 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 229/1000\n",
            "2/2 - 0s - loss: 0.6266 - accuracy: 0.6443 - val_loss: 0.7740 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 230/1000\n",
            "2/2 - 0s - loss: 0.6091 - accuracy: 0.6522 - val_loss: 0.7731 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 231/1000\n",
            "2/2 - 0s - loss: 0.5968 - accuracy: 0.6759 - val_loss: 0.7726 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 232/1000\n",
            "2/2 - 0s - loss: 0.6218 - accuracy: 0.6601 - val_loss: 0.7735 - val_accuracy: 0.5000 - 50ms/epoch - 25ms/step\n",
            "Epoch 233/1000\n",
            "2/2 - 0s - loss: 0.6147 - accuracy: 0.6206 - val_loss: 0.7744 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 234/1000\n",
            "2/2 - 0s - loss: 0.6105 - accuracy: 0.6561 - val_loss: 0.7750 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 235/1000\n",
            "2/2 - 0s - loss: 0.6209 - accuracy: 0.6522 - val_loss: 0.7761 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 236/1000\n",
            "2/2 - 0s - loss: 0.5923 - accuracy: 0.7154 - val_loss: 0.7781 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 237/1000\n",
            "2/2 - 0s - loss: 0.6054 - accuracy: 0.6443 - val_loss: 0.7804 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 238/1000\n",
            "2/2 - 0s - loss: 0.6166 - accuracy: 0.6482 - val_loss: 0.7821 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 239/1000\n",
            "2/2 - 0s - loss: 0.6136 - accuracy: 0.6680 - val_loss: 0.7831 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 240/1000\n",
            "2/2 - 0s - loss: 0.6067 - accuracy: 0.6759 - val_loss: 0.7848 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 241/1000\n",
            "2/2 - 0s - loss: 0.6163 - accuracy: 0.6522 - val_loss: 0.7851 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 242/1000\n",
            "2/2 - 0s - loss: 0.6088 - accuracy: 0.6285 - val_loss: 0.7847 - val_accuracy: 0.5000 - 51ms/epoch - 25ms/step\n",
            "Epoch 243/1000\n",
            "2/2 - 0s - loss: 0.6116 - accuracy: 0.6957 - val_loss: 0.7841 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 244/1000\n",
            "2/2 - 0s - loss: 0.5938 - accuracy: 0.6877 - val_loss: 0.7830 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 245/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.6680 - val_loss: 0.7836 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 246/1000\n",
            "2/2 - 0s - loss: 0.6131 - accuracy: 0.6443 - val_loss: 0.7838 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 247/1000\n",
            "2/2 - 0s - loss: 0.6119 - accuracy: 0.6561 - val_loss: 0.7843 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 248/1000\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6680 - val_loss: 0.7842 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 249/1000\n",
            "2/2 - 0s - loss: 0.6228 - accuracy: 0.6443 - val_loss: 0.7834 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 250/1000\n",
            "2/2 - 0s - loss: 0.6143 - accuracy: 0.6561 - val_loss: 0.7827 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 251/1000\n",
            "2/2 - 0s - loss: 0.6167 - accuracy: 0.6601 - val_loss: 0.7802 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 252/1000\n",
            "2/2 - 0s - loss: 0.6158 - accuracy: 0.6798 - val_loss: 0.7785 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 253/1000\n",
            "2/2 - 0s - loss: 0.6262 - accuracy: 0.6680 - val_loss: 0.7775 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 254/1000\n",
            "2/2 - 0s - loss: 0.6267 - accuracy: 0.6522 - val_loss: 0.7771 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 255/1000\n",
            "2/2 - 0s - loss: 0.6001 - accuracy: 0.6561 - val_loss: 0.7779 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 256/1000\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6957 - val_loss: 0.7796 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 257/1000\n",
            "2/2 - 0s - loss: 0.6122 - accuracy: 0.6719 - val_loss: 0.7797 - val_accuracy: 0.4688 - 48ms/epoch - 24ms/step\n",
            "Epoch 258/1000\n",
            "2/2 - 0s - loss: 0.6019 - accuracy: 0.6561 - val_loss: 0.7811 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 259/1000\n",
            "2/2 - 0s - loss: 0.5952 - accuracy: 0.6798 - val_loss: 0.7816 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 260/1000\n",
            "2/2 - 0s - loss: 0.5963 - accuracy: 0.6877 - val_loss: 0.7832 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 261/1000\n",
            "2/2 - 0s - loss: 0.6090 - accuracy: 0.6759 - val_loss: 0.7841 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 262/1000\n",
            "2/2 - 0s - loss: 0.5910 - accuracy: 0.6877 - val_loss: 0.7861 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 263/1000\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6877 - val_loss: 0.7887 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 264/1000\n",
            "2/2 - 0s - loss: 0.6153 - accuracy: 0.6561 - val_loss: 0.7918 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 265/1000\n",
            "2/2 - 0s - loss: 0.6148 - accuracy: 0.6877 - val_loss: 0.7943 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 266/1000\n",
            "2/2 - 0s - loss: 0.6146 - accuracy: 0.6403 - val_loss: 0.7966 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 267/1000\n",
            "2/2 - 0s - loss: 0.6138 - accuracy: 0.6640 - val_loss: 0.7983 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 268/1000\n",
            "2/2 - 0s - loss: 0.6105 - accuracy: 0.6561 - val_loss: 0.7994 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
            "Epoch 269/1000\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6680 - val_loss: 0.7989 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 270/1000\n",
            "2/2 - 0s - loss: 0.6329 - accuracy: 0.6561 - val_loss: 0.7968 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 271/1000\n",
            "2/2 - 0s - loss: 0.6250 - accuracy: 0.6364 - val_loss: 0.7936 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 272/1000\n",
            "2/2 - 0s - loss: 0.6075 - accuracy: 0.6601 - val_loss: 0.7903 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 273/1000\n",
            "2/2 - 0s - loss: 0.6073 - accuracy: 0.6443 - val_loss: 0.7886 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 274/1000\n",
            "2/2 - 0s - loss: 0.6061 - accuracy: 0.6877 - val_loss: 0.7861 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 275/1000\n",
            "2/2 - 0s - loss: 0.6143 - accuracy: 0.6917 - val_loss: 0.7836 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 276/1000\n",
            "2/2 - 0s - loss: 0.5992 - accuracy: 0.6759 - val_loss: 0.7809 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 277/1000\n",
            "2/2 - 0s - loss: 0.6188 - accuracy: 0.6443 - val_loss: 0.7784 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 278/1000\n",
            "2/2 - 0s - loss: 0.5991 - accuracy: 0.6957 - val_loss: 0.7781 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 279/1000\n",
            "2/2 - 0s - loss: 0.6189 - accuracy: 0.6561 - val_loss: 0.7794 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 280/1000\n",
            "2/2 - 0s - loss: 0.5847 - accuracy: 0.6996 - val_loss: 0.7802 - val_accuracy: 0.4844 - 30ms/epoch - 15ms/step\n",
            "Epoch 281/1000\n",
            "2/2 - 0s - loss: 0.5935 - accuracy: 0.7075 - val_loss: 0.7818 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 282/1000\n",
            "2/2 - 0s - loss: 0.6126 - accuracy: 0.6482 - val_loss: 0.7822 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 283/1000\n",
            "2/2 - 0s - loss: 0.6004 - accuracy: 0.6719 - val_loss: 0.7850 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 284/1000\n",
            "2/2 - 0s - loss: 0.6122 - accuracy: 0.6482 - val_loss: 0.7876 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 285/1000\n",
            "2/2 - 0s - loss: 0.6017 - accuracy: 0.6561 - val_loss: 0.7913 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 286/1000\n",
            "2/2 - 0s - loss: 0.6135 - accuracy: 0.6601 - val_loss: 0.7914 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 287/1000\n",
            "2/2 - 0s - loss: 0.6093 - accuracy: 0.6680 - val_loss: 0.7922 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 288/1000\n",
            "2/2 - 0s - loss: 0.6051 - accuracy: 0.6482 - val_loss: 0.7924 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 289/1000\n",
            "2/2 - 0s - loss: 0.6102 - accuracy: 0.6838 - val_loss: 0.7928 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 290/1000\n",
            "2/2 - 0s - loss: 0.6232 - accuracy: 0.6561 - val_loss: 0.7924 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 291/1000\n",
            "2/2 - 0s - loss: 0.6075 - accuracy: 0.6561 - val_loss: 0.7905 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 292/1000\n",
            "2/2 - 0s - loss: 0.5856 - accuracy: 0.7075 - val_loss: 0.7883 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 293/1000\n",
            "2/2 - 0s - loss: 0.6075 - accuracy: 0.6403 - val_loss: 0.7871 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 294/1000\n",
            "2/2 - 0s - loss: 0.5886 - accuracy: 0.6877 - val_loss: 0.7862 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 295/1000\n",
            "2/2 - 0s - loss: 0.5982 - accuracy: 0.6719 - val_loss: 0.7867 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 296/1000\n",
            "2/2 - 0s - loss: 0.6186 - accuracy: 0.6403 - val_loss: 0.7881 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 297/1000\n",
            "2/2 - 0s - loss: 0.6154 - accuracy: 0.6561 - val_loss: 0.7893 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 298/1000\n",
            "2/2 - 0s - loss: 0.6076 - accuracy: 0.6719 - val_loss: 0.7898 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 299/1000\n",
            "2/2 - 0s - loss: 0.5892 - accuracy: 0.6759 - val_loss: 0.7911 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 300/1000\n",
            "2/2 - 0s - loss: 0.5896 - accuracy: 0.6680 - val_loss: 0.7912 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 301/1000\n",
            "2/2 - 0s - loss: 0.5912 - accuracy: 0.7194 - val_loss: 0.7933 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 302/1000\n",
            "2/2 - 0s - loss: 0.6022 - accuracy: 0.6601 - val_loss: 0.7948 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 303/1000\n",
            "2/2 - 0s - loss: 0.5991 - accuracy: 0.6996 - val_loss: 0.7957 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 304/1000\n",
            "2/2 - 0s - loss: 0.6146 - accuracy: 0.6522 - val_loss: 0.7968 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 305/1000\n",
            "2/2 - 0s - loss: 0.6331 - accuracy: 0.6561 - val_loss: 0.7972 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 306/1000\n",
            "2/2 - 0s - loss: 0.6199 - accuracy: 0.6324 - val_loss: 0.7969 - val_accuracy: 0.4844 - 47ms/epoch - 24ms/step\n",
            "Epoch 307/1000\n",
            "2/2 - 0s - loss: 0.5890 - accuracy: 0.6759 - val_loss: 0.7956 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 308/1000\n",
            "2/2 - 0s - loss: 0.6197 - accuracy: 0.6640 - val_loss: 0.7930 - val_accuracy: 0.4844 - 43ms/epoch - 21ms/step\n",
            "Epoch 309/1000\n",
            "2/2 - 0s - loss: 0.5835 - accuracy: 0.6957 - val_loss: 0.7913 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 310/1000\n",
            "2/2 - 0s - loss: 0.6028 - accuracy: 0.6917 - val_loss: 0.7901 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 311/1000\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.6877 - val_loss: 0.7903 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 312/1000\n",
            "2/2 - 0s - loss: 0.5951 - accuracy: 0.6561 - val_loss: 0.7923 - val_accuracy: 0.5156 - 31ms/epoch - 15ms/step\n",
            "Epoch 313/1000\n",
            "2/2 - 0s - loss: 0.6290 - accuracy: 0.6324 - val_loss: 0.7925 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 314/1000\n",
            "2/2 - 0s - loss: 0.6058 - accuracy: 0.6957 - val_loss: 0.7929 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 315/1000\n",
            "2/2 - 0s - loss: 0.6008 - accuracy: 0.6561 - val_loss: 0.7916 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 316/1000\n",
            "2/2 - 0s - loss: 0.5922 - accuracy: 0.6561 - val_loss: 0.7904 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 317/1000\n",
            "2/2 - 0s - loss: 0.5892 - accuracy: 0.7075 - val_loss: 0.7910 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 318/1000\n",
            "2/2 - 0s - loss: 0.6033 - accuracy: 0.6798 - val_loss: 0.7912 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 319/1000\n",
            "2/2 - 0s - loss: 0.6084 - accuracy: 0.6877 - val_loss: 0.7914 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 320/1000\n",
            "2/2 - 0s - loss: 0.6095 - accuracy: 0.6877 - val_loss: 0.7917 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 321/1000\n",
            "2/2 - 0s - loss: 0.6191 - accuracy: 0.6443 - val_loss: 0.7909 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 322/1000\n",
            "2/2 - 0s - loss: 0.5917 - accuracy: 0.6719 - val_loss: 0.7905 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 323/1000\n",
            "2/2 - 0s - loss: 0.6105 - accuracy: 0.6759 - val_loss: 0.7902 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 324/1000\n",
            "2/2 - 0s - loss: 0.5948 - accuracy: 0.6759 - val_loss: 0.7900 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 325/1000\n",
            "2/2 - 0s - loss: 0.5936 - accuracy: 0.6877 - val_loss: 0.7915 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 326/1000\n",
            "2/2 - 0s - loss: 0.5859 - accuracy: 0.6957 - val_loss: 0.7925 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 327/1000\n",
            "2/2 - 0s - loss: 0.6020 - accuracy: 0.6719 - val_loss: 0.7920 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 328/1000\n",
            "2/2 - 0s - loss: 0.6040 - accuracy: 0.6522 - val_loss: 0.7927 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 329/1000\n",
            "2/2 - 0s - loss: 0.6077 - accuracy: 0.6838 - val_loss: 0.7909 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 330/1000\n",
            "2/2 - 0s - loss: 0.6076 - accuracy: 0.6759 - val_loss: 0.7903 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 331/1000\n",
            "2/2 - 0s - loss: 0.5893 - accuracy: 0.6601 - val_loss: 0.7908 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 332/1000\n",
            "2/2 - 0s - loss: 0.5967 - accuracy: 0.6798 - val_loss: 0.7923 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 333/1000\n",
            "2/2 - 0s - loss: 0.5805 - accuracy: 0.6996 - val_loss: 0.7934 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 334/1000\n",
            "2/2 - 0s - loss: 0.5948 - accuracy: 0.6601 - val_loss: 0.7953 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 335/1000\n",
            "2/2 - 0s - loss: 0.6317 - accuracy: 0.6443 - val_loss: 0.7962 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 336/1000\n",
            "2/2 - 0s - loss: 0.5863 - accuracy: 0.6877 - val_loss: 0.7966 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 337/1000\n",
            "2/2 - 0s - loss: 0.6114 - accuracy: 0.6719 - val_loss: 0.7970 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 338/1000\n",
            "2/2 - 0s - loss: 0.5985 - accuracy: 0.6838 - val_loss: 0.7966 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 339/1000\n",
            "2/2 - 0s - loss: 0.5966 - accuracy: 0.6561 - val_loss: 0.7970 - val_accuracy: 0.5000 - 45ms/epoch - 23ms/step\n",
            "Epoch 340/1000\n",
            "2/2 - 0s - loss: 0.6087 - accuracy: 0.6561 - val_loss: 0.7962 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 341/1000\n",
            "2/2 - 0s - loss: 0.6090 - accuracy: 0.6798 - val_loss: 0.7955 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 342/1000\n",
            "2/2 - 0s - loss: 0.5912 - accuracy: 0.6601 - val_loss: 0.7959 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 343/1000\n",
            "2/2 - 0s - loss: 0.5799 - accuracy: 0.6838 - val_loss: 0.7983 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 344/1000\n",
            "2/2 - 0s - loss: 0.6015 - accuracy: 0.6403 - val_loss: 0.7996 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 345/1000\n",
            "2/2 - 0s - loss: 0.5869 - accuracy: 0.6917 - val_loss: 0.8021 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 346/1000\n",
            "2/2 - 0s - loss: 0.5843 - accuracy: 0.7075 - val_loss: 0.8038 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 347/1000\n",
            "2/2 - 0s - loss: 0.5992 - accuracy: 0.6601 - val_loss: 0.8061 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 348/1000\n",
            "2/2 - 0s - loss: 0.6060 - accuracy: 0.6877 - val_loss: 0.8060 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 349/1000\n",
            "2/2 - 0s - loss: 0.5947 - accuracy: 0.7036 - val_loss: 0.8054 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 350/1000\n",
            "2/2 - 0s - loss: 0.5906 - accuracy: 0.6759 - val_loss: 0.8048 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 351/1000\n",
            "2/2 - 0s - loss: 0.5572 - accuracy: 0.7312 - val_loss: 0.8030 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 352/1000\n",
            "2/2 - 0s - loss: 0.6018 - accuracy: 0.6838 - val_loss: 0.8030 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 353/1000\n",
            "2/2 - 0s - loss: 0.5834 - accuracy: 0.6798 - val_loss: 0.8059 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 354/1000\n",
            "2/2 - 0s - loss: 0.5744 - accuracy: 0.6917 - val_loss: 0.8099 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 355/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.6680 - val_loss: 0.8140 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 356/1000\n",
            "2/2 - 0s - loss: 0.6040 - accuracy: 0.6522 - val_loss: 0.8168 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 357/1000\n",
            "2/2 - 0s - loss: 0.6070 - accuracy: 0.6324 - val_loss: 0.8185 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 358/1000\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6838 - val_loss: 0.8187 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 359/1000\n",
            "2/2 - 0s - loss: 0.5855 - accuracy: 0.6996 - val_loss: 0.8184 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 360/1000\n",
            "2/2 - 0s - loss: 0.6023 - accuracy: 0.6640 - val_loss: 0.8168 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 361/1000\n",
            "2/2 - 0s - loss: 0.6085 - accuracy: 0.6917 - val_loss: 0.8132 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 362/1000\n",
            "2/2 - 0s - loss: 0.5889 - accuracy: 0.6917 - val_loss: 0.8106 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 363/1000\n",
            "2/2 - 0s - loss: 0.6062 - accuracy: 0.6996 - val_loss: 0.8081 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 364/1000\n",
            "2/2 - 0s - loss: 0.5935 - accuracy: 0.6996 - val_loss: 0.8070 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 365/1000\n",
            "2/2 - 0s - loss: 0.5984 - accuracy: 0.6561 - val_loss: 0.8056 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 366/1000\n",
            "2/2 - 0s - loss: 0.5965 - accuracy: 0.6522 - val_loss: 0.8043 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 367/1000\n",
            "2/2 - 0s - loss: 0.5995 - accuracy: 0.6719 - val_loss: 0.8028 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 368/1000\n",
            "2/2 - 0s - loss: 0.6046 - accuracy: 0.6601 - val_loss: 0.7998 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 369/1000\n",
            "2/2 - 0s - loss: 0.6039 - accuracy: 0.6798 - val_loss: 0.7982 - val_accuracy: 0.5312 - 37ms/epoch - 19ms/step\n",
            "Epoch 370/1000\n",
            "2/2 - 0s - loss: 0.5895 - accuracy: 0.6957 - val_loss: 0.7976 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 371/1000\n",
            "2/2 - 0s - loss: 0.6156 - accuracy: 0.6798 - val_loss: 0.7964 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 372/1000\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6759 - val_loss: 0.7946 - val_accuracy: 0.5156 - 48ms/epoch - 24ms/step\n",
            "Epoch 373/1000\n",
            "2/2 - 0s - loss: 0.5859 - accuracy: 0.6917 - val_loss: 0.7938 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 374/1000\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.6996 - val_loss: 0.7943 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 375/1000\n",
            "2/2 - 0s - loss: 0.6017 - accuracy: 0.6640 - val_loss: 0.7950 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 376/1000\n",
            "2/2 - 0s - loss: 0.5961 - accuracy: 0.6996 - val_loss: 0.7964 - val_accuracy: 0.5312 - 36ms/epoch - 18ms/step\n",
            "Epoch 377/1000\n",
            "2/2 - 0s - loss: 0.6288 - accuracy: 0.6522 - val_loss: 0.7983 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 378/1000\n",
            "2/2 - 0s - loss: 0.5837 - accuracy: 0.6759 - val_loss: 0.8005 - val_accuracy: 0.5156 - 47ms/epoch - 23ms/step\n",
            "Epoch 379/1000\n",
            "2/2 - 0s - loss: 0.5915 - accuracy: 0.6640 - val_loss: 0.8032 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 380/1000\n",
            "2/2 - 0s - loss: 0.6037 - accuracy: 0.6561 - val_loss: 0.8043 - val_accuracy: 0.4844 - 47ms/epoch - 24ms/step\n",
            "Epoch 381/1000\n",
            "2/2 - 0s - loss: 0.5985 - accuracy: 0.6680 - val_loss: 0.8049 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 382/1000\n",
            "2/2 - 0s - loss: 0.6211 - accuracy: 0.6640 - val_loss: 0.8044 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 383/1000\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6877 - val_loss: 0.8016 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 384/1000\n",
            "2/2 - 0s - loss: 0.5983 - accuracy: 0.6838 - val_loss: 0.7989 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 385/1000\n",
            "2/2 - 0s - loss: 0.5853 - accuracy: 0.7036 - val_loss: 0.7975 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 386/1000\n",
            "2/2 - 0s - loss: 0.5948 - accuracy: 0.6719 - val_loss: 0.7956 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 387/1000\n",
            "2/2 - 0s - loss: 0.5890 - accuracy: 0.6759 - val_loss: 0.7943 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 388/1000\n",
            "2/2 - 0s - loss: 0.5861 - accuracy: 0.6957 - val_loss: 0.7933 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 389/1000\n",
            "2/2 - 0s - loss: 0.6168 - accuracy: 0.6482 - val_loss: 0.7921 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 390/1000\n",
            "2/2 - 0s - loss: 0.6008 - accuracy: 0.6917 - val_loss: 0.7901 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 391/1000\n",
            "2/2 - 0s - loss: 0.6101 - accuracy: 0.7036 - val_loss: 0.7889 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 392/1000\n",
            "2/2 - 0s - loss: 0.6130 - accuracy: 0.6482 - val_loss: 0.7874 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 393/1000\n",
            "2/2 - 0s - loss: 0.5846 - accuracy: 0.6759 - val_loss: 0.7866 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 394/1000\n",
            "2/2 - 0s - loss: 0.5789 - accuracy: 0.7194 - val_loss: 0.7863 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 395/1000\n",
            "2/2 - 0s - loss: 0.6038 - accuracy: 0.6798 - val_loss: 0.7875 - val_accuracy: 0.5156 - 41ms/epoch - 21ms/step\n",
            "Epoch 396/1000\n",
            "2/2 - 0s - loss: 0.5817 - accuracy: 0.7036 - val_loss: 0.7884 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 397/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.6917 - val_loss: 0.7901 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 398/1000\n",
            "2/2 - 0s - loss: 0.5988 - accuracy: 0.6798 - val_loss: 0.7917 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 399/1000\n",
            "2/2 - 0s - loss: 0.5891 - accuracy: 0.6798 - val_loss: 0.7940 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 400/1000\n",
            "2/2 - 0s - loss: 0.5993 - accuracy: 0.6364 - val_loss: 0.7955 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 401/1000\n",
            "2/2 - 0s - loss: 0.5835 - accuracy: 0.7036 - val_loss: 0.7967 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 402/1000\n",
            "2/2 - 0s - loss: 0.5854 - accuracy: 0.6640 - val_loss: 0.7995 - val_accuracy: 0.4844 - 43ms/epoch - 21ms/step\n",
            "Epoch 403/1000\n",
            "2/2 - 0s - loss: 0.6064 - accuracy: 0.6403 - val_loss: 0.8005 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 404/1000\n",
            "2/2 - 0s - loss: 0.6015 - accuracy: 0.6957 - val_loss: 0.8005 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 405/1000\n",
            "2/2 - 0s - loss: 0.5952 - accuracy: 0.6917 - val_loss: 0.7996 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 406/1000\n",
            "2/2 - 0s - loss: 0.5835 - accuracy: 0.7036 - val_loss: 0.7982 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 407/1000\n",
            "2/2 - 0s - loss: 0.6002 - accuracy: 0.6561 - val_loss: 0.7974 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 408/1000\n",
            "2/2 - 0s - loss: 0.6187 - accuracy: 0.6522 - val_loss: 0.7954 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 409/1000\n",
            "2/2 - 0s - loss: 0.5941 - accuracy: 0.6561 - val_loss: 0.7944 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 410/1000\n",
            "2/2 - 0s - loss: 0.5821 - accuracy: 0.7036 - val_loss: 0.7947 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 411/1000\n",
            "2/2 - 0s - loss: 0.6083 - accuracy: 0.6601 - val_loss: 0.7959 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 412/1000\n",
            "2/2 - 0s - loss: 0.6142 - accuracy: 0.6561 - val_loss: 0.7965 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 413/1000\n",
            "2/2 - 0s - loss: 0.6176 - accuracy: 0.6719 - val_loss: 0.7975 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 414/1000\n",
            "2/2 - 0s - loss: 0.5811 - accuracy: 0.6957 - val_loss: 0.7982 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 415/1000\n",
            "2/2 - 0s - loss: 0.5898 - accuracy: 0.7115 - val_loss: 0.7993 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 416/1000\n",
            "2/2 - 0s - loss: 0.5898 - accuracy: 0.6877 - val_loss: 0.7989 - val_accuracy: 0.5156 - 45ms/epoch - 23ms/step\n",
            "Epoch 417/1000\n",
            "2/2 - 0s - loss: 0.5918 - accuracy: 0.6759 - val_loss: 0.7981 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 418/1000\n",
            "2/2 - 0s - loss: 0.6082 - accuracy: 0.6917 - val_loss: 0.7979 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 419/1000\n",
            "2/2 - 0s - loss: 0.6094 - accuracy: 0.6482 - val_loss: 0.7971 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 420/1000\n",
            "2/2 - 0s - loss: 0.5969 - accuracy: 0.6561 - val_loss: 0.7994 - val_accuracy: 0.5156 - 41ms/epoch - 21ms/step\n",
            "Epoch 421/1000\n",
            "2/2 - 0s - loss: 0.6018 - accuracy: 0.6719 - val_loss: 0.8007 - val_accuracy: 0.5156 - 31ms/epoch - 15ms/step\n",
            "Epoch 422/1000\n",
            "2/2 - 0s - loss: 0.6014 - accuracy: 0.6798 - val_loss: 0.8007 - val_accuracy: 0.5156 - 43ms/epoch - 21ms/step\n",
            "Epoch 423/1000\n",
            "2/2 - 0s - loss: 0.5983 - accuracy: 0.6522 - val_loss: 0.8021 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 424/1000\n",
            "2/2 - 0s - loss: 0.5929 - accuracy: 0.6798 - val_loss: 0.8038 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 425/1000\n",
            "2/2 - 0s - loss: 0.6017 - accuracy: 0.6877 - val_loss: 0.8043 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 426/1000\n",
            "2/2 - 0s - loss: 0.5960 - accuracy: 0.6917 - val_loss: 0.8037 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 427/1000\n",
            "2/2 - 0s - loss: 0.5914 - accuracy: 0.6996 - val_loss: 0.8012 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 428/1000\n",
            "2/2 - 0s - loss: 0.5771 - accuracy: 0.7115 - val_loss: 0.8003 - val_accuracy: 0.5000 - 51ms/epoch - 26ms/step\n",
            "Epoch 429/1000\n",
            "2/2 - 0s - loss: 0.5809 - accuracy: 0.6798 - val_loss: 0.8003 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 430/1000\n",
            "2/2 - 0s - loss: 0.5608 - accuracy: 0.7273 - val_loss: 0.8022 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 431/1000\n",
            "2/2 - 0s - loss: 0.6162 - accuracy: 0.6640 - val_loss: 0.8031 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 432/1000\n",
            "2/2 - 0s - loss: 0.6034 - accuracy: 0.6719 - val_loss: 0.8020 - val_accuracy: 0.5000 - 51ms/epoch - 26ms/step\n",
            "Epoch 433/1000\n",
            "2/2 - 0s - loss: 0.6054 - accuracy: 0.6759 - val_loss: 0.8007 - val_accuracy: 0.5156 - 31ms/epoch - 16ms/step\n",
            "Epoch 434/1000\n",
            "2/2 - 0s - loss: 0.6043 - accuracy: 0.6680 - val_loss: 0.8006 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 435/1000\n",
            "2/2 - 0s - loss: 0.5772 - accuracy: 0.6917 - val_loss: 0.8012 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 436/1000\n",
            "2/2 - 0s - loss: 0.5906 - accuracy: 0.6798 - val_loss: 0.8001 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 437/1000\n",
            "2/2 - 0s - loss: 0.5953 - accuracy: 0.6719 - val_loss: 0.7980 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 438/1000\n",
            "2/2 - 0s - loss: 0.5848 - accuracy: 0.6917 - val_loss: 0.7949 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 439/1000\n",
            "2/2 - 0s - loss: 0.5814 - accuracy: 0.7036 - val_loss: 0.7929 - val_accuracy: 0.5156 - 41ms/epoch - 21ms/step\n",
            "Epoch 440/1000\n",
            "2/2 - 0s - loss: 0.6006 - accuracy: 0.6759 - val_loss: 0.7933 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 441/1000\n",
            "2/2 - 0s - loss: 0.5741 - accuracy: 0.6877 - val_loss: 0.7950 - val_accuracy: 0.5156 - 39ms/epoch - 19ms/step\n",
            "Epoch 442/1000\n",
            "2/2 - 0s - loss: 0.5948 - accuracy: 0.6680 - val_loss: 0.7990 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 443/1000\n",
            "2/2 - 0s - loss: 0.5895 - accuracy: 0.6601 - val_loss: 0.8017 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 444/1000\n",
            "2/2 - 0s - loss: 0.6197 - accuracy: 0.6719 - val_loss: 0.8025 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 445/1000\n",
            "2/2 - 0s - loss: 0.5960 - accuracy: 0.6561 - val_loss: 0.8027 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 446/1000\n",
            "2/2 - 0s - loss: 0.5807 - accuracy: 0.6917 - val_loss: 0.8026 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 447/1000\n",
            "2/2 - 0s - loss: 0.5979 - accuracy: 0.6759 - val_loss: 0.8038 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 448/1000\n",
            "2/2 - 0s - loss: 0.5623 - accuracy: 0.6957 - val_loss: 0.8059 - val_accuracy: 0.5156 - 56ms/epoch - 28ms/step\n",
            "Epoch 449/1000\n",
            "2/2 - 0s - loss: 0.5780 - accuracy: 0.6759 - val_loss: 0.8069 - val_accuracy: 0.5156 - 31ms/epoch - 16ms/step\n",
            "Epoch 450/1000\n",
            "2/2 - 0s - loss: 0.5950 - accuracy: 0.6640 - val_loss: 0.8061 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 451/1000\n",
            "2/2 - 0s - loss: 0.5849 - accuracy: 0.6640 - val_loss: 0.8041 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 452/1000\n",
            "2/2 - 0s - loss: 0.5998 - accuracy: 0.6601 - val_loss: 0.8039 - val_accuracy: 0.5156 - 54ms/epoch - 27ms/step\n",
            "Epoch 453/1000\n",
            "2/2 - 0s - loss: 0.5880 - accuracy: 0.7036 - val_loss: 0.8047 - val_accuracy: 0.5312 - 34ms/epoch - 17ms/step\n",
            "Epoch 454/1000\n",
            "2/2 - 0s - loss: 0.5864 - accuracy: 0.6759 - val_loss: 0.8055 - val_accuracy: 0.5312 - 30ms/epoch - 15ms/step\n",
            "Epoch 455/1000\n",
            "2/2 - 0s - loss: 0.5914 - accuracy: 0.6996 - val_loss: 0.8057 - val_accuracy: 0.5156 - 39ms/epoch - 20ms/step\n",
            "Epoch 456/1000\n",
            "2/2 - 0s - loss: 0.5801 - accuracy: 0.6957 - val_loss: 0.8084 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 457/1000\n",
            "2/2 - 0s - loss: 0.5999 - accuracy: 0.6798 - val_loss: 0.8107 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 458/1000\n",
            "2/2 - 0s - loss: 0.5987 - accuracy: 0.6443 - val_loss: 0.8126 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 459/1000\n",
            "2/2 - 0s - loss: 0.5918 - accuracy: 0.6680 - val_loss: 0.8131 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 460/1000\n",
            "2/2 - 0s - loss: 0.6010 - accuracy: 0.6759 - val_loss: 0.8120 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 461/1000\n",
            "2/2 - 0s - loss: 0.5885 - accuracy: 0.6877 - val_loss: 0.8089 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 462/1000\n",
            "2/2 - 0s - loss: 0.5942 - accuracy: 0.6561 - val_loss: 0.8060 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 463/1000\n",
            "2/2 - 0s - loss: 0.6189 - accuracy: 0.6324 - val_loss: 0.8027 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 464/1000\n",
            "2/2 - 0s - loss: 0.5880 - accuracy: 0.6759 - val_loss: 0.7999 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 465/1000\n",
            "2/2 - 0s - loss: 0.5985 - accuracy: 0.6957 - val_loss: 0.7990 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 466/1000\n",
            "2/2 - 0s - loss: 0.6028 - accuracy: 0.6877 - val_loss: 0.7979 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 467/1000\n",
            "2/2 - 0s - loss: 0.6013 - accuracy: 0.6640 - val_loss: 0.7965 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 468/1000\n",
            "2/2 - 0s - loss: 0.5857 - accuracy: 0.6917 - val_loss: 0.7953 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 469/1000\n",
            "2/2 - 0s - loss: 0.5909 - accuracy: 0.6798 - val_loss: 0.7960 - val_accuracy: 0.5312 - 35ms/epoch - 18ms/step\n",
            "Epoch 470/1000\n",
            "2/2 - 0s - loss: 0.5878 - accuracy: 0.6877 - val_loss: 0.7965 - val_accuracy: 0.5312 - 43ms/epoch - 21ms/step\n",
            "Epoch 471/1000\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.6996 - val_loss: 0.7976 - val_accuracy: 0.5469 - 39ms/epoch - 19ms/step\n",
            "Epoch 472/1000\n",
            "2/2 - 0s - loss: 0.5807 - accuracy: 0.6957 - val_loss: 0.7981 - val_accuracy: 0.5312 - 35ms/epoch - 18ms/step\n",
            "Epoch 473/1000\n",
            "2/2 - 0s - loss: 0.5760 - accuracy: 0.6877 - val_loss: 0.7999 - val_accuracy: 0.5312 - 39ms/epoch - 20ms/step\n",
            "Epoch 474/1000\n",
            "2/2 - 0s - loss: 0.5942 - accuracy: 0.6640 - val_loss: 0.8011 - val_accuracy: 0.5312 - 36ms/epoch - 18ms/step\n",
            "Epoch 475/1000\n",
            "2/2 - 0s - loss: 0.6002 - accuracy: 0.6917 - val_loss: 0.8019 - val_accuracy: 0.5312 - 38ms/epoch - 19ms/step\n",
            "Epoch 476/1000\n",
            "2/2 - 0s - loss: 0.5939 - accuracy: 0.7154 - val_loss: 0.8018 - val_accuracy: 0.5312 - 51ms/epoch - 25ms/step\n",
            "Epoch 477/1000\n",
            "2/2 - 0s - loss: 0.5706 - accuracy: 0.7194 - val_loss: 0.8026 - val_accuracy: 0.5312 - 42ms/epoch - 21ms/step\n",
            "Epoch 478/1000\n",
            "2/2 - 0s - loss: 0.5901 - accuracy: 0.6838 - val_loss: 0.8050 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 479/1000\n",
            "2/2 - 0s - loss: 0.5841 - accuracy: 0.6877 - val_loss: 0.8082 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 480/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.6838 - val_loss: 0.8106 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 481/1000\n",
            "2/2 - 0s - loss: 0.5968 - accuracy: 0.6482 - val_loss: 0.8122 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 482/1000\n",
            "2/2 - 0s - loss: 0.5866 - accuracy: 0.6719 - val_loss: 0.8127 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 483/1000\n",
            "2/2 - 0s - loss: 0.6079 - accuracy: 0.6680 - val_loss: 0.8138 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 484/1000\n",
            "2/2 - 0s - loss: 0.5804 - accuracy: 0.6957 - val_loss: 0.8140 - val_accuracy: 0.5156 - 31ms/epoch - 15ms/step\n",
            "Epoch 485/1000\n",
            "2/2 - 0s - loss: 0.5897 - accuracy: 0.6917 - val_loss: 0.8154 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 486/1000\n",
            "2/2 - 0s - loss: 0.5737 - accuracy: 0.7036 - val_loss: 0.8149 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 487/1000\n",
            "2/2 - 0s - loss: 0.6030 - accuracy: 0.6719 - val_loss: 0.8143 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 488/1000\n",
            "2/2 - 0s - loss: 0.5703 - accuracy: 0.7075 - val_loss: 0.8153 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 489/1000\n",
            "2/2 - 0s - loss: 0.5886 - accuracy: 0.7075 - val_loss: 0.8176 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 490/1000\n",
            "2/2 - 0s - loss: 0.5790 - accuracy: 0.6917 - val_loss: 0.8179 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 491/1000\n",
            "2/2 - 0s - loss: 0.5851 - accuracy: 0.6759 - val_loss: 0.8185 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 492/1000\n",
            "2/2 - 0s - loss: 0.5726 - accuracy: 0.6719 - val_loss: 0.8211 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 493/1000\n",
            "2/2 - 0s - loss: 0.5574 - accuracy: 0.7075 - val_loss: 0.8254 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 494/1000\n",
            "2/2 - 0s - loss: 0.5800 - accuracy: 0.6640 - val_loss: 0.8304 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 495/1000\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6917 - val_loss: 0.8362 - val_accuracy: 0.5156 - 41ms/epoch - 21ms/step\n",
            "Epoch 496/1000\n",
            "2/2 - 0s - loss: 0.5699 - accuracy: 0.7194 - val_loss: 0.8416 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 497/1000\n",
            "2/2 - 0s - loss: 0.5987 - accuracy: 0.7154 - val_loss: 0.8453 - val_accuracy: 0.5156 - 62ms/epoch - 31ms/step\n",
            "Epoch 498/1000\n",
            "2/2 - 0s - loss: 0.5822 - accuracy: 0.6838 - val_loss: 0.8440 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 499/1000\n",
            "2/2 - 0s - loss: 0.5856 - accuracy: 0.7115 - val_loss: 0.8419 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 500/1000\n",
            "2/2 - 0s - loss: 0.6095 - accuracy: 0.6838 - val_loss: 0.8361 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 501/1000\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.7036 - val_loss: 0.8287 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 502/1000\n",
            "2/2 - 0s - loss: 0.6060 - accuracy: 0.6640 - val_loss: 0.8234 - val_accuracy: 0.5312 - 38ms/epoch - 19ms/step\n",
            "Epoch 503/1000\n",
            "2/2 - 0s - loss: 0.5922 - accuracy: 0.6601 - val_loss: 0.8172 - val_accuracy: 0.5469 - 41ms/epoch - 21ms/step\n",
            "Epoch 504/1000\n",
            "2/2 - 0s - loss: 0.5654 - accuracy: 0.7036 - val_loss: 0.8136 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 505/1000\n",
            "2/2 - 0s - loss: 0.5868 - accuracy: 0.6719 - val_loss: 0.8132 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 506/1000\n",
            "2/2 - 0s - loss: 0.5685 - accuracy: 0.6877 - val_loss: 0.8141 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 507/1000\n",
            "2/2 - 0s - loss: 0.5901 - accuracy: 0.6957 - val_loss: 0.8159 - val_accuracy: 0.5156 - 58ms/epoch - 29ms/step\n",
            "Epoch 508/1000\n",
            "2/2 - 0s - loss: 0.5728 - accuracy: 0.7233 - val_loss: 0.8177 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 509/1000\n",
            "2/2 - 0s - loss: 0.5773 - accuracy: 0.7075 - val_loss: 0.8199 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 510/1000\n",
            "2/2 - 0s - loss: 0.5907 - accuracy: 0.6522 - val_loss: 0.8212 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 511/1000\n",
            "2/2 - 0s - loss: 0.6015 - accuracy: 0.6838 - val_loss: 0.8219 - val_accuracy: 0.5312 - 43ms/epoch - 22ms/step\n",
            "Epoch 512/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.6601 - val_loss: 0.8209 - val_accuracy: 0.5312 - 34ms/epoch - 17ms/step\n",
            "Epoch 513/1000\n",
            "2/2 - 0s - loss: 0.5890 - accuracy: 0.6838 - val_loss: 0.8187 - val_accuracy: 0.5312 - 43ms/epoch - 21ms/step\n",
            "Epoch 514/1000\n",
            "2/2 - 0s - loss: 0.5769 - accuracy: 0.7075 - val_loss: 0.8152 - val_accuracy: 0.5312 - 34ms/epoch - 17ms/step\n",
            "Epoch 515/1000\n",
            "2/2 - 0s - loss: 0.5803 - accuracy: 0.6838 - val_loss: 0.8128 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 516/1000\n",
            "2/2 - 0s - loss: 0.5898 - accuracy: 0.6838 - val_loss: 0.8092 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 517/1000\n",
            "2/2 - 0s - loss: 0.5666 - accuracy: 0.7115 - val_loss: 0.8066 - val_accuracy: 0.5156 - 41ms/epoch - 21ms/step\n",
            "Epoch 518/1000\n",
            "2/2 - 0s - loss: 0.5879 - accuracy: 0.7075 - val_loss: 0.8056 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 519/1000\n",
            "2/2 - 0s - loss: 0.5809 - accuracy: 0.6798 - val_loss: 0.8038 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 520/1000\n",
            "2/2 - 0s - loss: 0.5798 - accuracy: 0.7036 - val_loss: 0.8037 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 521/1000\n",
            "2/2 - 0s - loss: 0.5792 - accuracy: 0.6838 - val_loss: 0.8063 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 522/1000\n",
            "2/2 - 0s - loss: 0.5842 - accuracy: 0.6798 - val_loss: 0.8075 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 523/1000\n",
            "2/2 - 0s - loss: 0.5753 - accuracy: 0.7115 - val_loss: 0.8093 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 524/1000\n",
            "2/2 - 0s - loss: 0.5622 - accuracy: 0.7194 - val_loss: 0.8124 - val_accuracy: 0.5156 - 45ms/epoch - 23ms/step\n",
            "Epoch 525/1000\n",
            "2/2 - 0s - loss: 0.5449 - accuracy: 0.7312 - val_loss: 0.8165 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 526/1000\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6601 - val_loss: 0.8191 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 527/1000\n",
            "2/2 - 0s - loss: 0.5880 - accuracy: 0.6917 - val_loss: 0.8172 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 528/1000\n",
            "2/2 - 0s - loss: 0.5891 - accuracy: 0.6917 - val_loss: 0.8169 - val_accuracy: 0.5469 - 39ms/epoch - 19ms/step\n",
            "Epoch 529/1000\n",
            "2/2 - 0s - loss: 0.5945 - accuracy: 0.7036 - val_loss: 0.8172 - val_accuracy: 0.5469 - 37ms/epoch - 18ms/step\n",
            "Epoch 530/1000\n",
            "2/2 - 0s - loss: 0.5929 - accuracy: 0.6640 - val_loss: 0.8163 - val_accuracy: 0.5625 - 39ms/epoch - 19ms/step\n",
            "Epoch 531/1000\n",
            "2/2 - 0s - loss: 0.5559 - accuracy: 0.7194 - val_loss: 0.8157 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 532/1000\n",
            "2/2 - 0s - loss: 0.5869 - accuracy: 0.7036 - val_loss: 0.8160 - val_accuracy: 0.5312 - 38ms/epoch - 19ms/step\n",
            "Epoch 533/1000\n",
            "2/2 - 0s - loss: 0.5820 - accuracy: 0.6957 - val_loss: 0.8164 - val_accuracy: 0.5312 - 42ms/epoch - 21ms/step\n",
            "Epoch 534/1000\n",
            "2/2 - 0s - loss: 0.5757 - accuracy: 0.6877 - val_loss: 0.8156 - val_accuracy: 0.5469 - 33ms/epoch - 16ms/step\n",
            "Epoch 535/1000\n",
            "2/2 - 0s - loss: 0.5846 - accuracy: 0.6917 - val_loss: 0.8139 - val_accuracy: 0.5469 - 32ms/epoch - 16ms/step\n",
            "Epoch 536/1000\n",
            "2/2 - 0s - loss: 0.5879 - accuracy: 0.6719 - val_loss: 0.8121 - val_accuracy: 0.5312 - 37ms/epoch - 18ms/step\n",
            "Epoch 537/1000\n",
            "2/2 - 0s - loss: 0.5784 - accuracy: 0.6759 - val_loss: 0.8105 - val_accuracy: 0.5312 - 41ms/epoch - 20ms/step\n",
            "Epoch 538/1000\n",
            "2/2 - 0s - loss: 0.6056 - accuracy: 0.6522 - val_loss: 0.8104 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 539/1000\n",
            "2/2 - 0s - loss: 0.5752 - accuracy: 0.7036 - val_loss: 0.8103 - val_accuracy: 0.5312 - 32ms/epoch - 16ms/step\n",
            "Epoch 540/1000\n",
            "2/2 - 0s - loss: 0.5560 - accuracy: 0.7273 - val_loss: 0.8138 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 541/1000\n",
            "2/2 - 0s - loss: 0.5670 - accuracy: 0.7115 - val_loss: 0.8179 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 542/1000\n",
            "2/2 - 0s - loss: 0.5785 - accuracy: 0.6917 - val_loss: 0.8222 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 543/1000\n",
            "2/2 - 0s - loss: 0.5773 - accuracy: 0.6522 - val_loss: 0.8249 - val_accuracy: 0.5156 - 46ms/epoch - 23ms/step\n",
            "Epoch 544/1000\n",
            "2/2 - 0s - loss: 0.5628 - accuracy: 0.7154 - val_loss: 0.8272 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 545/1000\n",
            "2/2 - 0s - loss: 0.5726 - accuracy: 0.7115 - val_loss: 0.8293 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 546/1000\n",
            "2/2 - 0s - loss: 0.5875 - accuracy: 0.7036 - val_loss: 0.8305 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 547/1000\n",
            "2/2 - 0s - loss: 0.5832 - accuracy: 0.6996 - val_loss: 0.8316 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 548/1000\n",
            "2/2 - 0s - loss: 0.5785 - accuracy: 0.7115 - val_loss: 0.8307 - val_accuracy: 0.5156 - 47ms/epoch - 23ms/step\n",
            "Epoch 549/1000\n",
            "2/2 - 0s - loss: 0.5935 - accuracy: 0.6798 - val_loss: 0.8301 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 550/1000\n",
            "2/2 - 0s - loss: 0.5734 - accuracy: 0.7154 - val_loss: 0.8309 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 551/1000\n",
            "2/2 - 0s - loss: 0.5714 - accuracy: 0.7075 - val_loss: 0.8317 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 552/1000\n",
            "2/2 - 0s - loss: 0.5722 - accuracy: 0.7352 - val_loss: 0.8319 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 553/1000\n",
            "2/2 - 0s - loss: 0.5767 - accuracy: 0.6877 - val_loss: 0.8316 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 554/1000\n",
            "2/2 - 0s - loss: 0.5693 - accuracy: 0.7115 - val_loss: 0.8334 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 555/1000\n",
            "2/2 - 0s - loss: 0.5688 - accuracy: 0.6996 - val_loss: 0.8345 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 556/1000\n",
            "2/2 - 0s - loss: 0.5802 - accuracy: 0.6917 - val_loss: 0.8348 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 557/1000\n",
            "2/2 - 0s - loss: 0.5709 - accuracy: 0.7233 - val_loss: 0.8382 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 558/1000\n",
            "2/2 - 0s - loss: 0.5744 - accuracy: 0.6877 - val_loss: 0.8392 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 559/1000\n",
            "2/2 - 0s - loss: 0.5612 - accuracy: 0.7431 - val_loss: 0.8405 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 560/1000\n",
            "2/2 - 0s - loss: 0.5846 - accuracy: 0.7233 - val_loss: 0.8412 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 561/1000\n",
            "2/2 - 0s - loss: 0.5685 - accuracy: 0.7036 - val_loss: 0.8422 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 562/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.6719 - val_loss: 0.8436 - val_accuracy: 0.5312 - 37ms/epoch - 18ms/step\n",
            "Epoch 563/1000\n",
            "2/2 - 0s - loss: 0.5313 - accuracy: 0.7194 - val_loss: 0.8449 - val_accuracy: 0.5312 - 41ms/epoch - 20ms/step\n",
            "Epoch 564/1000\n",
            "2/2 - 0s - loss: 0.5775 - accuracy: 0.6759 - val_loss: 0.8475 - val_accuracy: 0.5312 - 34ms/epoch - 17ms/step\n",
            "Epoch 565/1000\n",
            "2/2 - 0s - loss: 0.5788 - accuracy: 0.6640 - val_loss: 0.8494 - val_accuracy: 0.5469 - 36ms/epoch - 18ms/step\n",
            "Epoch 566/1000\n",
            "2/2 - 0s - loss: 0.5629 - accuracy: 0.7036 - val_loss: 0.8508 - val_accuracy: 0.5312 - 36ms/epoch - 18ms/step\n",
            "Epoch 567/1000\n",
            "2/2 - 0s - loss: 0.5956 - accuracy: 0.6798 - val_loss: 0.8511 - val_accuracy: 0.5312 - 38ms/epoch - 19ms/step\n",
            "Epoch 568/1000\n",
            "2/2 - 0s - loss: 0.5685 - accuracy: 0.7154 - val_loss: 0.8536 - val_accuracy: 0.5312 - 41ms/epoch - 21ms/step\n",
            "Epoch 569/1000\n",
            "2/2 - 0s - loss: 0.5988 - accuracy: 0.6601 - val_loss: 0.8553 - val_accuracy: 0.5312 - 45ms/epoch - 23ms/step\n",
            "Epoch 570/1000\n",
            "2/2 - 0s - loss: 0.5896 - accuracy: 0.6996 - val_loss: 0.8561 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 571/1000\n",
            "2/2 - 0s - loss: 0.5477 - accuracy: 0.7115 - val_loss: 0.8551 - val_accuracy: 0.5312 - 33ms/epoch - 16ms/step\n",
            "Epoch 572/1000\n",
            "2/2 - 0s - loss: 0.5813 - accuracy: 0.7036 - val_loss: 0.8533 - val_accuracy: 0.5312 - 42ms/epoch - 21ms/step\n",
            "Epoch 573/1000\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.6877 - val_loss: 0.8518 - val_accuracy: 0.5312 - 35ms/epoch - 18ms/step\n",
            "Epoch 574/1000\n",
            "2/2 - 0s - loss: 0.5864 - accuracy: 0.7154 - val_loss: 0.8498 - val_accuracy: 0.5312 - 41ms/epoch - 20ms/step\n",
            "Epoch 575/1000\n",
            "2/2 - 0s - loss: 0.5699 - accuracy: 0.7075 - val_loss: 0.8472 - val_accuracy: 0.5312 - 35ms/epoch - 18ms/step\n",
            "Epoch 576/1000\n",
            "2/2 - 0s - loss: 0.5960 - accuracy: 0.6838 - val_loss: 0.8432 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 577/1000\n",
            "2/2 - 0s - loss: 0.5878 - accuracy: 0.7036 - val_loss: 0.8395 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 578/1000\n",
            "2/2 - 0s - loss: 0.5807 - accuracy: 0.6996 - val_loss: 0.8348 - val_accuracy: 0.5312 - 34ms/epoch - 17ms/step\n",
            "Epoch 579/1000\n",
            "2/2 - 0s - loss: 0.6063 - accuracy: 0.6601 - val_loss: 0.8316 - val_accuracy: 0.5312 - 39ms/epoch - 19ms/step\n",
            "Epoch 580/1000\n",
            "2/2 - 0s - loss: 0.6103 - accuracy: 0.6680 - val_loss: 0.8303 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 581/1000\n",
            "2/2 - 0s - loss: 0.5663 - accuracy: 0.7194 - val_loss: 0.8296 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 582/1000\n",
            "2/2 - 0s - loss: 0.5961 - accuracy: 0.6719 - val_loss: 0.8295 - val_accuracy: 0.4844 - 33ms/epoch - 16ms/step\n",
            "Epoch 583/1000\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6957 - val_loss: 0.8279 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 584/1000\n",
            "2/2 - 0s - loss: 0.5894 - accuracy: 0.6996 - val_loss: 0.8261 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 585/1000\n",
            "2/2 - 0s - loss: 0.5806 - accuracy: 0.6759 - val_loss: 0.8227 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 586/1000\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6996 - val_loss: 0.8200 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 587/1000\n",
            "2/2 - 0s - loss: 0.5745 - accuracy: 0.7233 - val_loss: 0.8172 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 588/1000\n",
            "2/2 - 0s - loss: 0.5692 - accuracy: 0.7352 - val_loss: 0.8139 - val_accuracy: 0.4844 - 43ms/epoch - 22ms/step\n",
            "Epoch 589/1000\n",
            "2/2 - 0s - loss: 0.5627 - accuracy: 0.7194 - val_loss: 0.8141 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 590/1000\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.7036 - val_loss: 0.8152 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 591/1000\n",
            "2/2 - 0s - loss: 0.5849 - accuracy: 0.6996 - val_loss: 0.8155 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 592/1000\n",
            "2/2 - 0s - loss: 0.5524 - accuracy: 0.7233 - val_loss: 0.8172 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 593/1000\n",
            "2/2 - 0s - loss: 0.5883 - accuracy: 0.6798 - val_loss: 0.8169 - val_accuracy: 0.5000 - 30ms/epoch - 15ms/step\n",
            "Epoch 594/1000\n",
            "2/2 - 0s - loss: 0.5830 - accuracy: 0.6877 - val_loss: 0.8171 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 595/1000\n",
            "2/2 - 0s - loss: 0.5781 - accuracy: 0.7036 - val_loss: 0.8155 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 596/1000\n",
            "2/2 - 0s - loss: 0.5852 - accuracy: 0.6561 - val_loss: 0.8159 - val_accuracy: 0.5156 - 48ms/epoch - 24ms/step\n",
            "Epoch 597/1000\n",
            "2/2 - 0s - loss: 0.5559 - accuracy: 0.7115 - val_loss: 0.8167 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 598/1000\n",
            "2/2 - 0s - loss: 0.5810 - accuracy: 0.7154 - val_loss: 0.8176 - val_accuracy: 0.5156 - 39ms/epoch - 20ms/step\n",
            "Epoch 599/1000\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6838 - val_loss: 0.8189 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 600/1000\n",
            "2/2 - 0s - loss: 0.5733 - accuracy: 0.6957 - val_loss: 0.8200 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 601/1000\n",
            "2/2 - 0s - loss: 0.5830 - accuracy: 0.6917 - val_loss: 0.8233 - val_accuracy: 0.5000 - 48ms/epoch - 24ms/step\n",
            "Epoch 602/1000\n",
            "2/2 - 0s - loss: 0.5756 - accuracy: 0.6838 - val_loss: 0.8266 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 603/1000\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6917 - val_loss: 0.8297 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 604/1000\n",
            "2/2 - 0s - loss: 0.5711 - accuracy: 0.6601 - val_loss: 0.8299 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 605/1000\n",
            "2/2 - 0s - loss: 0.5540 - accuracy: 0.7075 - val_loss: 0.8275 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 606/1000\n",
            "2/2 - 0s - loss: 0.5536 - accuracy: 0.7273 - val_loss: 0.8276 - val_accuracy: 0.4844 - 31ms/epoch - 16ms/step\n",
            "Epoch 607/1000\n",
            "2/2 - 0s - loss: 0.5679 - accuracy: 0.7075 - val_loss: 0.8290 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 608/1000\n",
            "2/2 - 0s - loss: 0.5736 - accuracy: 0.6957 - val_loss: 0.8301 - val_accuracy: 0.4844 - 43ms/epoch - 21ms/step\n",
            "Epoch 609/1000\n",
            "2/2 - 0s - loss: 0.5589 - accuracy: 0.6996 - val_loss: 0.8293 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 610/1000\n",
            "2/2 - 0s - loss: 0.5490 - accuracy: 0.7115 - val_loss: 0.8314 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 611/1000\n",
            "2/2 - 0s - loss: 0.5851 - accuracy: 0.6957 - val_loss: 0.8322 - val_accuracy: 0.4844 - 51ms/epoch - 26ms/step\n",
            "Epoch 612/1000\n",
            "2/2 - 0s - loss: 0.5752 - accuracy: 0.7036 - val_loss: 0.8322 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 613/1000\n",
            "2/2 - 0s - loss: 0.5785 - accuracy: 0.6561 - val_loss: 0.8336 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 614/1000\n",
            "2/2 - 0s - loss: 0.5871 - accuracy: 0.6996 - val_loss: 0.8341 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 615/1000\n",
            "2/2 - 0s - loss: 0.6018 - accuracy: 0.7154 - val_loss: 0.8346 - val_accuracy: 0.5000 - 54ms/epoch - 27ms/step\n",
            "Epoch 616/1000\n",
            "2/2 - 0s - loss: 0.5646 - accuracy: 0.7273 - val_loss: 0.8358 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 617/1000\n",
            "2/2 - 0s - loss: 0.5812 - accuracy: 0.7194 - val_loss: 0.8367 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 618/1000\n",
            "2/2 - 0s - loss: 0.5589 - accuracy: 0.7312 - val_loss: 0.8358 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 619/1000\n",
            "2/2 - 0s - loss: 0.5791 - accuracy: 0.6798 - val_loss: 0.8333 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 620/1000\n",
            "2/2 - 0s - loss: 0.5569 - accuracy: 0.6996 - val_loss: 0.8340 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 621/1000\n",
            "2/2 - 0s - loss: 0.5674 - accuracy: 0.7036 - val_loss: 0.8328 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 622/1000\n",
            "2/2 - 0s - loss: 0.5786 - accuracy: 0.6957 - val_loss: 0.8331 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 623/1000\n",
            "2/2 - 0s - loss: 0.5886 - accuracy: 0.7154 - val_loss: 0.8303 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 624/1000\n",
            "2/2 - 0s - loss: 0.5645 - accuracy: 0.6877 - val_loss: 0.8283 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 625/1000\n",
            "2/2 - 0s - loss: 0.5631 - accuracy: 0.7154 - val_loss: 0.8283 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 626/1000\n",
            "2/2 - 0s - loss: 0.5660 - accuracy: 0.7075 - val_loss: 0.8296 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 627/1000\n",
            "2/2 - 0s - loss: 0.5582 - accuracy: 0.6957 - val_loss: 0.8322 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 628/1000\n",
            "2/2 - 0s - loss: 0.5520 - accuracy: 0.7075 - val_loss: 0.8349 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 629/1000\n",
            "2/2 - 0s - loss: 0.5907 - accuracy: 0.6680 - val_loss: 0.8335 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 630/1000\n",
            "2/2 - 0s - loss: 0.5856 - accuracy: 0.6601 - val_loss: 0.8323 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 631/1000\n",
            "2/2 - 0s - loss: 0.5743 - accuracy: 0.6957 - val_loss: 0.8286 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 632/1000\n",
            "2/2 - 0s - loss: 0.5433 - accuracy: 0.7233 - val_loss: 0.8276 - val_accuracy: 0.5000 - 46ms/epoch - 23ms/step\n",
            "Epoch 633/1000\n",
            "2/2 - 0s - loss: 0.5823 - accuracy: 0.6759 - val_loss: 0.8247 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 634/1000\n",
            "2/2 - 0s - loss: 0.5825 - accuracy: 0.6838 - val_loss: 0.8214 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 635/1000\n",
            "2/2 - 0s - loss: 0.5492 - accuracy: 0.7233 - val_loss: 0.8185 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 636/1000\n",
            "2/2 - 0s - loss: 0.5500 - accuracy: 0.7154 - val_loss: 0.8162 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 637/1000\n",
            "2/2 - 0s - loss: 0.5739 - accuracy: 0.6798 - val_loss: 0.8153 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 638/1000\n",
            "2/2 - 0s - loss: 0.5785 - accuracy: 0.6877 - val_loss: 0.8142 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 639/1000\n",
            "2/2 - 0s - loss: 0.5665 - accuracy: 0.6957 - val_loss: 0.8142 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 640/1000\n",
            "2/2 - 0s - loss: 0.5512 - accuracy: 0.7312 - val_loss: 0.8156 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 641/1000\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6996 - val_loss: 0.8178 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 642/1000\n",
            "2/2 - 0s - loss: 0.5463 - accuracy: 0.7549 - val_loss: 0.8203 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 643/1000\n",
            "2/2 - 0s - loss: 0.5509 - accuracy: 0.7194 - val_loss: 0.8230 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 644/1000\n",
            "2/2 - 0s - loss: 0.5761 - accuracy: 0.6838 - val_loss: 0.8248 - val_accuracy: 0.5000 - 52ms/epoch - 26ms/step\n",
            "Epoch 645/1000\n",
            "2/2 - 0s - loss: 0.5138 - accuracy: 0.7668 - val_loss: 0.8294 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 646/1000\n",
            "2/2 - 0s - loss: 0.5881 - accuracy: 0.7036 - val_loss: 0.8320 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 647/1000\n",
            "2/2 - 0s - loss: 0.5726 - accuracy: 0.6957 - val_loss: 0.8364 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 648/1000\n",
            "2/2 - 0s - loss: 0.5626 - accuracy: 0.7233 - val_loss: 0.8397 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 649/1000\n",
            "2/2 - 0s - loss: 0.5719 - accuracy: 0.6917 - val_loss: 0.8410 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 650/1000\n",
            "2/2 - 0s - loss: 0.5700 - accuracy: 0.7036 - val_loss: 0.8426 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 651/1000\n",
            "2/2 - 0s - loss: 0.5857 - accuracy: 0.6917 - val_loss: 0.8425 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 652/1000\n",
            "2/2 - 0s - loss: 0.5565 - accuracy: 0.6877 - val_loss: 0.8412 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 653/1000\n",
            "2/2 - 0s - loss: 0.5653 - accuracy: 0.6838 - val_loss: 0.8384 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 654/1000\n",
            "2/2 - 0s - loss: 0.5608 - accuracy: 0.7154 - val_loss: 0.8367 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 655/1000\n",
            "2/2 - 0s - loss: 0.5639 - accuracy: 0.7036 - val_loss: 0.8338 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 656/1000\n",
            "2/2 - 0s - loss: 0.5579 - accuracy: 0.7194 - val_loss: 0.8297 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 657/1000\n",
            "2/2 - 0s - loss: 0.5528 - accuracy: 0.7312 - val_loss: 0.8253 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 658/1000\n",
            "2/2 - 0s - loss: 0.5605 - accuracy: 0.7115 - val_loss: 0.8219 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 659/1000\n",
            "2/2 - 0s - loss: 0.5536 - accuracy: 0.7154 - val_loss: 0.8196 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 660/1000\n",
            "2/2 - 0s - loss: 0.5616 - accuracy: 0.7194 - val_loss: 0.8207 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 661/1000\n",
            "2/2 - 0s - loss: 0.5433 - accuracy: 0.7233 - val_loss: 0.8238 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 662/1000\n",
            "2/2 - 0s - loss: 0.5679 - accuracy: 0.6640 - val_loss: 0.8281 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 663/1000\n",
            "2/2 - 0s - loss: 0.5909 - accuracy: 0.6996 - val_loss: 0.8298 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 664/1000\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.6640 - val_loss: 0.8311 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 665/1000\n",
            "2/2 - 0s - loss: 0.5800 - accuracy: 0.7036 - val_loss: 0.8303 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 666/1000\n",
            "2/2 - 0s - loss: 0.5702 - accuracy: 0.7115 - val_loss: 0.8287 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 667/1000\n",
            "2/2 - 0s - loss: 0.5327 - accuracy: 0.7589 - val_loss: 0.8271 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 668/1000\n",
            "2/2 - 0s - loss: 0.5662 - accuracy: 0.7036 - val_loss: 0.8297 - val_accuracy: 0.4688 - 52ms/epoch - 26ms/step\n",
            "Epoch 669/1000\n",
            "2/2 - 0s - loss: 0.5647 - accuracy: 0.7431 - val_loss: 0.8308 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 670/1000\n",
            "2/2 - 0s - loss: 0.5650 - accuracy: 0.6798 - val_loss: 0.8326 - val_accuracy: 0.4531 - 34ms/epoch - 17ms/step\n",
            "Epoch 671/1000\n",
            "2/2 - 0s - loss: 0.5688 - accuracy: 0.7352 - val_loss: 0.8310 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 672/1000\n",
            "2/2 - 0s - loss: 0.5761 - accuracy: 0.6996 - val_loss: 0.8310 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 673/1000\n",
            "2/2 - 0s - loss: 0.5507 - accuracy: 0.7036 - val_loss: 0.8318 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 674/1000\n",
            "2/2 - 0s - loss: 0.5585 - accuracy: 0.6759 - val_loss: 0.8331 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 675/1000\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.7154 - val_loss: 0.8359 - val_accuracy: 0.4688 - 44ms/epoch - 22ms/step\n",
            "Epoch 676/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7273 - val_loss: 0.8397 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 677/1000\n",
            "2/2 - 0s - loss: 0.5567 - accuracy: 0.7194 - val_loss: 0.8437 - val_accuracy: 0.4531 - 33ms/epoch - 17ms/step\n",
            "Epoch 678/1000\n",
            "2/2 - 0s - loss: 0.5708 - accuracy: 0.7036 - val_loss: 0.8456 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 679/1000\n",
            "2/2 - 0s - loss: 0.5743 - accuracy: 0.6957 - val_loss: 0.8444 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 680/1000\n",
            "2/2 - 0s - loss: 0.5532 - accuracy: 0.7154 - val_loss: 0.8442 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 681/1000\n",
            "2/2 - 0s - loss: 0.5576 - accuracy: 0.7391 - val_loss: 0.8433 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 682/1000\n",
            "2/2 - 0s - loss: 0.5329 - accuracy: 0.7312 - val_loss: 0.8440 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 683/1000\n",
            "2/2 - 0s - loss: 0.5625 - accuracy: 0.7036 - val_loss: 0.8435 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 684/1000\n",
            "2/2 - 0s - loss: 0.5763 - accuracy: 0.6838 - val_loss: 0.8408 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 685/1000\n",
            "2/2 - 0s - loss: 0.5636 - accuracy: 0.6798 - val_loss: 0.8359 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 686/1000\n",
            "2/2 - 0s - loss: 0.5694 - accuracy: 0.6798 - val_loss: 0.8339 - val_accuracy: 0.5000 - 33ms/epoch - 16ms/step\n",
            "Epoch 687/1000\n",
            "2/2 - 0s - loss: 0.5959 - accuracy: 0.7075 - val_loss: 0.8338 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 688/1000\n",
            "2/2 - 0s - loss: 0.5591 - accuracy: 0.6838 - val_loss: 0.8316 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 689/1000\n",
            "2/2 - 0s - loss: 0.5887 - accuracy: 0.6719 - val_loss: 0.8303 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 690/1000\n",
            "2/2 - 0s - loss: 0.5524 - accuracy: 0.6877 - val_loss: 0.8282 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 691/1000\n",
            "2/2 - 0s - loss: 0.5627 - accuracy: 0.7154 - val_loss: 0.8256 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 692/1000\n",
            "2/2 - 0s - loss: 0.5581 - accuracy: 0.7233 - val_loss: 0.8234 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 693/1000\n",
            "2/2 - 0s - loss: 0.5421 - accuracy: 0.7391 - val_loss: 0.8205 - val_accuracy: 0.4688 - 46ms/epoch - 23ms/step\n",
            "Epoch 694/1000\n",
            "2/2 - 0s - loss: 0.5521 - accuracy: 0.7312 - val_loss: 0.8179 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 695/1000\n",
            "2/2 - 0s - loss: 0.5807 - accuracy: 0.7036 - val_loss: 0.8135 - val_accuracy: 0.4688 - 45ms/epoch - 22ms/step\n",
            "Epoch 696/1000\n",
            "2/2 - 0s - loss: 0.5443 - accuracy: 0.7154 - val_loss: 0.8134 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 697/1000\n",
            "2/2 - 0s - loss: 0.5528 - accuracy: 0.7273 - val_loss: 0.8136 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 698/1000\n",
            "2/2 - 0s - loss: 0.5756 - accuracy: 0.7036 - val_loss: 0.8140 - val_accuracy: 0.4844 - 43ms/epoch - 22ms/step\n",
            "Epoch 699/1000\n",
            "2/2 - 0s - loss: 0.5771 - accuracy: 0.6917 - val_loss: 0.8161 - val_accuracy: 0.4688 - 56ms/epoch - 28ms/step\n",
            "Epoch 700/1000\n",
            "2/2 - 0s - loss: 0.5677 - accuracy: 0.6957 - val_loss: 0.8168 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 701/1000\n",
            "2/2 - 0s - loss: 0.5745 - accuracy: 0.7154 - val_loss: 0.8183 - val_accuracy: 0.4688 - 32ms/epoch - 16ms/step\n",
            "Epoch 702/1000\n",
            "2/2 - 0s - loss: 0.5335 - accuracy: 0.7352 - val_loss: 0.8171 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 703/1000\n",
            "2/2 - 0s - loss: 0.5480 - accuracy: 0.7352 - val_loss: 0.8169 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 704/1000\n",
            "2/2 - 0s - loss: 0.5654 - accuracy: 0.6996 - val_loss: 0.8170 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 705/1000\n",
            "2/2 - 0s - loss: 0.5600 - accuracy: 0.7036 - val_loss: 0.8164 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 706/1000\n",
            "2/2 - 0s - loss: 0.5681 - accuracy: 0.7154 - val_loss: 0.8161 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 707/1000\n",
            "2/2 - 0s - loss: 0.5530 - accuracy: 0.7352 - val_loss: 0.8161 - val_accuracy: 0.4844 - 43ms/epoch - 22ms/step\n",
            "Epoch 708/1000\n",
            "2/2 - 0s - loss: 0.5325 - accuracy: 0.6996 - val_loss: 0.8190 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 709/1000\n",
            "2/2 - 0s - loss: 0.5371 - accuracy: 0.7510 - val_loss: 0.8225 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 710/1000\n",
            "2/2 - 0s - loss: 0.5659 - accuracy: 0.6877 - val_loss: 0.8247 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 711/1000\n",
            "2/2 - 0s - loss: 0.5705 - accuracy: 0.6877 - val_loss: 0.8277 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 712/1000\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7115 - val_loss: 0.8297 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 713/1000\n",
            "2/2 - 0s - loss: 0.5572 - accuracy: 0.7154 - val_loss: 0.8329 - val_accuracy: 0.4844 - 47ms/epoch - 24ms/step\n",
            "Epoch 714/1000\n",
            "2/2 - 0s - loss: 0.5440 - accuracy: 0.7352 - val_loss: 0.8381 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 715/1000\n",
            "2/2 - 0s - loss: 0.5679 - accuracy: 0.6640 - val_loss: 0.8414 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 716/1000\n",
            "2/2 - 0s - loss: 0.5684 - accuracy: 0.7075 - val_loss: 0.8416 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 717/1000\n",
            "2/2 - 0s - loss: 0.5920 - accuracy: 0.7036 - val_loss: 0.8363 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 718/1000\n",
            "2/2 - 0s - loss: 0.5400 - accuracy: 0.7036 - val_loss: 0.8339 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 719/1000\n",
            "2/2 - 0s - loss: 0.5374 - accuracy: 0.7391 - val_loss: 0.8336 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 720/1000\n",
            "2/2 - 0s - loss: 0.5718 - accuracy: 0.6640 - val_loss: 0.8340 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 721/1000\n",
            "2/2 - 0s - loss: 0.5394 - accuracy: 0.7391 - val_loss: 0.8378 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 722/1000\n",
            "2/2 - 0s - loss: 0.5585 - accuracy: 0.7194 - val_loss: 0.8388 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 723/1000\n",
            "2/2 - 0s - loss: 0.5694 - accuracy: 0.7115 - val_loss: 0.8375 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 724/1000\n",
            "2/2 - 0s - loss: 0.5499 - accuracy: 0.7312 - val_loss: 0.8366 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 725/1000\n",
            "2/2 - 0s - loss: 0.5621 - accuracy: 0.7154 - val_loss: 0.8348 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 726/1000\n",
            "2/2 - 0s - loss: 0.5367 - accuracy: 0.7194 - val_loss: 0.8344 - val_accuracy: 0.4688 - 41ms/epoch - 21ms/step\n",
            "Epoch 727/1000\n",
            "2/2 - 0s - loss: 0.5473 - accuracy: 0.6996 - val_loss: 0.8356 - val_accuracy: 0.4219 - 33ms/epoch - 17ms/step\n",
            "Epoch 728/1000\n",
            "2/2 - 0s - loss: 0.5616 - accuracy: 0.7036 - val_loss: 0.8365 - val_accuracy: 0.4219 - 41ms/epoch - 21ms/step\n",
            "Epoch 729/1000\n",
            "2/2 - 0s - loss: 0.5397 - accuracy: 0.7194 - val_loss: 0.8346 - val_accuracy: 0.4531 - 35ms/epoch - 17ms/step\n",
            "Epoch 730/1000\n",
            "2/2 - 0s - loss: 0.5584 - accuracy: 0.7154 - val_loss: 0.8345 - val_accuracy: 0.4688 - 41ms/epoch - 20ms/step\n",
            "Epoch 731/1000\n",
            "2/2 - 0s - loss: 0.5652 - accuracy: 0.7115 - val_loss: 0.8348 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 732/1000\n",
            "2/2 - 0s - loss: 0.5450 - accuracy: 0.6957 - val_loss: 0.8381 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 733/1000\n",
            "2/2 - 0s - loss: 0.5560 - accuracy: 0.7233 - val_loss: 0.8426 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 734/1000\n",
            "2/2 - 0s - loss: 0.5368 - accuracy: 0.7194 - val_loss: 0.8442 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 735/1000\n",
            "2/2 - 0s - loss: 0.5434 - accuracy: 0.7391 - val_loss: 0.8439 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 736/1000\n",
            "2/2 - 0s - loss: 0.5496 - accuracy: 0.7036 - val_loss: 0.8435 - val_accuracy: 0.4688 - 43ms/epoch - 21ms/step\n",
            "Epoch 737/1000\n",
            "2/2 - 0s - loss: 0.5613 - accuracy: 0.6996 - val_loss: 0.8424 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 738/1000\n",
            "2/2 - 0s - loss: 0.5488 - accuracy: 0.6996 - val_loss: 0.8414 - val_accuracy: 0.5156 - 46ms/epoch - 23ms/step\n",
            "Epoch 739/1000\n",
            "2/2 - 0s - loss: 0.5565 - accuracy: 0.7273 - val_loss: 0.8357 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 740/1000\n",
            "2/2 - 0s - loss: 0.5575 - accuracy: 0.7075 - val_loss: 0.8311 - val_accuracy: 0.4844 - 54ms/epoch - 27ms/step\n",
            "Epoch 741/1000\n",
            "2/2 - 0s - loss: 0.5280 - accuracy: 0.7312 - val_loss: 0.8264 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 742/1000\n",
            "2/2 - 0s - loss: 0.5534 - accuracy: 0.7273 - val_loss: 0.8233 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 743/1000\n",
            "2/2 - 0s - loss: 0.5348 - accuracy: 0.7036 - val_loss: 0.8222 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 744/1000\n",
            "2/2 - 0s - loss: 0.5634 - accuracy: 0.6957 - val_loss: 0.8233 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 745/1000\n",
            "2/2 - 0s - loss: 0.5710 - accuracy: 0.6917 - val_loss: 0.8222 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 746/1000\n",
            "2/2 - 0s - loss: 0.5732 - accuracy: 0.7036 - val_loss: 0.8220 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 747/1000\n",
            "2/2 - 0s - loss: 0.5411 - accuracy: 0.7115 - val_loss: 0.8205 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 748/1000\n",
            "2/2 - 0s - loss: 0.5748 - accuracy: 0.6877 - val_loss: 0.8199 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 749/1000\n",
            "2/2 - 0s - loss: 0.5453 - accuracy: 0.7233 - val_loss: 0.8226 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 750/1000\n",
            "2/2 - 0s - loss: 0.5197 - accuracy: 0.7510 - val_loss: 0.8282 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 751/1000\n",
            "2/2 - 0s - loss: 0.5697 - accuracy: 0.6996 - val_loss: 0.8337 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 752/1000\n",
            "2/2 - 0s - loss: 0.5461 - accuracy: 0.7352 - val_loss: 0.8365 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 753/1000\n",
            "2/2 - 0s - loss: 0.5588 - accuracy: 0.7312 - val_loss: 0.8395 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 754/1000\n",
            "2/2 - 0s - loss: 0.5607 - accuracy: 0.7036 - val_loss: 0.8448 - val_accuracy: 0.4531 - 46ms/epoch - 23ms/step\n",
            "Epoch 755/1000\n",
            "2/2 - 0s - loss: 0.5477 - accuracy: 0.7431 - val_loss: 0.8487 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 756/1000\n",
            "2/2 - 0s - loss: 0.5699 - accuracy: 0.6957 - val_loss: 0.8521 - val_accuracy: 0.4531 - 44ms/epoch - 22ms/step\n",
            "Epoch 757/1000\n",
            "2/2 - 0s - loss: 0.5256 - accuracy: 0.7431 - val_loss: 0.8561 - val_accuracy: 0.4375 - 32ms/epoch - 16ms/step\n",
            "Epoch 758/1000\n",
            "2/2 - 0s - loss: 0.5535 - accuracy: 0.7154 - val_loss: 0.8565 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 759/1000\n",
            "2/2 - 0s - loss: 0.5589 - accuracy: 0.7154 - val_loss: 0.8561 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 760/1000\n",
            "2/2 - 0s - loss: 0.5403 - accuracy: 0.7075 - val_loss: 0.8554 - val_accuracy: 0.4531 - 41ms/epoch - 21ms/step\n",
            "Epoch 761/1000\n",
            "2/2 - 0s - loss: 0.5750 - accuracy: 0.6640 - val_loss: 0.8521 - val_accuracy: 0.4375 - 34ms/epoch - 17ms/step\n",
            "Epoch 762/1000\n",
            "2/2 - 0s - loss: 0.5599 - accuracy: 0.6996 - val_loss: 0.8497 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 763/1000\n",
            "2/2 - 0s - loss: 0.5356 - accuracy: 0.7194 - val_loss: 0.8390 - val_accuracy: 0.4375 - 35ms/epoch - 17ms/step\n",
            "Epoch 764/1000\n",
            "2/2 - 0s - loss: 0.5503 - accuracy: 0.6957 - val_loss: 0.8309 - val_accuracy: 0.4688 - 44ms/epoch - 22ms/step\n",
            "Epoch 765/1000\n",
            "2/2 - 0s - loss: 0.5555 - accuracy: 0.7194 - val_loss: 0.8241 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 766/1000\n",
            "2/2 - 0s - loss: 0.5665 - accuracy: 0.7115 - val_loss: 0.8171 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 767/1000\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7194 - val_loss: 0.8156 - val_accuracy: 0.5156 - 44ms/epoch - 22ms/step\n",
            "Epoch 768/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7115 - val_loss: 0.8157 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 769/1000\n",
            "2/2 - 0s - loss: 0.5425 - accuracy: 0.7352 - val_loss: 0.8171 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 770/1000\n",
            "2/2 - 0s - loss: 0.5634 - accuracy: 0.6996 - val_loss: 0.8195 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 771/1000\n",
            "2/2 - 0s - loss: 0.5374 - accuracy: 0.7391 - val_loss: 0.8218 - val_accuracy: 0.5156 - 39ms/epoch - 19ms/step\n",
            "Epoch 772/1000\n",
            "2/2 - 0s - loss: 0.5658 - accuracy: 0.7273 - val_loss: 0.8244 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 773/1000\n",
            "2/2 - 0s - loss: 0.5678 - accuracy: 0.6838 - val_loss: 0.8290 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 774/1000\n",
            "2/2 - 0s - loss: 0.5584 - accuracy: 0.6877 - val_loss: 0.8334 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 775/1000\n",
            "2/2 - 0s - loss: 0.5401 - accuracy: 0.7470 - val_loss: 0.8375 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 776/1000\n",
            "2/2 - 0s - loss: 0.5485 - accuracy: 0.7273 - val_loss: 0.8396 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 777/1000\n",
            "2/2 - 0s - loss: 0.5734 - accuracy: 0.7194 - val_loss: 0.8400 - val_accuracy: 0.4688 - 33ms/epoch - 16ms/step\n",
            "Epoch 778/1000\n",
            "2/2 - 0s - loss: 0.5448 - accuracy: 0.7273 - val_loss: 0.8408 - val_accuracy: 0.4531 - 37ms/epoch - 19ms/step\n",
            "Epoch 779/1000\n",
            "2/2 - 0s - loss: 0.5541 - accuracy: 0.7312 - val_loss: 0.8390 - val_accuracy: 0.4531 - 38ms/epoch - 19ms/step\n",
            "Epoch 780/1000\n",
            "2/2 - 0s - loss: 0.5502 - accuracy: 0.6957 - val_loss: 0.8321 - val_accuracy: 0.4219 - 35ms/epoch - 18ms/step\n",
            "Epoch 781/1000\n",
            "2/2 - 0s - loss: 0.5426 - accuracy: 0.7233 - val_loss: 0.8247 - val_accuracy: 0.4219 - 36ms/epoch - 18ms/step\n",
            "Epoch 782/1000\n",
            "2/2 - 0s - loss: 0.5608 - accuracy: 0.6759 - val_loss: 0.8205 - val_accuracy: 0.4375 - 36ms/epoch - 18ms/step\n",
            "Epoch 783/1000\n",
            "2/2 - 0s - loss: 0.5468 - accuracy: 0.7115 - val_loss: 0.8153 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 784/1000\n",
            "2/2 - 0s - loss: 0.5357 - accuracy: 0.7273 - val_loss: 0.8096 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 785/1000\n",
            "2/2 - 0s - loss: 0.5465 - accuracy: 0.7075 - val_loss: 0.8103 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 786/1000\n",
            "2/2 - 0s - loss: 0.5252 - accuracy: 0.7352 - val_loss: 0.8125 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 787/1000\n",
            "2/2 - 0s - loss: 0.5490 - accuracy: 0.7431 - val_loss: 0.8139 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 788/1000\n",
            "2/2 - 0s - loss: 0.5384 - accuracy: 0.7273 - val_loss: 0.8158 - val_accuracy: 0.5156 - 46ms/epoch - 23ms/step\n",
            "Epoch 789/1000\n",
            "2/2 - 0s - loss: 0.5577 - accuracy: 0.6957 - val_loss: 0.8174 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 790/1000\n",
            "2/2 - 0s - loss: 0.5569 - accuracy: 0.6996 - val_loss: 0.8218 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 791/1000\n",
            "2/2 - 0s - loss: 0.5547 - accuracy: 0.7075 - val_loss: 0.8243 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 792/1000\n",
            "2/2 - 0s - loss: 0.5634 - accuracy: 0.6957 - val_loss: 0.8243 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 793/1000\n",
            "2/2 - 0s - loss: 0.5255 - accuracy: 0.7352 - val_loss: 0.8240 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 794/1000\n",
            "2/2 - 0s - loss: 0.5454 - accuracy: 0.6996 - val_loss: 0.8247 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 795/1000\n",
            "2/2 - 0s - loss: 0.5138 - accuracy: 0.7470 - val_loss: 0.8256 - val_accuracy: 0.4844 - 43ms/epoch - 22ms/step\n",
            "Epoch 796/1000\n",
            "2/2 - 0s - loss: 0.5527 - accuracy: 0.6877 - val_loss: 0.8265 - val_accuracy: 0.4688 - 35ms/epoch - 17ms/step\n",
            "Epoch 797/1000\n",
            "2/2 - 0s - loss: 0.5677 - accuracy: 0.7154 - val_loss: 0.8268 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 798/1000\n",
            "2/2 - 0s - loss: 0.5476 - accuracy: 0.6877 - val_loss: 0.8269 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 799/1000\n",
            "2/2 - 0s - loss: 0.5266 - accuracy: 0.7312 - val_loss: 0.8252 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 800/1000\n",
            "2/2 - 0s - loss: 0.5285 - accuracy: 0.7352 - val_loss: 0.8273 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 801/1000\n",
            "2/2 - 0s - loss: 0.5729 - accuracy: 0.6877 - val_loss: 0.8305 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 802/1000\n",
            "2/2 - 0s - loss: 0.5437 - accuracy: 0.7391 - val_loss: 0.8313 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 803/1000\n",
            "2/2 - 0s - loss: 0.5637 - accuracy: 0.7115 - val_loss: 0.8298 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 804/1000\n",
            "2/2 - 0s - loss: 0.5308 - accuracy: 0.7431 - val_loss: 0.8281 - val_accuracy: 0.5000 - 31ms/epoch - 15ms/step\n",
            "Epoch 805/1000\n",
            "2/2 - 0s - loss: 0.5635 - accuracy: 0.7391 - val_loss: 0.8261 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 806/1000\n",
            "2/2 - 0s - loss: 0.5429 - accuracy: 0.7273 - val_loss: 0.8276 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 807/1000\n",
            "2/2 - 0s - loss: 0.5059 - accuracy: 0.7747 - val_loss: 0.8307 - val_accuracy: 0.5000 - 32ms/epoch - 16ms/step\n",
            "Epoch 808/1000\n",
            "2/2 - 0s - loss: 0.5538 - accuracy: 0.7470 - val_loss: 0.8331 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 809/1000\n",
            "2/2 - 0s - loss: 0.5511 - accuracy: 0.7194 - val_loss: 0.8353 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 810/1000\n",
            "2/2 - 0s - loss: 0.5433 - accuracy: 0.7075 - val_loss: 0.8395 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 811/1000\n",
            "2/2 - 0s - loss: 0.5466 - accuracy: 0.7470 - val_loss: 0.8408 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 812/1000\n",
            "2/2 - 0s - loss: 0.5419 - accuracy: 0.7194 - val_loss: 0.8408 - val_accuracy: 0.5000 - 51ms/epoch - 25ms/step\n",
            "Epoch 813/1000\n",
            "2/2 - 0s - loss: 0.5290 - accuracy: 0.7431 - val_loss: 0.8411 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 814/1000\n",
            "2/2 - 0s - loss: 0.5330 - accuracy: 0.7194 - val_loss: 0.8443 - val_accuracy: 0.5000 - 39ms/epoch - 20ms/step\n",
            "Epoch 815/1000\n",
            "2/2 - 0s - loss: 0.5382 - accuracy: 0.7391 - val_loss: 0.8457 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 816/1000\n",
            "2/2 - 0s - loss: 0.5558 - accuracy: 0.6838 - val_loss: 0.8465 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 817/1000\n",
            "2/2 - 0s - loss: 0.5190 - accuracy: 0.7549 - val_loss: 0.8489 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 818/1000\n",
            "2/2 - 0s - loss: 0.5309 - accuracy: 0.7154 - val_loss: 0.8539 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 819/1000\n",
            "2/2 - 0s - loss: 0.5143 - accuracy: 0.7470 - val_loss: 0.8579 - val_accuracy: 0.4375 - 35ms/epoch - 18ms/step\n",
            "Epoch 820/1000\n",
            "2/2 - 0s - loss: 0.5284 - accuracy: 0.7628 - val_loss: 0.8615 - val_accuracy: 0.4375 - 40ms/epoch - 20ms/step\n",
            "Epoch 821/1000\n",
            "2/2 - 0s - loss: 0.5242 - accuracy: 0.7470 - val_loss: 0.8613 - val_accuracy: 0.4375 - 37ms/epoch - 18ms/step\n",
            "Epoch 822/1000\n",
            "2/2 - 0s - loss: 0.5252 - accuracy: 0.7510 - val_loss: 0.8593 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 823/1000\n",
            "2/2 - 0s - loss: 0.5344 - accuracy: 0.7391 - val_loss: 0.8548 - val_accuracy: 0.5000 - 42ms/epoch - 21ms/step\n",
            "Epoch 824/1000\n",
            "2/2 - 0s - loss: 0.5474 - accuracy: 0.7431 - val_loss: 0.8506 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 825/1000\n",
            "2/2 - 0s - loss: 0.5501 - accuracy: 0.7154 - val_loss: 0.8472 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 826/1000\n",
            "2/2 - 0s - loss: 0.5359 - accuracy: 0.7352 - val_loss: 0.8422 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 827/1000\n",
            "2/2 - 0s - loss: 0.5213 - accuracy: 0.7154 - val_loss: 0.8401 - val_accuracy: 0.5156 - 31ms/epoch - 15ms/step\n",
            "Epoch 828/1000\n",
            "2/2 - 0s - loss: 0.5401 - accuracy: 0.7273 - val_loss: 0.8414 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 829/1000\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7312 - val_loss: 0.8375 - val_accuracy: 0.5156 - 43ms/epoch - 21ms/step\n",
            "Epoch 830/1000\n",
            "2/2 - 0s - loss: 0.5073 - accuracy: 0.7470 - val_loss: 0.8374 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 831/1000\n",
            "2/2 - 0s - loss: 0.5401 - accuracy: 0.7233 - val_loss: 0.8400 - val_accuracy: 0.5156 - 39ms/epoch - 20ms/step\n",
            "Epoch 832/1000\n",
            "2/2 - 0s - loss: 0.5298 - accuracy: 0.7431 - val_loss: 0.8444 - val_accuracy: 0.5000 - 34ms/epoch - 17ms/step\n",
            "Epoch 833/1000\n",
            "2/2 - 0s - loss: 0.5461 - accuracy: 0.7312 - val_loss: 0.8508 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 834/1000\n",
            "2/2 - 0s - loss: 0.5042 - accuracy: 0.7668 - val_loss: 0.8575 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 835/1000\n",
            "2/2 - 0s - loss: 0.5089 - accuracy: 0.7589 - val_loss: 0.8659 - val_accuracy: 0.5000 - 35ms/epoch - 17ms/step\n",
            "Epoch 836/1000\n",
            "2/2 - 0s - loss: 0.5392 - accuracy: 0.7312 - val_loss: 0.8679 - val_accuracy: 0.5000 - 33ms/epoch - 17ms/step\n",
            "Epoch 837/1000\n",
            "2/2 - 0s - loss: 0.5579 - accuracy: 0.7036 - val_loss: 0.8688 - val_accuracy: 0.5000 - 44ms/epoch - 22ms/step\n",
            "Epoch 838/1000\n",
            "2/2 - 0s - loss: 0.5419 - accuracy: 0.7273 - val_loss: 0.8681 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 839/1000\n",
            "2/2 - 0s - loss: 0.5298 - accuracy: 0.7431 - val_loss: 0.8651 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 840/1000\n",
            "2/2 - 0s - loss: 0.5263 - accuracy: 0.7312 - val_loss: 0.8608 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 841/1000\n",
            "2/2 - 0s - loss: 0.5370 - accuracy: 0.7510 - val_loss: 0.8573 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 842/1000\n",
            "2/2 - 0s - loss: 0.5187 - accuracy: 0.7510 - val_loss: 0.8526 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 843/1000\n",
            "2/2 - 0s - loss: 0.5474 - accuracy: 0.7549 - val_loss: 0.8471 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 844/1000\n",
            "2/2 - 0s - loss: 0.5427 - accuracy: 0.7352 - val_loss: 0.8436 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 845/1000\n",
            "2/2 - 0s - loss: 0.5599 - accuracy: 0.7233 - val_loss: 0.8419 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 846/1000\n",
            "2/2 - 0s - loss: 0.5310 - accuracy: 0.7273 - val_loss: 0.8424 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 847/1000\n",
            "2/2 - 0s - loss: 0.5736 - accuracy: 0.6957 - val_loss: 0.8380 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 848/1000\n",
            "2/2 - 0s - loss: 0.5481 - accuracy: 0.6877 - val_loss: 0.8364 - val_accuracy: 0.4688 - 37ms/epoch - 19ms/step\n",
            "Epoch 849/1000\n",
            "2/2 - 0s - loss: 0.5538 - accuracy: 0.7075 - val_loss: 0.8353 - val_accuracy: 0.4531 - 37ms/epoch - 18ms/step\n",
            "Epoch 850/1000\n",
            "2/2 - 0s - loss: 0.5204 - accuracy: 0.7510 - val_loss: 0.8385 - val_accuracy: 0.4531 - 47ms/epoch - 23ms/step\n",
            "Epoch 851/1000\n",
            "2/2 - 0s - loss: 0.5444 - accuracy: 0.7352 - val_loss: 0.8413 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 852/1000\n",
            "2/2 - 0s - loss: 0.5391 - accuracy: 0.7431 - val_loss: 0.8405 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 853/1000\n",
            "2/2 - 0s - loss: 0.5230 - accuracy: 0.7589 - val_loss: 0.8367 - val_accuracy: 0.4531 - 32ms/epoch - 16ms/step\n",
            "Epoch 854/1000\n",
            "2/2 - 0s - loss: 0.5585 - accuracy: 0.7036 - val_loss: 0.8307 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 855/1000\n",
            "2/2 - 0s - loss: 0.5260 - accuracy: 0.7115 - val_loss: 0.8278 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 856/1000\n",
            "2/2 - 0s - loss: 0.5518 - accuracy: 0.7154 - val_loss: 0.8256 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 857/1000\n",
            "2/2 - 0s - loss: 0.5627 - accuracy: 0.6759 - val_loss: 0.8257 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 858/1000\n",
            "2/2 - 0s - loss: 0.5271 - accuracy: 0.7273 - val_loss: 0.8262 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 859/1000\n",
            "2/2 - 0s - loss: 0.5495 - accuracy: 0.6957 - val_loss: 0.8278 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 860/1000\n",
            "2/2 - 0s - loss: 0.5290 - accuracy: 0.7075 - val_loss: 0.8285 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 861/1000\n",
            "2/2 - 0s - loss: 0.5415 - accuracy: 0.7431 - val_loss: 0.8271 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 862/1000\n",
            "2/2 - 0s - loss: 0.5240 - accuracy: 0.7154 - val_loss: 0.8258 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 863/1000\n",
            "2/2 - 0s - loss: 0.5488 - accuracy: 0.7431 - val_loss: 0.8265 - val_accuracy: 0.5156 - 33ms/epoch - 16ms/step\n",
            "Epoch 864/1000\n",
            "2/2 - 0s - loss: 0.5320 - accuracy: 0.7470 - val_loss: 0.8261 - val_accuracy: 0.5156 - 37ms/epoch - 19ms/step\n",
            "Epoch 865/1000\n",
            "2/2 - 0s - loss: 0.5308 - accuracy: 0.7352 - val_loss: 0.8255 - val_accuracy: 0.5312 - 39ms/epoch - 19ms/step\n",
            "Epoch 866/1000\n",
            "2/2 - 0s - loss: 0.5522 - accuracy: 0.7233 - val_loss: 0.8222 - val_accuracy: 0.5312 - 46ms/epoch - 23ms/step\n",
            "Epoch 867/1000\n",
            "2/2 - 0s - loss: 0.5468 - accuracy: 0.6996 - val_loss: 0.8196 - val_accuracy: 0.5312 - 39ms/epoch - 20ms/step\n",
            "Epoch 868/1000\n",
            "2/2 - 0s - loss: 0.5302 - accuracy: 0.6957 - val_loss: 0.8199 - val_accuracy: 0.5312 - 40ms/epoch - 20ms/step\n",
            "Epoch 869/1000\n",
            "2/2 - 0s - loss: 0.5335 - accuracy: 0.7470 - val_loss: 0.8204 - val_accuracy: 0.5312 - 37ms/epoch - 18ms/step\n",
            "Epoch 870/1000\n",
            "2/2 - 0s - loss: 0.5573 - accuracy: 0.7312 - val_loss: 0.8200 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 871/1000\n",
            "2/2 - 0s - loss: 0.5423 - accuracy: 0.7036 - val_loss: 0.8212 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 872/1000\n",
            "2/2 - 0s - loss: 0.5522 - accuracy: 0.7036 - val_loss: 0.8233 - val_accuracy: 0.4844 - 43ms/epoch - 22ms/step\n",
            "Epoch 873/1000\n",
            "2/2 - 0s - loss: 0.5362 - accuracy: 0.6996 - val_loss: 0.8252 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 874/1000\n",
            "2/2 - 0s - loss: 0.5382 - accuracy: 0.7312 - val_loss: 0.8269 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 875/1000\n",
            "2/2 - 0s - loss: 0.5452 - accuracy: 0.7273 - val_loss: 0.8299 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 876/1000\n",
            "2/2 - 0s - loss: 0.5552 - accuracy: 0.7273 - val_loss: 0.8304 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 877/1000\n",
            "2/2 - 0s - loss: 0.5249 - accuracy: 0.7628 - val_loss: 0.8307 - val_accuracy: 0.5000 - 53ms/epoch - 26ms/step\n",
            "Epoch 878/1000\n",
            "2/2 - 0s - loss: 0.5697 - accuracy: 0.6996 - val_loss: 0.8343 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 879/1000\n",
            "2/2 - 0s - loss: 0.5384 - accuracy: 0.7273 - val_loss: 0.8384 - val_accuracy: 0.5000 - 31ms/epoch - 16ms/step\n",
            "Epoch 880/1000\n",
            "2/2 - 0s - loss: 0.5447 - accuracy: 0.6957 - val_loss: 0.8404 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 881/1000\n",
            "2/2 - 0s - loss: 0.5128 - accuracy: 0.7510 - val_loss: 0.8434 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 882/1000\n",
            "2/2 - 0s - loss: 0.5370 - accuracy: 0.7312 - val_loss: 0.8463 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 883/1000\n",
            "2/2 - 0s - loss: 0.5381 - accuracy: 0.7194 - val_loss: 0.8483 - val_accuracy: 0.5156 - 41ms/epoch - 20ms/step\n",
            "Epoch 884/1000\n",
            "2/2 - 0s - loss: 0.5338 - accuracy: 0.7352 - val_loss: 0.8504 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 885/1000\n",
            "2/2 - 0s - loss: 0.5583 - accuracy: 0.7194 - val_loss: 0.8511 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 886/1000\n",
            "2/2 - 0s - loss: 0.5527 - accuracy: 0.6957 - val_loss: 0.8544 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 887/1000\n",
            "2/2 - 0s - loss: 0.5139 - accuracy: 0.7628 - val_loss: 0.8552 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 888/1000\n",
            "2/2 - 0s - loss: 0.5352 - accuracy: 0.7510 - val_loss: 0.8517 - val_accuracy: 0.5156 - 35ms/epoch - 18ms/step\n",
            "Epoch 889/1000\n",
            "2/2 - 0s - loss: 0.5735 - accuracy: 0.7154 - val_loss: 0.8495 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 890/1000\n",
            "2/2 - 0s - loss: 0.5244 - accuracy: 0.7747 - val_loss: 0.8442 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 891/1000\n",
            "2/2 - 0s - loss: 0.5446 - accuracy: 0.7273 - val_loss: 0.8400 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 892/1000\n",
            "2/2 - 0s - loss: 0.5405 - accuracy: 0.7115 - val_loss: 0.8374 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 893/1000\n",
            "2/2 - 0s - loss: 0.5600 - accuracy: 0.7312 - val_loss: 0.8344 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 894/1000\n",
            "2/2 - 0s - loss: 0.5302 - accuracy: 0.7273 - val_loss: 0.8336 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 895/1000\n",
            "2/2 - 0s - loss: 0.5283 - accuracy: 0.7273 - val_loss: 0.8352 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 896/1000\n",
            "2/2 - 0s - loss: 0.5208 - accuracy: 0.7470 - val_loss: 0.8420 - val_accuracy: 0.4844 - 32ms/epoch - 16ms/step\n",
            "Epoch 897/1000\n",
            "2/2 - 0s - loss: 0.5505 - accuracy: 0.7312 - val_loss: 0.8451 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 898/1000\n",
            "2/2 - 0s - loss: 0.5397 - accuracy: 0.7431 - val_loss: 0.8464 - val_accuracy: 0.4531 - 39ms/epoch - 20ms/step\n",
            "Epoch 899/1000\n",
            "2/2 - 0s - loss: 0.5018 - accuracy: 0.7826 - val_loss: 0.8461 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 900/1000\n",
            "2/2 - 0s - loss: 0.5226 - accuracy: 0.7352 - val_loss: 0.8456 - val_accuracy: 0.4531 - 39ms/epoch - 19ms/step\n",
            "Epoch 901/1000\n",
            "2/2 - 0s - loss: 0.5354 - accuracy: 0.7431 - val_loss: 0.8469 - val_accuracy: 0.4531 - 36ms/epoch - 18ms/step\n",
            "Epoch 902/1000\n",
            "2/2 - 0s - loss: 0.5396 - accuracy: 0.6996 - val_loss: 0.8474 - val_accuracy: 0.4688 - 33ms/epoch - 17ms/step\n",
            "Epoch 903/1000\n",
            "2/2 - 0s - loss: 0.5402 - accuracy: 0.7154 - val_loss: 0.8505 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 904/1000\n",
            "2/2 - 0s - loss: 0.5373 - accuracy: 0.7431 - val_loss: 0.8549 - val_accuracy: 0.4688 - 38ms/epoch - 19ms/step\n",
            "Epoch 905/1000\n",
            "2/2 - 0s - loss: 0.5122 - accuracy: 0.7510 - val_loss: 0.8579 - val_accuracy: 0.4688 - 43ms/epoch - 22ms/step\n",
            "Epoch 906/1000\n",
            "2/2 - 0s - loss: 0.5172 - accuracy: 0.7273 - val_loss: 0.8632 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 907/1000\n",
            "2/2 - 0s - loss: 0.5083 - accuracy: 0.7708 - val_loss: 0.8716 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 908/1000\n",
            "2/2 - 0s - loss: 0.5334 - accuracy: 0.7273 - val_loss: 0.8750 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 909/1000\n",
            "2/2 - 0s - loss: 0.5241 - accuracy: 0.7312 - val_loss: 0.8743 - val_accuracy: 0.4688 - 48ms/epoch - 24ms/step\n",
            "Epoch 910/1000\n",
            "2/2 - 0s - loss: 0.5397 - accuracy: 0.7075 - val_loss: 0.8715 - val_accuracy: 0.4688 - 31ms/epoch - 16ms/step\n",
            "Epoch 911/1000\n",
            "2/2 - 0s - loss: 0.5161 - accuracy: 0.7352 - val_loss: 0.8694 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 912/1000\n",
            "2/2 - 0s - loss: 0.5403 - accuracy: 0.7391 - val_loss: 0.8660 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 913/1000\n",
            "2/2 - 0s - loss: 0.5227 - accuracy: 0.7589 - val_loss: 0.8612 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 914/1000\n",
            "2/2 - 0s - loss: 0.5309 - accuracy: 0.7194 - val_loss: 0.8593 - val_accuracy: 0.5000 - 35ms/epoch - 18ms/step\n",
            "Epoch 915/1000\n",
            "2/2 - 0s - loss: 0.5175 - accuracy: 0.7510 - val_loss: 0.8583 - val_accuracy: 0.5156 - 37ms/epoch - 18ms/step\n",
            "Epoch 916/1000\n",
            "2/2 - 0s - loss: 0.5161 - accuracy: 0.7470 - val_loss: 0.8595 - val_accuracy: 0.5156 - 51ms/epoch - 26ms/step\n",
            "Epoch 917/1000\n",
            "2/2 - 0s - loss: 0.5247 - accuracy: 0.7233 - val_loss: 0.8637 - val_accuracy: 0.5156 - 53ms/epoch - 26ms/step\n",
            "Epoch 918/1000\n",
            "2/2 - 0s - loss: 0.5454 - accuracy: 0.7431 - val_loss: 0.8703 - val_accuracy: 0.5156 - 43ms/epoch - 22ms/step\n",
            "Epoch 919/1000\n",
            "2/2 - 0s - loss: 0.5276 - accuracy: 0.7352 - val_loss: 0.8760 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 920/1000\n",
            "2/2 - 0s - loss: 0.5385 - accuracy: 0.7233 - val_loss: 0.8779 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 921/1000\n",
            "2/2 - 0s - loss: 0.5384 - accuracy: 0.6996 - val_loss: 0.8803 - val_accuracy: 0.4531 - 35ms/epoch - 18ms/step\n",
            "Epoch 922/1000\n",
            "2/2 - 0s - loss: 0.5417 - accuracy: 0.7352 - val_loss: 0.8784 - val_accuracy: 0.4375 - 43ms/epoch - 21ms/step\n",
            "Epoch 923/1000\n",
            "2/2 - 0s - loss: 0.6145 - accuracy: 0.7075 - val_loss: 0.8697 - val_accuracy: 0.4531 - 40ms/epoch - 20ms/step\n",
            "Epoch 924/1000\n",
            "2/2 - 0s - loss: 0.5159 - accuracy: 0.7510 - val_loss: 0.8619 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 925/1000\n",
            "2/2 - 0s - loss: 0.5256 - accuracy: 0.7273 - val_loss: 0.8567 - val_accuracy: 0.5000 - 39ms/epoch - 19ms/step\n",
            "Epoch 926/1000\n",
            "2/2 - 0s - loss: 0.5215 - accuracy: 0.7233 - val_loss: 0.8525 - val_accuracy: 0.5000 - 37ms/epoch - 18ms/step\n",
            "Epoch 927/1000\n",
            "2/2 - 0s - loss: 0.5166 - accuracy: 0.7352 - val_loss: 0.8519 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 928/1000\n",
            "2/2 - 0s - loss: 0.5399 - accuracy: 0.7194 - val_loss: 0.8529 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 929/1000\n",
            "2/2 - 0s - loss: 0.5296 - accuracy: 0.7154 - val_loss: 0.8564 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 930/1000\n",
            "2/2 - 0s - loss: 0.5245 - accuracy: 0.7194 - val_loss: 0.8616 - val_accuracy: 0.4844 - 41ms/epoch - 21ms/step\n",
            "Epoch 931/1000\n",
            "2/2 - 0s - loss: 0.5317 - accuracy: 0.7589 - val_loss: 0.8649 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 932/1000\n",
            "2/2 - 0s - loss: 0.5015 - accuracy: 0.7826 - val_loss: 0.8658 - val_accuracy: 0.4844 - 44ms/epoch - 22ms/step\n",
            "Epoch 933/1000\n",
            "2/2 - 0s - loss: 0.5357 - accuracy: 0.7312 - val_loss: 0.8653 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 934/1000\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7470 - val_loss: 0.8626 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 935/1000\n",
            "2/2 - 0s - loss: 0.5487 - accuracy: 0.7312 - val_loss: 0.8591 - val_accuracy: 0.5000 - 36ms/epoch - 18ms/step\n",
            "Epoch 936/1000\n",
            "2/2 - 0s - loss: 0.5217 - accuracy: 0.7431 - val_loss: 0.8561 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 937/1000\n",
            "2/2 - 0s - loss: 0.5249 - accuracy: 0.7470 - val_loss: 0.8510 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 938/1000\n",
            "2/2 - 0s - loss: 0.5430 - accuracy: 0.7154 - val_loss: 0.8483 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 939/1000\n",
            "2/2 - 0s - loss: 0.4937 - accuracy: 0.7747 - val_loss: 0.8465 - val_accuracy: 0.5156 - 34ms/epoch - 17ms/step\n",
            "Epoch 940/1000\n",
            "2/2 - 0s - loss: 0.5556 - accuracy: 0.7431 - val_loss: 0.8478 - val_accuracy: 0.5156 - 36ms/epoch - 18ms/step\n",
            "Epoch 941/1000\n",
            "2/2 - 0s - loss: 0.5373 - accuracy: 0.7470 - val_loss: 0.8455 - val_accuracy: 0.5000 - 56ms/epoch - 28ms/step\n",
            "Epoch 942/1000\n",
            "2/2 - 0s - loss: 0.5252 - accuracy: 0.7194 - val_loss: 0.8449 - val_accuracy: 0.5000 - 43ms/epoch - 22ms/step\n",
            "Epoch 943/1000\n",
            "2/2 - 0s - loss: 0.5286 - accuracy: 0.7391 - val_loss: 0.8456 - val_accuracy: 0.4844 - 31ms/epoch - 15ms/step\n",
            "Epoch 944/1000\n",
            "2/2 - 0s - loss: 0.5393 - accuracy: 0.7273 - val_loss: 0.8452 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 945/1000\n",
            "2/2 - 0s - loss: 0.5314 - accuracy: 0.7312 - val_loss: 0.8460 - val_accuracy: 0.4844 - 46ms/epoch - 23ms/step\n",
            "Epoch 946/1000\n",
            "2/2 - 0s - loss: 0.5184 - accuracy: 0.7470 - val_loss: 0.8485 - val_accuracy: 0.4688 - 39ms/epoch - 19ms/step\n",
            "Epoch 947/1000\n",
            "2/2 - 0s - loss: 0.5419 - accuracy: 0.7352 - val_loss: 0.8501 - val_accuracy: 0.4688 - 39ms/epoch - 20ms/step\n",
            "Epoch 948/1000\n",
            "2/2 - 0s - loss: 0.5242 - accuracy: 0.7233 - val_loss: 0.8526 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 949/1000\n",
            "2/2 - 0s - loss: 0.5102 - accuracy: 0.7549 - val_loss: 0.8539 - val_accuracy: 0.4844 - 40ms/epoch - 20ms/step\n",
            "Epoch 950/1000\n",
            "2/2 - 0s - loss: 0.5377 - accuracy: 0.7273 - val_loss: 0.8561 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 951/1000\n",
            "2/2 - 0s - loss: 0.5200 - accuracy: 0.7589 - val_loss: 0.8548 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 952/1000\n",
            "2/2 - 0s - loss: 0.5258 - accuracy: 0.7273 - val_loss: 0.8563 - val_accuracy: 0.4688 - 42ms/epoch - 21ms/step\n",
            "Epoch 953/1000\n",
            "2/2 - 0s - loss: 0.5453 - accuracy: 0.7352 - val_loss: 0.8574 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 954/1000\n",
            "2/2 - 0s - loss: 0.5449 - accuracy: 0.7075 - val_loss: 0.8581 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 955/1000\n",
            "2/2 - 0s - loss: 0.5162 - accuracy: 0.7470 - val_loss: 0.8584 - val_accuracy: 0.4688 - 43ms/epoch - 22ms/step\n",
            "Epoch 956/1000\n",
            "2/2 - 0s - loss: 0.5262 - accuracy: 0.7115 - val_loss: 0.8587 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 957/1000\n",
            "2/2 - 0s - loss: 0.5304 - accuracy: 0.7470 - val_loss: 0.8597 - val_accuracy: 0.4844 - 35ms/epoch - 18ms/step\n",
            "Epoch 958/1000\n",
            "2/2 - 0s - loss: 0.5048 - accuracy: 0.7668 - val_loss: 0.8591 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 959/1000\n",
            "2/2 - 0s - loss: 0.5460 - accuracy: 0.7036 - val_loss: 0.8606 - val_accuracy: 0.4844 - 39ms/epoch - 20ms/step\n",
            "Epoch 960/1000\n",
            "2/2 - 0s - loss: 0.5275 - accuracy: 0.7470 - val_loss: 0.8627 - val_accuracy: 0.4688 - 36ms/epoch - 18ms/step\n",
            "Epoch 961/1000\n",
            "2/2 - 0s - loss: 0.5262 - accuracy: 0.7589 - val_loss: 0.8632 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 962/1000\n",
            "2/2 - 0s - loss: 0.5358 - accuracy: 0.7115 - val_loss: 0.8629 - val_accuracy: 0.4844 - 41ms/epoch - 20ms/step\n",
            "Epoch 963/1000\n",
            "2/2 - 0s - loss: 0.5390 - accuracy: 0.7470 - val_loss: 0.8624 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 964/1000\n",
            "2/2 - 0s - loss: 0.5470 - accuracy: 0.7075 - val_loss: 0.8643 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 965/1000\n",
            "2/2 - 0s - loss: 0.5286 - accuracy: 0.7312 - val_loss: 0.8682 - val_accuracy: 0.4844 - 34ms/epoch - 17ms/step\n",
            "Epoch 966/1000\n",
            "2/2 - 0s - loss: 0.5312 - accuracy: 0.7391 - val_loss: 0.8732 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 967/1000\n",
            "2/2 - 0s - loss: 0.5115 - accuracy: 0.7549 - val_loss: 0.8783 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 968/1000\n",
            "2/2 - 0s - loss: 0.5182 - accuracy: 0.7431 - val_loss: 0.8842 - val_accuracy: 0.4844 - 58ms/epoch - 29ms/step\n",
            "Epoch 969/1000\n",
            "2/2 - 0s - loss: 0.5030 - accuracy: 0.7708 - val_loss: 0.8877 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 970/1000\n",
            "2/2 - 0s - loss: 0.5244 - accuracy: 0.7312 - val_loss: 0.8865 - val_accuracy: 0.5000 - 40ms/epoch - 20ms/step\n",
            "Epoch 971/1000\n",
            "2/2 - 0s - loss: 0.5363 - accuracy: 0.7233 - val_loss: 0.8817 - val_accuracy: 0.5000 - 41ms/epoch - 20ms/step\n",
            "Epoch 972/1000\n",
            "2/2 - 0s - loss: 0.5188 - accuracy: 0.7391 - val_loss: 0.8820 - val_accuracy: 0.5000 - 41ms/epoch - 21ms/step\n",
            "Epoch 973/1000\n",
            "2/2 - 0s - loss: 0.5603 - accuracy: 0.6996 - val_loss: 0.8835 - val_accuracy: 0.5000 - 37ms/epoch - 19ms/step\n",
            "Epoch 974/1000\n",
            "2/2 - 0s - loss: 0.5052 - accuracy: 0.7589 - val_loss: 0.8826 - val_accuracy: 0.4844 - 42ms/epoch - 21ms/step\n",
            "Epoch 975/1000\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7391 - val_loss: 0.8762 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 976/1000\n",
            "2/2 - 0s - loss: 0.5217 - accuracy: 0.7470 - val_loss: 0.8725 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 977/1000\n",
            "2/2 - 0s - loss: 0.5284 - accuracy: 0.7628 - val_loss: 0.8706 - val_accuracy: 0.4844 - 39ms/epoch - 19ms/step\n",
            "Epoch 978/1000\n",
            "2/2 - 0s - loss: 0.5303 - accuracy: 0.7312 - val_loss: 0.8692 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 979/1000\n",
            "2/2 - 0s - loss: 0.5137 - accuracy: 0.7708 - val_loss: 0.8662 - val_accuracy: 0.4844 - 45ms/epoch - 23ms/step\n",
            "Epoch 980/1000\n",
            "2/2 - 0s - loss: 0.5021 - accuracy: 0.7826 - val_loss: 0.8640 - val_accuracy: 0.4844 - 35ms/epoch - 17ms/step\n",
            "Epoch 981/1000\n",
            "2/2 - 0s - loss: 0.4950 - accuracy: 0.7549 - val_loss: 0.8631 - val_accuracy: 0.5156 - 32ms/epoch - 16ms/step\n",
            "Epoch 982/1000\n",
            "2/2 - 0s - loss: 0.5345 - accuracy: 0.7312 - val_loss: 0.8630 - val_accuracy: 0.5156 - 38ms/epoch - 19ms/step\n",
            "Epoch 983/1000\n",
            "2/2 - 0s - loss: 0.5331 - accuracy: 0.7194 - val_loss: 0.8644 - val_accuracy: 0.5156 - 33ms/epoch - 17ms/step\n",
            "Epoch 984/1000\n",
            "2/2 - 0s - loss: 0.4960 - accuracy: 0.7549 - val_loss: 0.8695 - val_accuracy: 0.5000 - 38ms/epoch - 19ms/step\n",
            "Epoch 985/1000\n",
            "2/2 - 0s - loss: 0.5147 - accuracy: 0.7589 - val_loss: 0.8750 - val_accuracy: 0.4844 - 38ms/epoch - 19ms/step\n",
            "Epoch 986/1000\n",
            "2/2 - 0s - loss: 0.5274 - accuracy: 0.7470 - val_loss: 0.8804 - val_accuracy: 0.4688 - 34ms/epoch - 17ms/step\n",
            "Epoch 987/1000\n",
            "2/2 - 0s - loss: 0.5119 - accuracy: 0.7352 - val_loss: 0.8842 - val_accuracy: 0.4688 - 37ms/epoch - 18ms/step\n",
            "Epoch 988/1000\n",
            "2/2 - 0s - loss: 0.5525 - accuracy: 0.6957 - val_loss: 0.8843 - val_accuracy: 0.4688 - 35ms/epoch - 18ms/step\n",
            "Epoch 989/1000\n",
            "2/2 - 0s - loss: 0.5307 - accuracy: 0.7391 - val_loss: 0.8794 - val_accuracy: 0.4688 - 40ms/epoch - 20ms/step\n",
            "Epoch 990/1000\n",
            "2/2 - 0s - loss: 0.5012 - accuracy: 0.7826 - val_loss: 0.8749 - val_accuracy: 0.4844 - 37ms/epoch - 19ms/step\n",
            "Epoch 991/1000\n",
            "2/2 - 0s - loss: 0.5086 - accuracy: 0.7391 - val_loss: 0.8721 - val_accuracy: 0.5156 - 35ms/epoch - 17ms/step\n",
            "Epoch 992/1000\n",
            "2/2 - 0s - loss: 0.5030 - accuracy: 0.7510 - val_loss: 0.8676 - val_accuracy: 0.5156 - 42ms/epoch - 21ms/step\n",
            "Epoch 993/1000\n",
            "2/2 - 0s - loss: 0.4898 - accuracy: 0.7628 - val_loss: 0.8661 - val_accuracy: 0.5156 - 39ms/epoch - 19ms/step\n",
            "Epoch 994/1000\n",
            "2/2 - 0s - loss: 0.5318 - accuracy: 0.7154 - val_loss: 0.8657 - val_accuracy: 0.5156 - 40ms/epoch - 20ms/step\n",
            "Epoch 995/1000\n",
            "2/2 - 0s - loss: 0.5150 - accuracy: 0.7510 - val_loss: 0.8672 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 996/1000\n",
            "2/2 - 0s - loss: 0.5469 - accuracy: 0.7194 - val_loss: 0.8673 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 997/1000\n",
            "2/2 - 0s - loss: 0.5432 - accuracy: 0.7115 - val_loss: 0.8650 - val_accuracy: 0.4844 - 37ms/epoch - 18ms/step\n",
            "Epoch 998/1000\n",
            "2/2 - 0s - loss: 0.5594 - accuracy: 0.6957 - val_loss: 0.8637 - val_accuracy: 0.4844 - 36ms/epoch - 18ms/step\n",
            "Epoch 999/1000\n",
            "2/2 - 0s - loss: 0.5305 - accuracy: 0.7312 - val_loss: 0.8610 - val_accuracy: 0.4844 - 33ms/epoch - 17ms/step\n",
            "Epoch 1000/1000\n",
            "2/2 - 0s - loss: 0.5209 - accuracy: 0.7312 - val_loss: 0.8595 - val_accuracy: 0.5000 - 48ms/epoch - 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9c8a88c10>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evalaute evaluate Accury, and print out\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print()  \n",
        "print(\"\\t[Info] Accuracy of testing data = {:2.1f}%\".format(score[1]*100.0)) \n",
        "#print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnctAHNo510",
        "outputId": "85699316-5141-4072-ef7a-6a142fbd33ad"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7443 - accuracy: 0.5625\n",
            "\n",
            "\t[Info] Accuracy of testing data = 56.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 預測(prediction)\n",
        "# X = X_test[0:20,:]\n",
        "# #predictions = model.predict_classes(X)\n",
        "# mypredictions = model.predict(X).astype('int64')\n",
        "# classes_x = np.argmax(mypredictions, axis = 1)\n",
        "# classes_x\n",
        "\n",
        "#myPredict = model.predict_classes( X_test).astype('int64')\n",
        "myPredict=model.predict(X_test).astype('int64') \n",
        "classes_x=np.argmax(myPredict,axis=1)\n",
        "#print(classes_x)\n",
        "#classes_x"
      ],
      "metadata": {
        "id": "NQs9yzfqnE-7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_test\n",
        "#混淆矩陣 (confusion matrix)  -> cross table\n",
        "print(y_test_cross)\n",
        "print(classes_x)\n",
        "pd.crosstab(y_test_cross,classes_x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "gipn3pzYpIQG",
        "outputId": "1fc9e4cb-eb6a-4ce3-a89e-7c05a240c17d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1\n",
            " 1 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0\n",
            " 0 1 0 1 1 1]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0   0\n",
              "row_0    \n",
              "0      35\n",
              "1      45"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a00fd41-b5cf-4406-a3e8-f8d28528540a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a00fd41-b5cf-4406-a3e8-f8d28528540a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a00fd41-b5cf-4406-a3e8-f8d28528540a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a00fd41-b5cf-4406-a3e8-f8d28528540a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# plt.plot( stock_df['收盤價'], '--')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "2M7fNrNijimi",
        "outputId": "4e55b3b8-f1c7-4721-c41f-4a49bc934d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}