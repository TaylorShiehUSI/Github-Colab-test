{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220814 2230.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMy5EfLHR4a/ZLhNubWvd6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaylorShiehUSI/Github-Colab-test/blob/main/20220814_2230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k8nXyuRd_S",
        "outputId": "2ce9269b-9618-4a4e-ca21-94d72eafdf41"
      },
      "execution_count": 180,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "cviUbaTWRSko"
      },
      "outputs": [],
      "source": [
        "# 下載資料套件\n",
        "import requests as r\n",
        "\n",
        "# 資料處理套件\n",
        "from lxml import etree\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "# 財經套件\n",
        "# import yfinance as yf\n",
        "\n",
        "# 畫圖套件\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tw_stock_data(start_year, start_month, end_year, end_month, stock_code):\n",
        "    start_date = str(date(start_year, start_month, 1))\n",
        "    end_date = str(date(end_year, end_month, 1))\n",
        "    month_list = pd.date_range(start_date, end_date, freq='MS').strftime(\"%Y%m%d\").tolist()\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    for month in month_list:\n",
        "        url = \"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"+ month + \"&stockNo=\" + str(stock_code)\n",
        "        res = r.get(url)\n",
        "        stock_json = res.json()\n",
        "        stock_df = pd.DataFrame.from_dict(stock_json['data'])\n",
        "        df = df.append(stock_df, ignore_index = True)\n",
        "        \n",
        "    # 資料轉型\n",
        "    for col in [0, 1, 2, 3, 4, 5, 6, 8]:\n",
        "        for row in range(df.shape[0]):\n",
        "            # 把\"日期\"從字串(string)換成時間(datetime)，並將民國年換成西元年\n",
        "            if col == 0:\n",
        "                day = df.iloc[row,0].split('/')\n",
        "                df.iloc[row, 0] = datetime(int(day[0]) + 1911, int(day[1]), int(day[2]))  \n",
        "            # 把\"開盤價\", \"最高價\", \"最低價\", \"收盤價\"帶有逗號的字串(string)換成浮點數(float) \n",
        "            elif col != 0:\n",
        "                df.iloc[row, col] = float(df.iloc[row,col].replace(',', ''))\n",
        "    \n",
        "    df.columns = ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數']\n",
        "    return df"
      ],
      "metadata": {
        "id": "6IuqlNYjRvxb"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df = get_tw_stock_data(start_year = 2021, \n",
        "                start_month = 1, \n",
        "                end_year = 2022, \n",
        "                end_month = 8, \n",
        "                stock_code = 2330)\n",
        "stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tjxBWizKRyTK",
        "outputId": "0440a212-16d2-4b3d-ad43-bd874be9a03c"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      日期        成交股數           成交金額    開盤價    最高價    最低價  \\\n",
              "0    2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0   \n",
              "1    2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0   \n",
              "2    2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0   \n",
              "3    2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0   \n",
              "4    2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0   \n",
              "..                   ...         ...            ...    ...    ...    ...   \n",
              "387  2022-08-08 00:00:00  20568971.0  10531710250.0  510.0  515.0  509.0   \n",
              "388  2022-08-09 00:00:00  24370709.0  12372442661.0  507.0  511.0  504.0   \n",
              "389  2022-08-10 00:00:00  22112239.0  11075581424.0  500.0  503.0  499.5   \n",
              "390  2022-08-11 00:00:00  24906177.0  12771121611.0  513.0  514.0  510.0   \n",
              "391  2022-08-12 00:00:00  21343450.0  11016097043.0  515.0  518.0  514.0   \n",
              "\n",
              "       收盤價    漲跌價差     成交筆數  \n",
              "0    536.0   +6.00  33316.0  \n",
              "1    542.0   +6.00  28512.0  \n",
              "2    549.0   +7.00  55462.0  \n",
              "3    565.0  +16.00  47905.0  \n",
              "4    580.0  +15.00  56426.0  \n",
              "..     ...     ...      ...  \n",
              "387  512.0   -4.00  18131.0  \n",
              "388  510.0   -2.00  25433.0  \n",
              "389  500.0  -10.00  35188.0  \n",
              "390  514.0  +14.00  23949.0  \n",
              "391  517.0   +3.00  21701.0  \n",
              "\n",
              "[392 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee0ec540-e0fc-4652-b829-fab1e6a2b1fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>2022-08-08 00:00:00</td>\n",
              "      <td>20568971.0</td>\n",
              "      <td>10531710250.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>509.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>-4.00</td>\n",
              "      <td>18131.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>2022-08-09 00:00:00</td>\n",
              "      <td>24370709.0</td>\n",
              "      <td>12372442661.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>-2.00</td>\n",
              "      <td>25433.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>2022-08-10 00:00:00</td>\n",
              "      <td>22112239.0</td>\n",
              "      <td>11075581424.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>503.0</td>\n",
              "      <td>499.5</td>\n",
              "      <td>500.0</td>\n",
              "      <td>-10.00</td>\n",
              "      <td>35188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>2022-08-11 00:00:00</td>\n",
              "      <td>24906177.0</td>\n",
              "      <td>12771121611.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>+14.00</td>\n",
              "      <td>23949.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>2022-08-12 00:00:00</td>\n",
              "      <td>21343450.0</td>\n",
              "      <td>11016097043.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>518.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>+3.00</td>\n",
              "      <td>21701.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee0ec540-e0fc-4652-b829-fab1e6a2b1fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee0ec540-e0fc-4652-b829-fab1e6a2b1fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee0ec540-e0fc-4652-b829-fab1e6a2b1fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.to_csv('2230.csv',encoding='utf-8_sig')"
      ],
      "metadata": {
        "id": "aa45vys1Vefv"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Processing // Add is_up\n",
        "import numpy as np\n",
        "\n",
        "stock_df['is_up'] = (stock_df['開盤價'].shift(-1) - stock_df['收盤價'] >0).astype('int')\n",
        "stock_df['開收價差'] = (stock_df['收盤價'])-(stock_df['開盤價']).astype('int')\n",
        "stock_df['高低價差'] = (stock_df['最高價'])-(stock_df['最低價']).astype('int')\n",
        "stock_df['每筆股數'] = ((stock_df['成交股數'])/(stock_df['成交筆數']).astype('int'))\n",
        "def one_hot(targets, nb_classes):\n",
        "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "y_data = one_hot(stock_df['is_up'], 2)\n",
        "stock_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s28R2AUsYOgW",
        "outputId": "c1f3f678-246c-40f2-bc9f-43deca5e51c1"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    日期        成交股數           成交金額    開盤價    最高價    最低價    收盤價  \\\n",
              "0  2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0  536.0   \n",
              "1  2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0  542.0   \n",
              "2  2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0  549.0   \n",
              "3  2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0  565.0   \n",
              "4  2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0  580.0   \n",
              "\n",
              "     漲跌價差     成交筆數  is_up  開收價差  高低價差         每筆股數  \n",
              "0   +6.00  33316.0      0   6.0  12.0  1185.315134  \n",
              "1   +6.00  28512.0      1   6.0   7.0  1221.920279  \n",
              "2   +7.00  55462.0      1  -6.0  14.0   1002.74844  \n",
              "3  +16.00  47905.0      1  11.0  17.0   1114.55512  \n",
              "4  +15.00  56426.0      0   0.0   9.0  1115.747138  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21f0e257-a090-46ab-82c4-aa9f12eb29d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>is_up</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1185.315134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1221.920279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1002.74844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1114.55512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1115.747138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21f0e257-a090-46ab-82c4-aa9f12eb29d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21f0e257-a090-46ab-82c4-aa9f12eb29d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21f0e257-a090-46ab-82c4-aa9f12eb29d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare Feature Data\n",
        "X_data = stock_df.drop(['成交股數','日期','開盤價','收盤價','最高價','最低價','is_up','漲跌價差','成交筆數'], axis=1)\n",
        "X_data.head()\n",
        "#X_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U6L5IslyY-A0",
        "outputId": "0df66103-e8b7-4631-df86-d2e8e565a65a"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            成交金額  開收價差  高低價差         每筆股數\n",
              "0  21127581248.0   6.0  12.0  1185.315134\n",
              "1  18761831567.0   6.0   7.0  1221.920279\n",
              "2  30572783229.0  -6.0  14.0   1002.74844\n",
              "3  30018630685.0  11.0  17.0   1114.55512\n",
              "4  36339702855.0   0.0   9.0  1115.747138"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69bad6d8-7c9b-4113-840b-af3434542a1a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1185.315134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1221.920279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1002.74844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1114.55512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1115.747138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69bad6d8-7c9b-4113-840b-af3434542a1a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69bad6d8-7c9b-4113-840b-af3434542a1a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69bad6d8-7c9b-4113-840b-af3434542a1a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalized\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "scaled = scaler.fit_transform(X_data)\n",
        "X_data = pd.DataFrame(scaled, columns=X_data.columns)\n",
        "#print(X_data)\n",
        "X_data.head()"
      ],
      "metadata": {
        "id": "WeNiJCBNQ3x9",
        "outputId": "6f19d0a2-1aab-46a3-b9c0-688246c987c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       成交金額      開收價差      高低價差      每筆股數\n",
              "0 -0.079254  1.008965  0.602092  0.738068\n",
              "1 -0.255043  1.008965 -0.397146  0.842745\n",
              "2  0.622583 -0.899811  1.001788  0.215994\n",
              "3  0.581406  1.804289  1.601331  0.535720\n",
              "4  1.051100  0.054577  0.002549  0.539129"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5597086-cd3a-452a-b3cf-cc8b4ca26882\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.079254</td>\n",
              "      <td>1.008965</td>\n",
              "      <td>0.602092</td>\n",
              "      <td>0.738068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.255043</td>\n",
              "      <td>1.008965</td>\n",
              "      <td>-0.397146</td>\n",
              "      <td>0.842745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.622583</td>\n",
              "      <td>-0.899811</td>\n",
              "      <td>1.001788</td>\n",
              "      <td>0.215994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.581406</td>\n",
              "      <td>1.804289</td>\n",
              "      <td>1.601331</td>\n",
              "      <td>0.535720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.051100</td>\n",
              "      <td>0.054577</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.539129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5597086-cd3a-452a-b3cf-cc8b4ca26882')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5597086-cd3a-452a-b3cf-cc8b4ca26882 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5597086-cd3a-452a-b3cf-cc8b4ca26882');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model, with preparing the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "X_train = K.cast_to_floatx(X_train)\n",
        "y_train = K.cast_to_floatx(y_train)\n",
        "X_test = K.cast_to_floatx(X_test)\n",
        "y_test = K.cast_to_floatx(y_test)"
      ],
      "metadata": {
        "id": "dSxbm6ltjPHa"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot( stock_df['收盤價'], '--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2M7fNrNijimi",
        "outputId": "b91b8bf0-92d6-47d8-dff2-f0ecb9852b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ],
      "metadata": {
        "id": "G_DulbtRjrdy"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set up model, and print the model summary\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 64,\n",
        "                input_shape=X_train.shape[1:],\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 32,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dense(units = 2,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f98ijyGEjunx",
        "outputId": "d0bf9f03-4da8-44c2-b0eb-125b582f107f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_50 (Dense)            (None, 64)                320       \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,682\n",
            "Trainable params: 2,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "model.fit(x = X_train,\n",
        "          y = y_train,\n",
        "          validation_split = 0.2,\n",
        "          batch_size=128,\n",
        "          epochs=600,\n",
        "          verbose = 2) "
      ],
      "metadata": {
        "id": "Kd8QlzjZkAG4",
        "outputId": "2c6720b7-551b-4381-e87b-100c73d61656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "2/2 - 1s - loss: 0.6932 - accuracy: 0.4840 - val_loss: 0.6932 - val_accuracy: 0.4286 - 634ms/epoch - 317ms/step\n",
            "Epoch 2/600\n",
            "2/2 - 0s - loss: 0.6931 - accuracy: 0.5680 - val_loss: 0.6934 - val_accuracy: 0.4444 - 27ms/epoch - 13ms/step\n",
            "Epoch 3/600\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5280 - val_loss: 0.6936 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 4/600\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5280 - val_loss: 0.6938 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 5/600\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5280 - val_loss: 0.6941 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 6/600\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5280 - val_loss: 0.6943 - val_accuracy: 0.4444 - 33ms/epoch - 17ms/step\n",
            "Epoch 7/600\n",
            "2/2 - 0s - loss: 0.6924 - accuracy: 0.5280 - val_loss: 0.6946 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 8/600\n",
            "2/2 - 0s - loss: 0.6922 - accuracy: 0.5280 - val_loss: 0.6948 - val_accuracy: 0.4444 - 27ms/epoch - 13ms/step\n",
            "Epoch 9/600\n",
            "2/2 - 0s - loss: 0.6921 - accuracy: 0.5280 - val_loss: 0.6951 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 10/600\n",
            "2/2 - 0s - loss: 0.6919 - accuracy: 0.5280 - val_loss: 0.6954 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 11/600\n",
            "2/2 - 0s - loss: 0.6918 - accuracy: 0.5280 - val_loss: 0.6957 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 12/600\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5280 - val_loss: 0.6961 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 13/600\n",
            "2/2 - 0s - loss: 0.6913 - accuracy: 0.5280 - val_loss: 0.6964 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 14/600\n",
            "2/2 - 0s - loss: 0.6911 - accuracy: 0.5280 - val_loss: 0.6969 - val_accuracy: 0.4444 - 27ms/epoch - 14ms/step\n",
            "Epoch 15/600\n",
            "2/2 - 0s - loss: 0.6907 - accuracy: 0.5280 - val_loss: 0.6973 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 16/600\n",
            "2/2 - 0s - loss: 0.6904 - accuracy: 0.5280 - val_loss: 0.6977 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 17/600\n",
            "2/2 - 0s - loss: 0.6901 - accuracy: 0.5280 - val_loss: 0.6982 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 18/600\n",
            "2/2 - 0s - loss: 0.6897 - accuracy: 0.5280 - val_loss: 0.6989 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 19/600\n",
            "2/2 - 0s - loss: 0.6892 - accuracy: 0.5280 - val_loss: 0.6996 - val_accuracy: 0.4444 - 40ms/epoch - 20ms/step\n",
            "Epoch 20/600\n",
            "2/2 - 0s - loss: 0.6889 - accuracy: 0.5280 - val_loss: 0.7003 - val_accuracy: 0.4444 - 37ms/epoch - 18ms/step\n",
            "Epoch 21/600\n",
            "2/2 - 0s - loss: 0.6881 - accuracy: 0.5280 - val_loss: 0.7010 - val_accuracy: 0.4444 - 35ms/epoch - 18ms/step\n",
            "Epoch 22/600\n",
            "2/2 - 0s - loss: 0.6875 - accuracy: 0.5280 - val_loss: 0.7019 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 23/600\n",
            "2/2 - 0s - loss: 0.6865 - accuracy: 0.5280 - val_loss: 0.7029 - val_accuracy: 0.4444 - 35ms/epoch - 17ms/step\n",
            "Epoch 24/600\n",
            "2/2 - 0s - loss: 0.6862 - accuracy: 0.5400 - val_loss: 0.7039 - val_accuracy: 0.4444 - 27ms/epoch - 14ms/step\n",
            "Epoch 25/600\n",
            "2/2 - 0s - loss: 0.6855 - accuracy: 0.5400 - val_loss: 0.7050 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 26/600\n",
            "2/2 - 0s - loss: 0.6846 - accuracy: 0.5520 - val_loss: 0.7062 - val_accuracy: 0.4127 - 30ms/epoch - 15ms/step\n",
            "Epoch 27/600\n",
            "2/2 - 0s - loss: 0.6834 - accuracy: 0.5560 - val_loss: 0.7075 - val_accuracy: 0.4127 - 33ms/epoch - 16ms/step\n",
            "Epoch 28/600\n",
            "2/2 - 0s - loss: 0.6825 - accuracy: 0.5680 - val_loss: 0.7089 - val_accuracy: 0.3968 - 32ms/epoch - 16ms/step\n",
            "Epoch 29/600\n",
            "2/2 - 0s - loss: 0.6816 - accuracy: 0.5680 - val_loss: 0.7109 - val_accuracy: 0.4127 - 36ms/epoch - 18ms/step\n",
            "Epoch 30/600\n",
            "2/2 - 0s - loss: 0.6798 - accuracy: 0.5840 - val_loss: 0.7129 - val_accuracy: 0.4286 - 31ms/epoch - 15ms/step\n",
            "Epoch 31/600\n",
            "2/2 - 0s - loss: 0.6805 - accuracy: 0.5800 - val_loss: 0.7149 - val_accuracy: 0.4127 - 29ms/epoch - 15ms/step\n",
            "Epoch 32/600\n",
            "2/2 - 0s - loss: 0.6792 - accuracy: 0.6000 - val_loss: 0.7172 - val_accuracy: 0.3968 - 29ms/epoch - 15ms/step\n",
            "Epoch 33/600\n",
            "2/2 - 0s - loss: 0.6781 - accuracy: 0.6160 - val_loss: 0.7196 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 34/600\n",
            "2/2 - 0s - loss: 0.6756 - accuracy: 0.6000 - val_loss: 0.7210 - val_accuracy: 0.3968 - 35ms/epoch - 17ms/step\n",
            "Epoch 35/600\n",
            "2/2 - 0s - loss: 0.6751 - accuracy: 0.6160 - val_loss: 0.7224 - val_accuracy: 0.3810 - 32ms/epoch - 16ms/step\n",
            "Epoch 36/600\n",
            "2/2 - 0s - loss: 0.6736 - accuracy: 0.5960 - val_loss: 0.7238 - val_accuracy: 0.4127 - 28ms/epoch - 14ms/step\n",
            "Epoch 37/600\n",
            "2/2 - 0s - loss: 0.6743 - accuracy: 0.6120 - val_loss: 0.7250 - val_accuracy: 0.4127 - 33ms/epoch - 17ms/step\n",
            "Epoch 38/600\n",
            "2/2 - 0s - loss: 0.6723 - accuracy: 0.6040 - val_loss: 0.7254 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 39/600\n",
            "2/2 - 0s - loss: 0.6672 - accuracy: 0.6160 - val_loss: 0.7268 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 40/600\n",
            "2/2 - 0s - loss: 0.6680 - accuracy: 0.6040 - val_loss: 0.7284 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 41/600\n",
            "2/2 - 0s - loss: 0.6659 - accuracy: 0.6040 - val_loss: 0.7305 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 42/600\n",
            "2/2 - 0s - loss: 0.6660 - accuracy: 0.5880 - val_loss: 0.7327 - val_accuracy: 0.4603 - 33ms/epoch - 16ms/step\n",
            "Epoch 43/600\n",
            "2/2 - 0s - loss: 0.6669 - accuracy: 0.5920 - val_loss: 0.7342 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 44/600\n",
            "2/2 - 0s - loss: 0.6656 - accuracy: 0.5920 - val_loss: 0.7354 - val_accuracy: 0.4603 - 35ms/epoch - 17ms/step\n",
            "Epoch 45/600\n",
            "2/2 - 0s - loss: 0.6624 - accuracy: 0.5960 - val_loss: 0.7358 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 46/600\n",
            "2/2 - 0s - loss: 0.6610 - accuracy: 0.5920 - val_loss: 0.7370 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 47/600\n",
            "2/2 - 0s - loss: 0.6585 - accuracy: 0.5960 - val_loss: 0.7369 - val_accuracy: 0.4603 - 49ms/epoch - 24ms/step\n",
            "Epoch 48/600\n",
            "2/2 - 0s - loss: 0.6607 - accuracy: 0.6080 - val_loss: 0.7384 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 49/600\n",
            "2/2 - 0s - loss: 0.6631 - accuracy: 0.5880 - val_loss: 0.7383 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 50/600\n",
            "2/2 - 0s - loss: 0.6646 - accuracy: 0.5920 - val_loss: 0.7382 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 51/600\n",
            "2/2 - 0s - loss: 0.6570 - accuracy: 0.6080 - val_loss: 0.7389 - val_accuracy: 0.4603 - 52ms/epoch - 26ms/step\n",
            "Epoch 52/600\n",
            "2/2 - 0s - loss: 0.6546 - accuracy: 0.6000 - val_loss: 0.7397 - val_accuracy: 0.4603 - 26ms/epoch - 13ms/step\n",
            "Epoch 53/600\n",
            "2/2 - 0s - loss: 0.6562 - accuracy: 0.6160 - val_loss: 0.7405 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 54/600\n",
            "2/2 - 0s - loss: 0.6595 - accuracy: 0.6040 - val_loss: 0.7411 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 55/600\n",
            "2/2 - 0s - loss: 0.6540 - accuracy: 0.5960 - val_loss: 0.7410 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 56/600\n",
            "2/2 - 0s - loss: 0.6603 - accuracy: 0.6000 - val_loss: 0.7421 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 57/600\n",
            "2/2 - 0s - loss: 0.6569 - accuracy: 0.5920 - val_loss: 0.7425 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 58/600\n",
            "2/2 - 0s - loss: 0.6531 - accuracy: 0.6040 - val_loss: 0.7429 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 59/600\n",
            "2/2 - 0s - loss: 0.6493 - accuracy: 0.6280 - val_loss: 0.7433 - val_accuracy: 0.4444 - 52ms/epoch - 26ms/step\n",
            "Epoch 60/600\n",
            "2/2 - 0s - loss: 0.6504 - accuracy: 0.6280 - val_loss: 0.7452 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 61/600\n",
            "2/2 - 0s - loss: 0.6570 - accuracy: 0.5960 - val_loss: 0.7462 - val_accuracy: 0.4603 - 33ms/epoch - 16ms/step\n",
            "Epoch 62/600\n",
            "2/2 - 0s - loss: 0.6495 - accuracy: 0.6080 - val_loss: 0.7476 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 63/600\n",
            "2/2 - 0s - loss: 0.6506 - accuracy: 0.6120 - val_loss: 0.7481 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 64/600\n",
            "2/2 - 0s - loss: 0.6504 - accuracy: 0.6200 - val_loss: 0.7479 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 65/600\n",
            "2/2 - 0s - loss: 0.6526 - accuracy: 0.6120 - val_loss: 0.7489 - val_accuracy: 0.4444 - 38ms/epoch - 19ms/step\n",
            "Epoch 66/600\n",
            "2/2 - 0s - loss: 0.6486 - accuracy: 0.5960 - val_loss: 0.7477 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 67/600\n",
            "2/2 - 0s - loss: 0.6530 - accuracy: 0.6040 - val_loss: 0.7468 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 68/600\n",
            "2/2 - 0s - loss: 0.6543 - accuracy: 0.6120 - val_loss: 0.7460 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 69/600\n",
            "2/2 - 0s - loss: 0.6466 - accuracy: 0.6240 - val_loss: 0.7461 - val_accuracy: 0.4603 - 29ms/epoch - 15ms/step\n",
            "Epoch 70/600\n",
            "2/2 - 0s - loss: 0.6491 - accuracy: 0.6200 - val_loss: 0.7487 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 71/600\n",
            "2/2 - 0s - loss: 0.6454 - accuracy: 0.6280 - val_loss: 0.7501 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 72/600\n",
            "2/2 - 0s - loss: 0.6430 - accuracy: 0.6160 - val_loss: 0.7502 - val_accuracy: 0.4603 - 29ms/epoch - 15ms/step\n",
            "Epoch 73/600\n",
            "2/2 - 0s - loss: 0.6532 - accuracy: 0.5920 - val_loss: 0.7493 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 74/600\n",
            "2/2 - 0s - loss: 0.6460 - accuracy: 0.6120 - val_loss: 0.7490 - val_accuracy: 0.4603 - 38ms/epoch - 19ms/step\n",
            "Epoch 75/600\n",
            "2/2 - 0s - loss: 0.6472 - accuracy: 0.6240 - val_loss: 0.7481 - val_accuracy: 0.4603 - 26ms/epoch - 13ms/step\n",
            "Epoch 76/600\n",
            "2/2 - 0s - loss: 0.6454 - accuracy: 0.6000 - val_loss: 0.7477 - val_accuracy: 0.4762 - 33ms/epoch - 16ms/step\n",
            "Epoch 77/600\n",
            "2/2 - 0s - loss: 0.6502 - accuracy: 0.6200 - val_loss: 0.7475 - val_accuracy: 0.4762 - 27ms/epoch - 13ms/step\n",
            "Epoch 78/600\n",
            "2/2 - 0s - loss: 0.6445 - accuracy: 0.5960 - val_loss: 0.7485 - val_accuracy: 0.4603 - 35ms/epoch - 17ms/step\n",
            "Epoch 79/600\n",
            "2/2 - 0s - loss: 0.6525 - accuracy: 0.6040 - val_loss: 0.7497 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 80/600\n",
            "2/2 - 0s - loss: 0.6530 - accuracy: 0.6160 - val_loss: 0.7500 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 81/600\n",
            "2/2 - 0s - loss: 0.6465 - accuracy: 0.6240 - val_loss: 0.7509 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 82/600\n",
            "2/2 - 0s - loss: 0.6442 - accuracy: 0.6000 - val_loss: 0.7504 - val_accuracy: 0.4444 - 33ms/epoch - 17ms/step\n",
            "Epoch 83/600\n",
            "2/2 - 0s - loss: 0.6470 - accuracy: 0.6120 - val_loss: 0.7500 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 84/600\n",
            "2/2 - 0s - loss: 0.6483 - accuracy: 0.6120 - val_loss: 0.7491 - val_accuracy: 0.4444 - 37ms/epoch - 18ms/step\n",
            "Epoch 85/600\n",
            "2/2 - 0s - loss: 0.6496 - accuracy: 0.6280 - val_loss: 0.7490 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 86/600\n",
            "2/2 - 0s - loss: 0.6409 - accuracy: 0.6160 - val_loss: 0.7493 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 87/600\n",
            "2/2 - 0s - loss: 0.6449 - accuracy: 0.6320 - val_loss: 0.7508 - val_accuracy: 0.4286 - 29ms/epoch - 14ms/step\n",
            "Epoch 88/600\n",
            "2/2 - 0s - loss: 0.6458 - accuracy: 0.6200 - val_loss: 0.7522 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 89/600\n",
            "2/2 - 0s - loss: 0.6450 - accuracy: 0.6240 - val_loss: 0.7534 - val_accuracy: 0.4286 - 34ms/epoch - 17ms/step\n",
            "Epoch 90/600\n",
            "2/2 - 0s - loss: 0.6377 - accuracy: 0.5960 - val_loss: 0.7535 - val_accuracy: 0.4286 - 28ms/epoch - 14ms/step\n",
            "Epoch 91/600\n",
            "2/2 - 0s - loss: 0.6397 - accuracy: 0.6160 - val_loss: 0.7535 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 92/600\n",
            "2/2 - 0s - loss: 0.6394 - accuracy: 0.6240 - val_loss: 0.7541 - val_accuracy: 0.4286 - 33ms/epoch - 16ms/step\n",
            "Epoch 93/600\n",
            "2/2 - 0s - loss: 0.6494 - accuracy: 0.6160 - val_loss: 0.7542 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 94/600\n",
            "2/2 - 0s - loss: 0.6441 - accuracy: 0.6000 - val_loss: 0.7542 - val_accuracy: 0.4286 - 27ms/epoch - 14ms/step\n",
            "Epoch 95/600\n",
            "2/2 - 0s - loss: 0.6383 - accuracy: 0.6560 - val_loss: 0.7532 - val_accuracy: 0.4286 - 37ms/epoch - 19ms/step\n",
            "Epoch 96/600\n",
            "2/2 - 0s - loss: 0.6471 - accuracy: 0.6280 - val_loss: 0.7530 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 97/600\n",
            "2/2 - 0s - loss: 0.6384 - accuracy: 0.6320 - val_loss: 0.7536 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 98/600\n",
            "2/2 - 0s - loss: 0.6462 - accuracy: 0.6160 - val_loss: 0.7541 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 99/600\n",
            "2/2 - 0s - loss: 0.6339 - accuracy: 0.6320 - val_loss: 0.7552 - val_accuracy: 0.4127 - 28ms/epoch - 14ms/step\n",
            "Epoch 100/600\n",
            "2/2 - 0s - loss: 0.6438 - accuracy: 0.6240 - val_loss: 0.7543 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 101/600\n",
            "2/2 - 0s - loss: 0.6374 - accuracy: 0.6440 - val_loss: 0.7541 - val_accuracy: 0.4127 - 27ms/epoch - 14ms/step\n",
            "Epoch 102/600\n",
            "2/2 - 0s - loss: 0.6441 - accuracy: 0.6000 - val_loss: 0.7559 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 103/600\n",
            "2/2 - 0s - loss: 0.6373 - accuracy: 0.6360 - val_loss: 0.7561 - val_accuracy: 0.4127 - 40ms/epoch - 20ms/step\n",
            "Epoch 104/600\n",
            "2/2 - 0s - loss: 0.6374 - accuracy: 0.6400 - val_loss: 0.7565 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 105/600\n",
            "2/2 - 0s - loss: 0.6395 - accuracy: 0.6200 - val_loss: 0.7564 - val_accuracy: 0.4286 - 28ms/epoch - 14ms/step\n",
            "Epoch 106/600\n",
            "2/2 - 0s - loss: 0.6278 - accuracy: 0.6400 - val_loss: 0.7565 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 107/600\n",
            "2/2 - 0s - loss: 0.6408 - accuracy: 0.6120 - val_loss: 0.7562 - val_accuracy: 0.4286 - 34ms/epoch - 17ms/step\n",
            "Epoch 108/600\n",
            "2/2 - 0s - loss: 0.6334 - accuracy: 0.6240 - val_loss: 0.7571 - val_accuracy: 0.4286 - 35ms/epoch - 17ms/step\n",
            "Epoch 109/600\n",
            "2/2 - 0s - loss: 0.6402 - accuracy: 0.6120 - val_loss: 0.7573 - val_accuracy: 0.4286 - 37ms/epoch - 19ms/step\n",
            "Epoch 110/600\n",
            "2/2 - 0s - loss: 0.6419 - accuracy: 0.6080 - val_loss: 0.7578 - val_accuracy: 0.4286 - 31ms/epoch - 16ms/step\n",
            "Epoch 111/600\n",
            "2/2 - 0s - loss: 0.6347 - accuracy: 0.6280 - val_loss: 0.7583 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 112/600\n",
            "2/2 - 0s - loss: 0.6480 - accuracy: 0.6120 - val_loss: 0.7584 - val_accuracy: 0.4286 - 35ms/epoch - 18ms/step\n",
            "Epoch 113/600\n",
            "2/2 - 0s - loss: 0.6386 - accuracy: 0.6280 - val_loss: 0.7577 - val_accuracy: 0.4286 - 27ms/epoch - 14ms/step\n",
            "Epoch 114/600\n",
            "2/2 - 0s - loss: 0.6418 - accuracy: 0.6360 - val_loss: 0.7554 - val_accuracy: 0.4286 - 28ms/epoch - 14ms/step\n",
            "Epoch 115/600\n",
            "2/2 - 0s - loss: 0.6474 - accuracy: 0.6240 - val_loss: 0.7535 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 116/600\n",
            "2/2 - 0s - loss: 0.6404 - accuracy: 0.6280 - val_loss: 0.7531 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 117/600\n",
            "2/2 - 0s - loss: 0.6331 - accuracy: 0.6440 - val_loss: 0.7537 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 118/600\n",
            "2/2 - 0s - loss: 0.6434 - accuracy: 0.6000 - val_loss: 0.7530 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 119/600\n",
            "2/2 - 0s - loss: 0.6395 - accuracy: 0.6280 - val_loss: 0.7530 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 120/600\n",
            "2/2 - 0s - loss: 0.6356 - accuracy: 0.6240 - val_loss: 0.7530 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 121/600\n",
            "2/2 - 0s - loss: 0.6314 - accuracy: 0.6200 - val_loss: 0.7537 - val_accuracy: 0.4127 - 29ms/epoch - 14ms/step\n",
            "Epoch 122/600\n",
            "2/2 - 0s - loss: 0.6260 - accuracy: 0.6680 - val_loss: 0.7544 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 123/600\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6440 - val_loss: 0.7552 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 124/600\n",
            "2/2 - 0s - loss: 0.6241 - accuracy: 0.6440 - val_loss: 0.7555 - val_accuracy: 0.4603 - 37ms/epoch - 18ms/step\n",
            "Epoch 125/600\n",
            "2/2 - 0s - loss: 0.6229 - accuracy: 0.6560 - val_loss: 0.7568 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 126/600\n",
            "2/2 - 0s - loss: 0.6402 - accuracy: 0.6480 - val_loss: 0.7595 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 127/600\n",
            "2/2 - 0s - loss: 0.6240 - accuracy: 0.6280 - val_loss: 0.7621 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 128/600\n",
            "2/2 - 0s - loss: 0.6299 - accuracy: 0.6320 - val_loss: 0.7654 - val_accuracy: 0.4286 - 31ms/epoch - 15ms/step\n",
            "Epoch 129/600\n",
            "2/2 - 0s - loss: 0.6285 - accuracy: 0.6320 - val_loss: 0.7675 - val_accuracy: 0.4286 - 29ms/epoch - 14ms/step\n",
            "Epoch 130/600\n",
            "2/2 - 0s - loss: 0.6167 - accuracy: 0.6640 - val_loss: 0.7688 - val_accuracy: 0.4286 - 37ms/epoch - 18ms/step\n",
            "Epoch 131/600\n",
            "2/2 - 0s - loss: 0.6231 - accuracy: 0.6480 - val_loss: 0.7681 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 132/600\n",
            "2/2 - 0s - loss: 0.6397 - accuracy: 0.6240 - val_loss: 0.7650 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 133/600\n",
            "2/2 - 0s - loss: 0.6253 - accuracy: 0.6520 - val_loss: 0.7631 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 134/600\n",
            "2/2 - 0s - loss: 0.6283 - accuracy: 0.6480 - val_loss: 0.7632 - val_accuracy: 0.4286 - 46ms/epoch - 23ms/step\n",
            "Epoch 135/600\n",
            "2/2 - 0s - loss: 0.6388 - accuracy: 0.6120 - val_loss: 0.7623 - val_accuracy: 0.4444 - 27ms/epoch - 14ms/step\n",
            "Epoch 136/600\n",
            "2/2 - 0s - loss: 0.6270 - accuracy: 0.6480 - val_loss: 0.7608 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 137/600\n",
            "2/2 - 0s - loss: 0.6269 - accuracy: 0.6280 - val_loss: 0.7587 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 138/600\n",
            "2/2 - 0s - loss: 0.6223 - accuracy: 0.6680 - val_loss: 0.7576 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 139/600\n",
            "2/2 - 0s - loss: 0.6193 - accuracy: 0.6440 - val_loss: 0.7583 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 140/600\n",
            "2/2 - 0s - loss: 0.6183 - accuracy: 0.6760 - val_loss: 0.7608 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 141/600\n",
            "2/2 - 0s - loss: 0.6191 - accuracy: 0.6600 - val_loss: 0.7629 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 142/600\n",
            "2/2 - 0s - loss: 0.6207 - accuracy: 0.6520 - val_loss: 0.7668 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 143/600\n",
            "2/2 - 0s - loss: 0.6285 - accuracy: 0.6600 - val_loss: 0.7695 - val_accuracy: 0.4286 - 36ms/epoch - 18ms/step\n",
            "Epoch 144/600\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6560 - val_loss: 0.7675 - val_accuracy: 0.4444 - 33ms/epoch - 16ms/step\n",
            "Epoch 145/600\n",
            "2/2 - 0s - loss: 0.6180 - accuracy: 0.6600 - val_loss: 0.7654 - val_accuracy: 0.4444 - 37ms/epoch - 19ms/step\n",
            "Epoch 146/600\n",
            "2/2 - 0s - loss: 0.6135 - accuracy: 0.6480 - val_loss: 0.7654 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 147/600\n",
            "2/2 - 0s - loss: 0.6286 - accuracy: 0.6160 - val_loss: 0.7653 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 148/600\n",
            "2/2 - 0s - loss: 0.6136 - accuracy: 0.6600 - val_loss: 0.7649 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 149/600\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6520 - val_loss: 0.7643 - val_accuracy: 0.4286 - 36ms/epoch - 18ms/step\n",
            "Epoch 150/600\n",
            "2/2 - 0s - loss: 0.6164 - accuracy: 0.6560 - val_loss: 0.7647 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 151/600\n",
            "2/2 - 0s - loss: 0.6323 - accuracy: 0.6360 - val_loss: 0.7685 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 152/600\n",
            "2/2 - 0s - loss: 0.6112 - accuracy: 0.6400 - val_loss: 0.7685 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 153/600\n",
            "2/2 - 0s - loss: 0.6189 - accuracy: 0.6480 - val_loss: 0.7670 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 154/600\n",
            "2/2 - 0s - loss: 0.6145 - accuracy: 0.6600 - val_loss: 0.7653 - val_accuracy: 0.4444 - 51ms/epoch - 25ms/step\n",
            "Epoch 155/600\n",
            "2/2 - 0s - loss: 0.6247 - accuracy: 0.6520 - val_loss: 0.7625 - val_accuracy: 0.4286 - 28ms/epoch - 14ms/step\n",
            "Epoch 156/600\n",
            "2/2 - 0s - loss: 0.6138 - accuracy: 0.6520 - val_loss: 0.7622 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 157/600\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6680 - val_loss: 0.7630 - val_accuracy: 0.4286 - 43ms/epoch - 22ms/step\n",
            "Epoch 158/600\n",
            "2/2 - 0s - loss: 0.6242 - accuracy: 0.6600 - val_loss: 0.7673 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 159/600\n",
            "2/2 - 0s - loss: 0.6171 - accuracy: 0.6840 - val_loss: 0.7721 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 160/600\n",
            "2/2 - 0s - loss: 0.6012 - accuracy: 0.6680 - val_loss: 0.7755 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 161/600\n",
            "2/2 - 0s - loss: 0.6131 - accuracy: 0.6400 - val_loss: 0.7788 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 162/600\n",
            "2/2 - 0s - loss: 0.6157 - accuracy: 0.6480 - val_loss: 0.7782 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 163/600\n",
            "2/2 - 0s - loss: 0.6188 - accuracy: 0.6640 - val_loss: 0.7746 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 164/600\n",
            "2/2 - 0s - loss: 0.6148 - accuracy: 0.6720 - val_loss: 0.7715 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 165/600\n",
            "2/2 - 0s - loss: 0.6022 - accuracy: 0.6720 - val_loss: 0.7677 - val_accuracy: 0.4127 - 33ms/epoch - 17ms/step\n",
            "Epoch 166/600\n",
            "2/2 - 0s - loss: 0.6237 - accuracy: 0.6440 - val_loss: 0.7669 - val_accuracy: 0.4127 - 34ms/epoch - 17ms/step\n",
            "Epoch 167/600\n",
            "2/2 - 0s - loss: 0.6015 - accuracy: 0.6800 - val_loss: 0.7649 - val_accuracy: 0.4127 - 30ms/epoch - 15ms/step\n",
            "Epoch 168/600\n",
            "2/2 - 0s - loss: 0.6086 - accuracy: 0.6840 - val_loss: 0.7653 - val_accuracy: 0.4127 - 34ms/epoch - 17ms/step\n",
            "Epoch 169/600\n",
            "2/2 - 0s - loss: 0.6152 - accuracy: 0.6520 - val_loss: 0.7693 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 170/600\n",
            "2/2 - 0s - loss: 0.6051 - accuracy: 0.6720 - val_loss: 0.7732 - val_accuracy: 0.4127 - 33ms/epoch - 16ms/step\n",
            "Epoch 171/600\n",
            "2/2 - 0s - loss: 0.6107 - accuracy: 0.6600 - val_loss: 0.7752 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 172/600\n",
            "2/2 - 0s - loss: 0.6032 - accuracy: 0.6560 - val_loss: 0.7769 - val_accuracy: 0.4127 - 29ms/epoch - 15ms/step\n",
            "Epoch 173/600\n",
            "2/2 - 0s - loss: 0.6330 - accuracy: 0.6520 - val_loss: 0.7766 - val_accuracy: 0.4127 - 28ms/epoch - 14ms/step\n",
            "Epoch 174/600\n",
            "2/2 - 0s - loss: 0.6053 - accuracy: 0.6800 - val_loss: 0.7775 - val_accuracy: 0.4286 - 28ms/epoch - 14ms/step\n",
            "Epoch 175/600\n",
            "2/2 - 0s - loss: 0.6016 - accuracy: 0.6840 - val_loss: 0.7810 - val_accuracy: 0.4286 - 34ms/epoch - 17ms/step\n",
            "Epoch 176/600\n",
            "2/2 - 0s - loss: 0.6050 - accuracy: 0.6760 - val_loss: 0.7804 - val_accuracy: 0.4286 - 29ms/epoch - 14ms/step\n",
            "Epoch 177/600\n",
            "2/2 - 0s - loss: 0.6296 - accuracy: 0.6600 - val_loss: 0.7814 - val_accuracy: 0.4127 - 33ms/epoch - 16ms/step\n",
            "Epoch 178/600\n",
            "2/2 - 0s - loss: 0.6009 - accuracy: 0.6840 - val_loss: 0.7816 - val_accuracy: 0.4127 - 36ms/epoch - 18ms/step\n",
            "Epoch 179/600\n",
            "2/2 - 0s - loss: 0.6058 - accuracy: 0.6800 - val_loss: 0.7796 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 180/600\n",
            "2/2 - 0s - loss: 0.6106 - accuracy: 0.6520 - val_loss: 0.7785 - val_accuracy: 0.4127 - 33ms/epoch - 16ms/step\n",
            "Epoch 181/600\n",
            "2/2 - 0s - loss: 0.6069 - accuracy: 0.6600 - val_loss: 0.7759 - val_accuracy: 0.4286 - 53ms/epoch - 26ms/step\n",
            "Epoch 182/600\n",
            "2/2 - 0s - loss: 0.6009 - accuracy: 0.6840 - val_loss: 0.7741 - val_accuracy: 0.4286 - 33ms/epoch - 16ms/step\n",
            "Epoch 183/600\n",
            "2/2 - 0s - loss: 0.6082 - accuracy: 0.6560 - val_loss: 0.7700 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 184/600\n",
            "2/2 - 0s - loss: 0.6173 - accuracy: 0.6560 - val_loss: 0.7683 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 185/600\n",
            "2/2 - 0s - loss: 0.6157 - accuracy: 0.6560 - val_loss: 0.7702 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 186/600\n",
            "2/2 - 0s - loss: 0.6108 - accuracy: 0.6560 - val_loss: 0.7734 - val_accuracy: 0.4444 - 33ms/epoch - 16ms/step\n",
            "Epoch 187/600\n",
            "2/2 - 0s - loss: 0.6078 - accuracy: 0.6640 - val_loss: 0.7772 - val_accuracy: 0.4127 - 36ms/epoch - 18ms/step\n",
            "Epoch 188/600\n",
            "2/2 - 0s - loss: 0.6033 - accuracy: 0.6680 - val_loss: 0.7788 - val_accuracy: 0.4127 - 36ms/epoch - 18ms/step\n",
            "Epoch 189/600\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6520 - val_loss: 0.7770 - val_accuracy: 0.4127 - 29ms/epoch - 15ms/step\n",
            "Epoch 190/600\n",
            "2/2 - 0s - loss: 0.6043 - accuracy: 0.6840 - val_loss: 0.7758 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 191/600\n",
            "2/2 - 0s - loss: 0.6107 - accuracy: 0.6840 - val_loss: 0.7688 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 192/600\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6640 - val_loss: 0.7671 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 193/600\n",
            "2/2 - 0s - loss: 0.5993 - accuracy: 0.6720 - val_loss: 0.7681 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 194/600\n",
            "2/2 - 0s - loss: 0.5900 - accuracy: 0.6880 - val_loss: 0.7722 - val_accuracy: 0.4444 - 35ms/epoch - 18ms/step\n",
            "Epoch 195/600\n",
            "2/2 - 0s - loss: 0.6080 - accuracy: 0.6720 - val_loss: 0.7757 - val_accuracy: 0.4286 - 35ms/epoch - 17ms/step\n",
            "Epoch 196/600\n",
            "2/2 - 0s - loss: 0.5989 - accuracy: 0.6960 - val_loss: 0.7773 - val_accuracy: 0.4286 - 36ms/epoch - 18ms/step\n",
            "Epoch 197/600\n",
            "2/2 - 0s - loss: 0.5904 - accuracy: 0.6840 - val_loss: 0.7796 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 198/600\n",
            "2/2 - 0s - loss: 0.6123 - accuracy: 0.6600 - val_loss: 0.7797 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 199/600\n",
            "2/2 - 0s - loss: 0.6021 - accuracy: 0.6720 - val_loss: 0.7772 - val_accuracy: 0.4286 - 35ms/epoch - 17ms/step\n",
            "Epoch 200/600\n",
            "2/2 - 0s - loss: 0.6000 - accuracy: 0.6560 - val_loss: 0.7762 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 201/600\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6720 - val_loss: 0.7756 - val_accuracy: 0.4286 - 27ms/epoch - 13ms/step\n",
            "Epoch 202/600\n",
            "2/2 - 0s - loss: 0.6025 - accuracy: 0.6640 - val_loss: 0.7778 - val_accuracy: 0.4286 - 26ms/epoch - 13ms/step\n",
            "Epoch 203/600\n",
            "2/2 - 0s - loss: 0.6002 - accuracy: 0.6920 - val_loss: 0.7780 - val_accuracy: 0.4286 - 27ms/epoch - 13ms/step\n",
            "Epoch 204/600\n",
            "2/2 - 0s - loss: 0.5947 - accuracy: 0.6600 - val_loss: 0.7807 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 205/600\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6760 - val_loss: 0.7793 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 206/600\n",
            "2/2 - 0s - loss: 0.5820 - accuracy: 0.6760 - val_loss: 0.7810 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 207/600\n",
            "2/2 - 0s - loss: 0.5938 - accuracy: 0.6840 - val_loss: 0.7849 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 208/600\n",
            "2/2 - 0s - loss: 0.5893 - accuracy: 0.6800 - val_loss: 0.7869 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 209/600\n",
            "2/2 - 0s - loss: 0.5926 - accuracy: 0.6800 - val_loss: 0.7870 - val_accuracy: 0.4286 - 47ms/epoch - 24ms/step\n",
            "Epoch 210/600\n",
            "2/2 - 0s - loss: 0.5823 - accuracy: 0.6880 - val_loss: 0.7842 - val_accuracy: 0.4286 - 33ms/epoch - 16ms/step\n",
            "Epoch 211/600\n",
            "2/2 - 0s - loss: 0.5928 - accuracy: 0.6720 - val_loss: 0.7830 - val_accuracy: 0.4286 - 40ms/epoch - 20ms/step\n",
            "Epoch 212/600\n",
            "2/2 - 0s - loss: 0.5877 - accuracy: 0.6720 - val_loss: 0.7813 - val_accuracy: 0.4286 - 57ms/epoch - 28ms/step\n",
            "Epoch 213/600\n",
            "2/2 - 0s - loss: 0.5973 - accuracy: 0.6640 - val_loss: 0.7814 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 214/600\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6880 - val_loss: 0.7822 - val_accuracy: 0.4286 - 29ms/epoch - 15ms/step\n",
            "Epoch 215/600\n",
            "2/2 - 0s - loss: 0.5890 - accuracy: 0.6800 - val_loss: 0.7872 - val_accuracy: 0.4286 - 50ms/epoch - 25ms/step\n",
            "Epoch 216/600\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6840 - val_loss: 0.7900 - val_accuracy: 0.4286 - 34ms/epoch - 17ms/step\n",
            "Epoch 217/600\n",
            "2/2 - 0s - loss: 0.5834 - accuracy: 0.6880 - val_loss: 0.7902 - val_accuracy: 0.4286 - 35ms/epoch - 18ms/step\n",
            "Epoch 218/600\n",
            "2/2 - 0s - loss: 0.5872 - accuracy: 0.6920 - val_loss: 0.7884 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 219/600\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6840 - val_loss: 0.7830 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 220/600\n",
            "2/2 - 0s - loss: 0.5717 - accuracy: 0.7200 - val_loss: 0.7832 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 221/600\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6840 - val_loss: 0.7827 - val_accuracy: 0.4286 - 35ms/epoch - 17ms/step\n",
            "Epoch 222/600\n",
            "2/2 - 0s - loss: 0.5871 - accuracy: 0.7080 - val_loss: 0.7854 - val_accuracy: 0.4127 - 34ms/epoch - 17ms/step\n",
            "Epoch 223/600\n",
            "2/2 - 0s - loss: 0.5841 - accuracy: 0.7080 - val_loss: 0.7852 - val_accuracy: 0.4127 - 31ms/epoch - 15ms/step\n",
            "Epoch 224/600\n",
            "2/2 - 0s - loss: 0.5691 - accuracy: 0.7040 - val_loss: 0.7848 - val_accuracy: 0.4127 - 32ms/epoch - 16ms/step\n",
            "Epoch 225/600\n",
            "2/2 - 0s - loss: 0.5865 - accuracy: 0.6960 - val_loss: 0.7842 - val_accuracy: 0.4444 - 40ms/epoch - 20ms/step\n",
            "Epoch 226/600\n",
            "2/2 - 0s - loss: 0.5884 - accuracy: 0.6800 - val_loss: 0.7842 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 227/600\n",
            "2/2 - 0s - loss: 0.6023 - accuracy: 0.6560 - val_loss: 0.7829 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 228/600\n",
            "2/2 - 0s - loss: 0.5969 - accuracy: 0.6720 - val_loss: 0.7869 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 229/600\n",
            "2/2 - 0s - loss: 0.5857 - accuracy: 0.6680 - val_loss: 0.7879 - val_accuracy: 0.4762 - 39ms/epoch - 20ms/step\n",
            "Epoch 230/600\n",
            "2/2 - 0s - loss: 0.5882 - accuracy: 0.6720 - val_loss: 0.7911 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 231/600\n",
            "2/2 - 0s - loss: 0.5810 - accuracy: 0.7000 - val_loss: 0.7945 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 232/600\n",
            "2/2 - 0s - loss: 0.5851 - accuracy: 0.6920 - val_loss: 0.7997 - val_accuracy: 0.4286 - 37ms/epoch - 18ms/step\n",
            "Epoch 233/600\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6920 - val_loss: 0.8017 - val_accuracy: 0.4286 - 27ms/epoch - 13ms/step\n",
            "Epoch 234/600\n",
            "2/2 - 0s - loss: 0.5868 - accuracy: 0.6800 - val_loss: 0.7988 - val_accuracy: 0.4286 - 47ms/epoch - 23ms/step\n",
            "Epoch 235/600\n",
            "2/2 - 0s - loss: 0.5797 - accuracy: 0.6960 - val_loss: 0.7958 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 236/600\n",
            "2/2 - 0s - loss: 0.5820 - accuracy: 0.6920 - val_loss: 0.7944 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 237/600\n",
            "2/2 - 0s - loss: 0.5757 - accuracy: 0.7000 - val_loss: 0.7906 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 238/600\n",
            "2/2 - 0s - loss: 0.5725 - accuracy: 0.6800 - val_loss: 0.7874 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 239/600\n",
            "2/2 - 0s - loss: 0.5870 - accuracy: 0.6920 - val_loss: 0.7900 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 240/600\n",
            "2/2 - 0s - loss: 0.5707 - accuracy: 0.7160 - val_loss: 0.7950 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 241/600\n",
            "2/2 - 0s - loss: 0.5763 - accuracy: 0.6840 - val_loss: 0.7992 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 242/600\n",
            "2/2 - 0s - loss: 0.5754 - accuracy: 0.6880 - val_loss: 0.8041 - val_accuracy: 0.4286 - 34ms/epoch - 17ms/step\n",
            "Epoch 243/600\n",
            "2/2 - 0s - loss: 0.5839 - accuracy: 0.6840 - val_loss: 0.8039 - val_accuracy: 0.4127 - 35ms/epoch - 18ms/step\n",
            "Epoch 244/600\n",
            "2/2 - 0s - loss: 0.5674 - accuracy: 0.7040 - val_loss: 0.8082 - val_accuracy: 0.4286 - 31ms/epoch - 16ms/step\n",
            "Epoch 245/600\n",
            "2/2 - 0s - loss: 0.5847 - accuracy: 0.6880 - val_loss: 0.8129 - val_accuracy: 0.4286 - 32ms/epoch - 16ms/step\n",
            "Epoch 246/600\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7080 - val_loss: 0.8129 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 247/600\n",
            "2/2 - 0s - loss: 0.5776 - accuracy: 0.7080 - val_loss: 0.8098 - val_accuracy: 0.4286 - 38ms/epoch - 19ms/step\n",
            "Epoch 248/600\n",
            "2/2 - 0s - loss: 0.5648 - accuracy: 0.7120 - val_loss: 0.8027 - val_accuracy: 0.4127 - 29ms/epoch - 14ms/step\n",
            "Epoch 249/600\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.7120 - val_loss: 0.8030 - val_accuracy: 0.4127 - 33ms/epoch - 16ms/step\n",
            "Epoch 250/600\n",
            "2/2 - 0s - loss: 0.5730 - accuracy: 0.7080 - val_loss: 0.7962 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 251/600\n",
            "2/2 - 0s - loss: 0.5666 - accuracy: 0.6920 - val_loss: 0.7963 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 252/600\n",
            "2/2 - 0s - loss: 0.5626 - accuracy: 0.7240 - val_loss: 0.8017 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 253/600\n",
            "2/2 - 0s - loss: 0.5727 - accuracy: 0.6960 - val_loss: 0.8097 - val_accuracy: 0.4286 - 39ms/epoch - 19ms/step\n",
            "Epoch 254/600\n",
            "2/2 - 0s - loss: 0.5738 - accuracy: 0.7080 - val_loss: 0.8184 - val_accuracy: 0.4127 - 35ms/epoch - 18ms/step\n",
            "Epoch 255/600\n",
            "2/2 - 0s - loss: 0.5571 - accuracy: 0.7160 - val_loss: 0.8270 - val_accuracy: 0.4127 - 33ms/epoch - 17ms/step\n",
            "Epoch 256/600\n",
            "2/2 - 0s - loss: 0.5658 - accuracy: 0.6880 - val_loss: 0.8290 - val_accuracy: 0.4603 - 38ms/epoch - 19ms/step\n",
            "Epoch 257/600\n",
            "2/2 - 0s - loss: 0.5694 - accuracy: 0.7000 - val_loss: 0.8347 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 258/600\n",
            "2/2 - 0s - loss: 0.5620 - accuracy: 0.7160 - val_loss: 0.8311 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 259/600\n",
            "2/2 - 0s - loss: 0.5786 - accuracy: 0.6840 - val_loss: 0.8262 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 260/600\n",
            "2/2 - 0s - loss: 0.5686 - accuracy: 0.7000 - val_loss: 0.8202 - val_accuracy: 0.4603 - 37ms/epoch - 19ms/step\n",
            "Epoch 261/600\n",
            "2/2 - 0s - loss: 0.5685 - accuracy: 0.6840 - val_loss: 0.8130 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 262/600\n",
            "2/2 - 0s - loss: 0.5628 - accuracy: 0.7240 - val_loss: 0.8102 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 263/600\n",
            "2/2 - 0s - loss: 0.5639 - accuracy: 0.6760 - val_loss: 0.8085 - val_accuracy: 0.4603 - 29ms/epoch - 15ms/step\n",
            "Epoch 264/600\n",
            "2/2 - 0s - loss: 0.5752 - accuracy: 0.7120 - val_loss: 0.8044 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 265/600\n",
            "2/2 - 0s - loss: 0.5645 - accuracy: 0.7120 - val_loss: 0.8037 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 266/600\n",
            "2/2 - 0s - loss: 0.5757 - accuracy: 0.6920 - val_loss: 0.8074 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 267/600\n",
            "2/2 - 0s - loss: 0.5634 - accuracy: 0.7240 - val_loss: 0.8119 - val_accuracy: 0.4603 - 35ms/epoch - 17ms/step\n",
            "Epoch 268/600\n",
            "2/2 - 0s - loss: 0.5727 - accuracy: 0.7000 - val_loss: 0.8202 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 269/600\n",
            "2/2 - 0s - loss: 0.5599 - accuracy: 0.7240 - val_loss: 0.8287 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 270/600\n",
            "2/2 - 0s - loss: 0.5619 - accuracy: 0.7200 - val_loss: 0.8358 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 271/600\n",
            "2/2 - 0s - loss: 0.5709 - accuracy: 0.7000 - val_loss: 0.8395 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 272/600\n",
            "2/2 - 0s - loss: 0.5549 - accuracy: 0.7440 - val_loss: 0.8408 - val_accuracy: 0.4286 - 33ms/epoch - 17ms/step\n",
            "Epoch 273/600\n",
            "2/2 - 0s - loss: 0.5587 - accuracy: 0.7000 - val_loss: 0.8391 - val_accuracy: 0.4603 - 35ms/epoch - 18ms/step\n",
            "Epoch 274/600\n",
            "2/2 - 0s - loss: 0.5856 - accuracy: 0.6800 - val_loss: 0.8330 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 275/600\n",
            "2/2 - 0s - loss: 0.5455 - accuracy: 0.7360 - val_loss: 0.8305 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 276/600\n",
            "2/2 - 0s - loss: 0.5530 - accuracy: 0.7000 - val_loss: 0.8336 - val_accuracy: 0.4762 - 39ms/epoch - 20ms/step\n",
            "Epoch 277/600\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6920 - val_loss: 0.8378 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 278/600\n",
            "2/2 - 0s - loss: 0.5677 - accuracy: 0.7200 - val_loss: 0.8411 - val_accuracy: 0.4603 - 38ms/epoch - 19ms/step\n",
            "Epoch 279/600\n",
            "2/2 - 0s - loss: 0.5700 - accuracy: 0.6760 - val_loss: 0.8364 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 280/600\n",
            "2/2 - 0s - loss: 0.5714 - accuracy: 0.6840 - val_loss: 0.8298 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 281/600\n",
            "2/2 - 0s - loss: 0.5557 - accuracy: 0.7040 - val_loss: 0.8302 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 282/600\n",
            "2/2 - 0s - loss: 0.5480 - accuracy: 0.7320 - val_loss: 0.8320 - val_accuracy: 0.4603 - 35ms/epoch - 18ms/step\n",
            "Epoch 283/600\n",
            "2/2 - 0s - loss: 0.5623 - accuracy: 0.7120 - val_loss: 0.8338 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 284/600\n",
            "2/2 - 0s - loss: 0.5536 - accuracy: 0.7200 - val_loss: 0.8335 - val_accuracy: 0.4603 - 27ms/epoch - 14ms/step\n",
            "Epoch 285/600\n",
            "2/2 - 0s - loss: 0.5736 - accuracy: 0.7080 - val_loss: 0.8365 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 286/600\n",
            "2/2 - 0s - loss: 0.5723 - accuracy: 0.7200 - val_loss: 0.8381 - val_accuracy: 0.4603 - 44ms/epoch - 22ms/step\n",
            "Epoch 287/600\n",
            "2/2 - 0s - loss: 0.5602 - accuracy: 0.7120 - val_loss: 0.8410 - val_accuracy: 0.4286 - 30ms/epoch - 15ms/step\n",
            "Epoch 288/600\n",
            "2/2 - 0s - loss: 0.5559 - accuracy: 0.7040 - val_loss: 0.8340 - val_accuracy: 0.4603 - 37ms/epoch - 18ms/step\n",
            "Epoch 289/600\n",
            "2/2 - 0s - loss: 0.5744 - accuracy: 0.7000 - val_loss: 0.8360 - val_accuracy: 0.4603 - 37ms/epoch - 18ms/step\n",
            "Epoch 290/600\n",
            "2/2 - 0s - loss: 0.5444 - accuracy: 0.7440 - val_loss: 0.8389 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 291/600\n",
            "2/2 - 0s - loss: 0.5545 - accuracy: 0.7000 - val_loss: 0.8387 - val_accuracy: 0.4921 - 29ms/epoch - 14ms/step\n",
            "Epoch 292/600\n",
            "2/2 - 0s - loss: 0.5399 - accuracy: 0.7000 - val_loss: 0.8377 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 293/600\n",
            "2/2 - 0s - loss: 0.5353 - accuracy: 0.7400 - val_loss: 0.8407 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 294/600\n",
            "2/2 - 0s - loss: 0.5661 - accuracy: 0.7000 - val_loss: 0.8457 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 295/600\n",
            "2/2 - 0s - loss: 0.5506 - accuracy: 0.7040 - val_loss: 0.8516 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 296/600\n",
            "2/2 - 0s - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.8549 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 297/600\n",
            "2/2 - 0s - loss: 0.5663 - accuracy: 0.7280 - val_loss: 0.8510 - val_accuracy: 0.4444 - 33ms/epoch - 16ms/step\n",
            "Epoch 298/600\n",
            "2/2 - 0s - loss: 0.5408 - accuracy: 0.7080 - val_loss: 0.8499 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 299/600\n",
            "2/2 - 0s - loss: 0.5427 - accuracy: 0.7120 - val_loss: 0.8446 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 300/600\n",
            "2/2 - 0s - loss: 0.5731 - accuracy: 0.6920 - val_loss: 0.8394 - val_accuracy: 0.4603 - 35ms/epoch - 18ms/step\n",
            "Epoch 301/600\n",
            "2/2 - 0s - loss: 0.5231 - accuracy: 0.7320 - val_loss: 0.8339 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 302/600\n",
            "2/2 - 0s - loss: 0.5446 - accuracy: 0.7320 - val_loss: 0.8352 - val_accuracy: 0.4762 - 27ms/epoch - 14ms/step\n",
            "Epoch 303/600\n",
            "2/2 - 0s - loss: 0.5170 - accuracy: 0.7360 - val_loss: 0.8400 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 304/600\n",
            "2/2 - 0s - loss: 0.5447 - accuracy: 0.7480 - val_loss: 0.8464 - val_accuracy: 0.4762 - 29ms/epoch - 14ms/step\n",
            "Epoch 305/600\n",
            "2/2 - 0s - loss: 0.5265 - accuracy: 0.7240 - val_loss: 0.8558 - val_accuracy: 0.4603 - 29ms/epoch - 15ms/step\n",
            "Epoch 306/600\n",
            "2/2 - 0s - loss: 0.5332 - accuracy: 0.7080 - val_loss: 0.8692 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 307/600\n",
            "2/2 - 0s - loss: 0.5547 - accuracy: 0.7280 - val_loss: 0.8760 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 308/600\n",
            "2/2 - 0s - loss: 0.5643 - accuracy: 0.7000 - val_loss: 0.8767 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 309/600\n",
            "2/2 - 0s - loss: 0.5546 - accuracy: 0.7160 - val_loss: 0.8727 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 310/600\n",
            "2/2 - 0s - loss: 0.5545 - accuracy: 0.6760 - val_loss: 0.8636 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 311/600\n",
            "2/2 - 0s - loss: 0.5417 - accuracy: 0.7080 - val_loss: 0.8592 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 312/600\n",
            "2/2 - 0s - loss: 0.5401 - accuracy: 0.7200 - val_loss: 0.8549 - val_accuracy: 0.4444 - 35ms/epoch - 17ms/step\n",
            "Epoch 313/600\n",
            "2/2 - 0s - loss: 0.5497 - accuracy: 0.7440 - val_loss: 0.8551 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 314/600\n",
            "2/2 - 0s - loss: 0.5528 - accuracy: 0.6920 - val_loss: 0.8589 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 315/600\n",
            "2/2 - 0s - loss: 0.5453 - accuracy: 0.7400 - val_loss: 0.8683 - val_accuracy: 0.4444 - 35ms/epoch - 18ms/step\n",
            "Epoch 316/600\n",
            "2/2 - 0s - loss: 0.5207 - accuracy: 0.7440 - val_loss: 0.8794 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 317/600\n",
            "2/2 - 0s - loss: 0.5326 - accuracy: 0.7160 - val_loss: 0.8818 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 318/600\n",
            "2/2 - 0s - loss: 0.5453 - accuracy: 0.7160 - val_loss: 0.8809 - val_accuracy: 0.4444 - 44ms/epoch - 22ms/step\n",
            "Epoch 319/600\n",
            "2/2 - 0s - loss: 0.5380 - accuracy: 0.6960 - val_loss: 0.8754 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 320/600\n",
            "2/2 - 0s - loss: 0.5362 - accuracy: 0.7240 - val_loss: 0.8674 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 321/600\n",
            "2/2 - 0s - loss: 0.5300 - accuracy: 0.7360 - val_loss: 0.8672 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 322/600\n",
            "2/2 - 0s - loss: 0.5513 - accuracy: 0.7000 - val_loss: 0.8667 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 323/600\n",
            "2/2 - 0s - loss: 0.5506 - accuracy: 0.7080 - val_loss: 0.8723 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 324/600\n",
            "2/2 - 0s - loss: 0.5398 - accuracy: 0.7280 - val_loss: 0.8744 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 325/600\n",
            "2/2 - 0s - loss: 0.5406 - accuracy: 0.7040 - val_loss: 0.8705 - val_accuracy: 0.4444 - 33ms/epoch - 17ms/step\n",
            "Epoch 326/600\n",
            "2/2 - 0s - loss: 0.5156 - accuracy: 0.7640 - val_loss: 0.8717 - val_accuracy: 0.4603 - 33ms/epoch - 16ms/step\n",
            "Epoch 327/600\n",
            "2/2 - 0s - loss: 0.5409 - accuracy: 0.6960 - val_loss: 0.8727 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 328/600\n",
            "2/2 - 0s - loss: 0.5317 - accuracy: 0.7360 - val_loss: 0.8751 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 329/600\n",
            "2/2 - 0s - loss: 0.5307 - accuracy: 0.7400 - val_loss: 0.8781 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 330/600\n",
            "2/2 - 0s - loss: 0.5402 - accuracy: 0.7000 - val_loss: 0.8824 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 331/600\n",
            "2/2 - 0s - loss: 0.5398 - accuracy: 0.7240 - val_loss: 0.8792 - val_accuracy: 0.4444 - 35ms/epoch - 17ms/step\n",
            "Epoch 332/600\n",
            "2/2 - 0s - loss: 0.5232 - accuracy: 0.7440 - val_loss: 0.8708 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 333/600\n",
            "2/2 - 0s - loss: 0.5306 - accuracy: 0.7400 - val_loss: 0.8678 - val_accuracy: 0.4603 - 50ms/epoch - 25ms/step\n",
            "Epoch 334/600\n",
            "2/2 - 0s - loss: 0.5161 - accuracy: 0.7520 - val_loss: 0.8702 - val_accuracy: 0.4603 - 27ms/epoch - 13ms/step\n",
            "Epoch 335/600\n",
            "2/2 - 0s - loss: 0.5315 - accuracy: 0.7320 - val_loss: 0.8739 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 336/600\n",
            "2/2 - 0s - loss: 0.5367 - accuracy: 0.7200 - val_loss: 0.8849 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 337/600\n",
            "2/2 - 0s - loss: 0.5393 - accuracy: 0.7560 - val_loss: 0.8966 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 338/600\n",
            "2/2 - 0s - loss: 0.5419 - accuracy: 0.7080 - val_loss: 0.9049 - val_accuracy: 0.4444 - 33ms/epoch - 16ms/step\n",
            "Epoch 339/600\n",
            "2/2 - 0s - loss: 0.5617 - accuracy: 0.6960 - val_loss: 0.9122 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 340/600\n",
            "2/2 - 0s - loss: 0.5495 - accuracy: 0.7160 - val_loss: 0.9195 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 341/600\n",
            "2/2 - 0s - loss: 0.5450 - accuracy: 0.7440 - val_loss: 0.9149 - val_accuracy: 0.4444 - 33ms/epoch - 16ms/step\n",
            "Epoch 342/600\n",
            "2/2 - 0s - loss: 0.5267 - accuracy: 0.7520 - val_loss: 0.9057 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 343/600\n",
            "2/2 - 0s - loss: 0.5286 - accuracy: 0.7160 - val_loss: 0.8998 - val_accuracy: 0.4444 - 52ms/epoch - 26ms/step\n",
            "Epoch 344/600\n",
            "2/2 - 0s - loss: 0.5390 - accuracy: 0.7280 - val_loss: 0.8984 - val_accuracy: 0.4444 - 28ms/epoch - 14ms/step\n",
            "Epoch 345/600\n",
            "2/2 - 0s - loss: 0.5192 - accuracy: 0.7240 - val_loss: 0.8956 - val_accuracy: 0.4444 - 41ms/epoch - 20ms/step\n",
            "Epoch 346/600\n",
            "2/2 - 0s - loss: 0.5376 - accuracy: 0.7160 - val_loss: 0.8985 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 347/600\n",
            "2/2 - 0s - loss: 0.5318 - accuracy: 0.7200 - val_loss: 0.8983 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 348/600\n",
            "2/2 - 0s - loss: 0.5159 - accuracy: 0.7440 - val_loss: 0.9043 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 349/600\n",
            "2/2 - 0s - loss: 0.5402 - accuracy: 0.7120 - val_loss: 0.9086 - val_accuracy: 0.4603 - 37ms/epoch - 19ms/step\n",
            "Epoch 350/600\n",
            "2/2 - 0s - loss: 0.5340 - accuracy: 0.7000 - val_loss: 0.9034 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 351/600\n",
            "2/2 - 0s - loss: 0.4940 - accuracy: 0.7720 - val_loss: 0.9032 - val_accuracy: 0.4762 - 29ms/epoch - 14ms/step\n",
            "Epoch 352/600\n",
            "2/2 - 0s - loss: 0.5332 - accuracy: 0.7280 - val_loss: 0.9064 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 353/600\n",
            "2/2 - 0s - loss: 0.5594 - accuracy: 0.7080 - val_loss: 0.9109 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 354/600\n",
            "2/2 - 0s - loss: 0.5101 - accuracy: 0.7720 - val_loss: 0.9194 - val_accuracy: 0.4762 - 33ms/epoch - 16ms/step\n",
            "Epoch 355/600\n",
            "2/2 - 0s - loss: 0.5056 - accuracy: 0.7440 - val_loss: 0.9262 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 356/600\n",
            "2/2 - 0s - loss: 0.5152 - accuracy: 0.7520 - val_loss: 0.9326 - val_accuracy: 0.4444 - 33ms/epoch - 17ms/step\n",
            "Epoch 357/600\n",
            "2/2 - 0s - loss: 0.5218 - accuracy: 0.7440 - val_loss: 0.9332 - val_accuracy: 0.4444 - 38ms/epoch - 19ms/step\n",
            "Epoch 358/600\n",
            "2/2 - 0s - loss: 0.5299 - accuracy: 0.7400 - val_loss: 0.9301 - val_accuracy: 0.4444 - 31ms/epoch - 16ms/step\n",
            "Epoch 359/600\n",
            "2/2 - 0s - loss: 0.5316 - accuracy: 0.7520 - val_loss: 0.9255 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 360/600\n",
            "2/2 - 0s - loss: 0.5260 - accuracy: 0.7240 - val_loss: 0.9224 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 361/600\n",
            "2/2 - 0s - loss: 0.5157 - accuracy: 0.7360 - val_loss: 0.9241 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 362/600\n",
            "2/2 - 0s - loss: 0.5298 - accuracy: 0.7160 - val_loss: 0.9240 - val_accuracy: 0.4444 - 35ms/epoch - 18ms/step\n",
            "Epoch 363/600\n",
            "2/2 - 0s - loss: 0.4947 - accuracy: 0.7600 - val_loss: 0.9250 - val_accuracy: 0.4444 - 48ms/epoch - 24ms/step\n",
            "Epoch 364/600\n",
            "2/2 - 0s - loss: 0.5206 - accuracy: 0.7400 - val_loss: 0.9294 - val_accuracy: 0.4444 - 30ms/epoch - 15ms/step\n",
            "Epoch 365/600\n",
            "2/2 - 0s - loss: 0.5352 - accuracy: 0.7200 - val_loss: 0.9350 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 366/600\n",
            "2/2 - 0s - loss: 0.4985 - accuracy: 0.7560 - val_loss: 0.9439 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 367/600\n",
            "2/2 - 0s - loss: 0.5305 - accuracy: 0.7200 - val_loss: 0.9479 - val_accuracy: 0.4444 - 29ms/epoch - 14ms/step\n",
            "Epoch 368/600\n",
            "2/2 - 0s - loss: 0.5224 - accuracy: 0.7440 - val_loss: 0.9482 - val_accuracy: 0.4444 - 32ms/epoch - 16ms/step\n",
            "Epoch 369/600\n",
            "2/2 - 0s - loss: 0.5264 - accuracy: 0.7440 - val_loss: 0.9453 - val_accuracy: 0.4444 - 27ms/epoch - 14ms/step\n",
            "Epoch 370/600\n",
            "2/2 - 0s - loss: 0.4969 - accuracy: 0.7360 - val_loss: 0.9448 - val_accuracy: 0.4444 - 31ms/epoch - 15ms/step\n",
            "Epoch 371/600\n",
            "2/2 - 0s - loss: 0.5136 - accuracy: 0.7360 - val_loss: 0.9404 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 372/600\n",
            "2/2 - 0s - loss: 0.5271 - accuracy: 0.7440 - val_loss: 0.9341 - val_accuracy: 0.4603 - 48ms/epoch - 24ms/step\n",
            "Epoch 373/600\n",
            "2/2 - 0s - loss: 0.5213 - accuracy: 0.7320 - val_loss: 0.9308 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 374/600\n",
            "2/2 - 0s - loss: 0.5237 - accuracy: 0.7640 - val_loss: 0.9338 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 375/600\n",
            "2/2 - 0s - loss: 0.4880 - accuracy: 0.7760 - val_loss: 0.9411 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 376/600\n",
            "2/2 - 0s - loss: 0.5079 - accuracy: 0.7520 - val_loss: 0.9477 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 377/600\n",
            "2/2 - 0s - loss: 0.5274 - accuracy: 0.7320 - val_loss: 0.9551 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 378/600\n",
            "2/2 - 0s - loss: 0.5237 - accuracy: 0.7240 - val_loss: 0.9531 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 379/600\n",
            "2/2 - 0s - loss: 0.5344 - accuracy: 0.7240 - val_loss: 0.9544 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 380/600\n",
            "2/2 - 0s - loss: 0.5213 - accuracy: 0.7320 - val_loss: 0.9553 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 381/600\n",
            "2/2 - 0s - loss: 0.5176 - accuracy: 0.7400 - val_loss: 0.9588 - val_accuracy: 0.4762 - 31ms/epoch - 15ms/step\n",
            "Epoch 382/600\n",
            "2/2 - 0s - loss: 0.5245 - accuracy: 0.7400 - val_loss: 0.9572 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 383/600\n",
            "2/2 - 0s - loss: 0.5308 - accuracy: 0.7440 - val_loss: 0.9626 - val_accuracy: 0.4444 - 29ms/epoch - 15ms/step\n",
            "Epoch 384/600\n",
            "2/2 - 0s - loss: 0.5344 - accuracy: 0.7160 - val_loss: 0.9589 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 385/600\n",
            "2/2 - 0s - loss: 0.5279 - accuracy: 0.7120 - val_loss: 0.9551 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 386/600\n",
            "2/2 - 0s - loss: 0.5131 - accuracy: 0.7600 - val_loss: 0.9551 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 387/600\n",
            "2/2 - 0s - loss: 0.5154 - accuracy: 0.7720 - val_loss: 0.9603 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 388/600\n",
            "2/2 - 0s - loss: 0.5412 - accuracy: 0.7360 - val_loss: 0.9669 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 389/600\n",
            "2/2 - 0s - loss: 0.5260 - accuracy: 0.7120 - val_loss: 0.9646 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 390/600\n",
            "2/2 - 0s - loss: 0.5028 - accuracy: 0.7920 - val_loss: 0.9527 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 391/600\n",
            "2/2 - 0s - loss: 0.5204 - accuracy: 0.7440 - val_loss: 0.9406 - val_accuracy: 0.4921 - 40ms/epoch - 20ms/step\n",
            "Epoch 392/600\n",
            "2/2 - 0s - loss: 0.5167 - accuracy: 0.7600 - val_loss: 0.9299 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 393/600\n",
            "2/2 - 0s - loss: 0.5226 - accuracy: 0.7240 - val_loss: 0.9311 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 394/600\n",
            "2/2 - 0s - loss: 0.5221 - accuracy: 0.7240 - val_loss: 0.9394 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 395/600\n",
            "2/2 - 0s - loss: 0.5231 - accuracy: 0.7280 - val_loss: 0.9494 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 396/600\n",
            "2/2 - 0s - loss: 0.5067 - accuracy: 0.7400 - val_loss: 0.9621 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 397/600\n",
            "2/2 - 0s - loss: 0.5124 - accuracy: 0.7160 - val_loss: 0.9711 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 398/600\n",
            "2/2 - 0s - loss: 0.5088 - accuracy: 0.7400 - val_loss: 0.9656 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 399/600\n",
            "2/2 - 0s - loss: 0.5236 - accuracy: 0.7440 - val_loss: 0.9624 - val_accuracy: 0.4603 - 40ms/epoch - 20ms/step\n",
            "Epoch 400/600\n",
            "2/2 - 0s - loss: 0.5365 - accuracy: 0.7040 - val_loss: 0.9603 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 401/600\n",
            "2/2 - 0s - loss: 0.4853 - accuracy: 0.7600 - val_loss: 0.9595 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 402/600\n",
            "2/2 - 0s - loss: 0.5296 - accuracy: 0.7360 - val_loss: 0.9635 - val_accuracy: 0.4444 - 34ms/epoch - 17ms/step\n",
            "Epoch 403/600\n",
            "2/2 - 0s - loss: 0.4805 - accuracy: 0.7480 - val_loss: 0.9684 - val_accuracy: 0.4444 - 36ms/epoch - 18ms/step\n",
            "Epoch 404/600\n",
            "2/2 - 0s - loss: 0.4845 - accuracy: 0.7600 - val_loss: 0.9727 - val_accuracy: 0.4444 - 40ms/epoch - 20ms/step\n",
            "Epoch 405/600\n",
            "2/2 - 0s - loss: 0.5118 - accuracy: 0.7280 - val_loss: 0.9741 - val_accuracy: 0.4444 - 40ms/epoch - 20ms/step\n",
            "Epoch 406/600\n",
            "2/2 - 0s - loss: 0.5047 - accuracy: 0.7640 - val_loss: 0.9737 - val_accuracy: 0.4444 - 35ms/epoch - 17ms/step\n",
            "Epoch 407/600\n",
            "2/2 - 0s - loss: 0.5266 - accuracy: 0.7200 - val_loss: 0.9708 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 408/600\n",
            "2/2 - 0s - loss: 0.5352 - accuracy: 0.7560 - val_loss: 0.9760 - val_accuracy: 0.4762 - 29ms/epoch - 15ms/step\n",
            "Epoch 409/600\n",
            "2/2 - 0s - loss: 0.5151 - accuracy: 0.7200 - val_loss: 0.9828 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 410/600\n",
            "2/2 - 0s - loss: 0.5118 - accuracy: 0.7480 - val_loss: 0.9877 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 411/600\n",
            "2/2 - 0s - loss: 0.4924 - accuracy: 0.7680 - val_loss: 0.9937 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 412/600\n",
            "2/2 - 0s - loss: 0.5102 - accuracy: 0.7400 - val_loss: 0.9948 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 413/600\n",
            "2/2 - 0s - loss: 0.4959 - accuracy: 0.7480 - val_loss: 0.9889 - val_accuracy: 0.4762 - 38ms/epoch - 19ms/step\n",
            "Epoch 414/600\n",
            "2/2 - 0s - loss: 0.5041 - accuracy: 0.7680 - val_loss: 0.9886 - val_accuracy: 0.4921 - 39ms/epoch - 19ms/step\n",
            "Epoch 415/600\n",
            "2/2 - 0s - loss: 0.5221 - accuracy: 0.7280 - val_loss: 0.9861 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 416/600\n",
            "2/2 - 0s - loss: 0.5153 - accuracy: 0.7320 - val_loss: 0.9886 - val_accuracy: 0.4603 - 28ms/epoch - 14ms/step\n",
            "Epoch 417/600\n",
            "2/2 - 0s - loss: 0.5040 - accuracy: 0.7440 - val_loss: 0.9927 - val_accuracy: 0.4603 - 31ms/epoch - 16ms/step\n",
            "Epoch 418/600\n",
            "2/2 - 0s - loss: 0.4824 - accuracy: 0.7520 - val_loss: 0.9967 - val_accuracy: 0.4603 - 29ms/epoch - 14ms/step\n",
            "Epoch 419/600\n",
            "2/2 - 0s - loss: 0.5199 - accuracy: 0.7280 - val_loss: 0.9975 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 420/600\n",
            "2/2 - 0s - loss: 0.4998 - accuracy: 0.7440 - val_loss: 1.0003 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 421/600\n",
            "2/2 - 0s - loss: 0.4980 - accuracy: 0.7760 - val_loss: 1.0056 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 422/600\n",
            "2/2 - 0s - loss: 0.5164 - accuracy: 0.7360 - val_loss: 1.0122 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 423/600\n",
            "2/2 - 0s - loss: 0.4732 - accuracy: 0.7640 - val_loss: 1.0152 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 424/600\n",
            "2/2 - 0s - loss: 0.5008 - accuracy: 0.7640 - val_loss: 1.0176 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 425/600\n",
            "2/2 - 0s - loss: 0.4799 - accuracy: 0.7880 - val_loss: 1.0221 - val_accuracy: 0.4762 - 33ms/epoch - 16ms/step\n",
            "Epoch 426/600\n",
            "2/2 - 0s - loss: 0.4841 - accuracy: 0.7480 - val_loss: 1.0215 - val_accuracy: 0.4603 - 37ms/epoch - 19ms/step\n",
            "Epoch 427/600\n",
            "2/2 - 0s - loss: 0.5122 - accuracy: 0.7240 - val_loss: 1.0177 - val_accuracy: 0.4603 - 35ms/epoch - 18ms/step\n",
            "Epoch 428/600\n",
            "2/2 - 0s - loss: 0.5013 - accuracy: 0.7600 - val_loss: 1.0091 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 429/600\n",
            "2/2 - 0s - loss: 0.4975 - accuracy: 0.7560 - val_loss: 1.0046 - val_accuracy: 0.4603 - 38ms/epoch - 19ms/step\n",
            "Epoch 430/600\n",
            "2/2 - 0s - loss: 0.4964 - accuracy: 0.7440 - val_loss: 0.9998 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 431/600\n",
            "2/2 - 0s - loss: 0.5137 - accuracy: 0.7480 - val_loss: 1.0017 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 432/600\n",
            "2/2 - 0s - loss: 0.5002 - accuracy: 0.7440 - val_loss: 1.0025 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 433/600\n",
            "2/2 - 0s - loss: 0.4841 - accuracy: 0.7280 - val_loss: 1.0057 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 434/600\n",
            "2/2 - 0s - loss: 0.5201 - accuracy: 0.7280 - val_loss: 1.0149 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 435/600\n",
            "2/2 - 0s - loss: 0.4708 - accuracy: 0.7640 - val_loss: 1.0238 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 436/600\n",
            "2/2 - 0s - loss: 0.5068 - accuracy: 0.7560 - val_loss: 1.0308 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 437/600\n",
            "2/2 - 0s - loss: 0.5306 - accuracy: 0.7400 - val_loss: 1.0313 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 438/600\n",
            "2/2 - 0s - loss: 0.4969 - accuracy: 0.7720 - val_loss: 1.0299 - val_accuracy: 0.5079 - 29ms/epoch - 15ms/step\n",
            "Epoch 439/600\n",
            "2/2 - 0s - loss: 0.5028 - accuracy: 0.7640 - val_loss: 1.0250 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 440/600\n",
            "2/2 - 0s - loss: 0.4944 - accuracy: 0.7600 - val_loss: 1.0253 - val_accuracy: 0.4921 - 44ms/epoch - 22ms/step\n",
            "Epoch 441/600\n",
            "2/2 - 0s - loss: 0.5073 - accuracy: 0.7480 - val_loss: 1.0270 - val_accuracy: 0.4762 - 35ms/epoch - 18ms/step\n",
            "Epoch 442/600\n",
            "2/2 - 0s - loss: 0.5265 - accuracy: 0.7280 - val_loss: 1.0318 - val_accuracy: 0.4762 - 28ms/epoch - 14ms/step\n",
            "Epoch 443/600\n",
            "2/2 - 0s - loss: 0.4942 - accuracy: 0.7600 - val_loss: 1.0381 - val_accuracy: 0.4762 - 57ms/epoch - 29ms/step\n",
            "Epoch 444/600\n",
            "2/2 - 0s - loss: 0.4964 - accuracy: 0.7520 - val_loss: 1.0370 - val_accuracy: 0.4921 - 39ms/epoch - 20ms/step\n",
            "Epoch 445/600\n",
            "2/2 - 0s - loss: 0.4888 - accuracy: 0.7320 - val_loss: 1.0365 - val_accuracy: 0.4921 - 29ms/epoch - 14ms/step\n",
            "Epoch 446/600\n",
            "2/2 - 0s - loss: 0.5029 - accuracy: 0.7560 - val_loss: 1.0389 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 447/600\n",
            "2/2 - 0s - loss: 0.4853 - accuracy: 0.7600 - val_loss: 1.0342 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 448/600\n",
            "2/2 - 0s - loss: 0.5101 - accuracy: 0.7360 - val_loss: 1.0279 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 449/600\n",
            "2/2 - 0s - loss: 0.4910 - accuracy: 0.7680 - val_loss: 1.0221 - val_accuracy: 0.4762 - 29ms/epoch - 15ms/step\n",
            "Epoch 450/600\n",
            "2/2 - 0s - loss: 0.5029 - accuracy: 0.7240 - val_loss: 1.0163 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 451/600\n",
            "2/2 - 0s - loss: 0.5210 - accuracy: 0.7480 - val_loss: 1.0193 - val_accuracy: 0.4762 - 47ms/epoch - 23ms/step\n",
            "Epoch 452/600\n",
            "2/2 - 0s - loss: 0.4599 - accuracy: 0.7840 - val_loss: 1.0261 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 453/600\n",
            "2/2 - 0s - loss: 0.4796 - accuracy: 0.7520 - val_loss: 1.0279 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 454/600\n",
            "2/2 - 0s - loss: 0.4892 - accuracy: 0.7400 - val_loss: 1.0275 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 455/600\n",
            "2/2 - 0s - loss: 0.4860 - accuracy: 0.7560 - val_loss: 1.0281 - val_accuracy: 0.4762 - 35ms/epoch - 18ms/step\n",
            "Epoch 456/600\n",
            "2/2 - 0s - loss: 0.4914 - accuracy: 0.7840 - val_loss: 1.0284 - val_accuracy: 0.4921 - 29ms/epoch - 14ms/step\n",
            "Epoch 457/600\n",
            "2/2 - 0s - loss: 0.4801 - accuracy: 0.7640 - val_loss: 1.0329 - val_accuracy: 0.4921 - 35ms/epoch - 18ms/step\n",
            "Epoch 458/600\n",
            "2/2 - 0s - loss: 0.4957 - accuracy: 0.7480 - val_loss: 1.0310 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 459/600\n",
            "2/2 - 0s - loss: 0.4992 - accuracy: 0.7280 - val_loss: 1.0282 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 460/600\n",
            "2/2 - 0s - loss: 0.5029 - accuracy: 0.7440 - val_loss: 1.0330 - val_accuracy: 0.4921 - 29ms/epoch - 14ms/step\n",
            "Epoch 461/600\n",
            "2/2 - 0s - loss: 0.4639 - accuracy: 0.7920 - val_loss: 1.0476 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 462/600\n",
            "2/2 - 0s - loss: 0.4887 - accuracy: 0.7880 - val_loss: 1.0564 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 463/600\n",
            "2/2 - 0s - loss: 0.4892 - accuracy: 0.7880 - val_loss: 1.0696 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 464/600\n",
            "2/2 - 0s - loss: 0.4850 - accuracy: 0.7760 - val_loss: 1.0709 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 465/600\n",
            "2/2 - 0s - loss: 0.5182 - accuracy: 0.7240 - val_loss: 1.0657 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 466/600\n",
            "2/2 - 0s - loss: 0.4755 - accuracy: 0.7840 - val_loss: 1.0604 - val_accuracy: 0.4921 - 39ms/epoch - 19ms/step\n",
            "Epoch 467/600\n",
            "2/2 - 0s - loss: 0.4955 - accuracy: 0.7360 - val_loss: 1.0559 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 468/600\n",
            "2/2 - 0s - loss: 0.4822 - accuracy: 0.7720 - val_loss: 1.0596 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 469/600\n",
            "2/2 - 0s - loss: 0.4811 - accuracy: 0.7680 - val_loss: 1.0688 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 470/600\n",
            "2/2 - 0s - loss: 0.5040 - accuracy: 0.7560 - val_loss: 1.0727 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 471/600\n",
            "2/2 - 0s - loss: 0.5077 - accuracy: 0.7400 - val_loss: 1.0748 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 472/600\n",
            "2/2 - 0s - loss: 0.4968 - accuracy: 0.7600 - val_loss: 1.0676 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 473/600\n",
            "2/2 - 0s - loss: 0.5030 - accuracy: 0.7400 - val_loss: 1.0667 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 474/600\n",
            "2/2 - 0s - loss: 0.4809 - accuracy: 0.7520 - val_loss: 1.0660 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 475/600\n",
            "2/2 - 0s - loss: 0.4911 - accuracy: 0.7880 - val_loss: 1.0662 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 476/600\n",
            "2/2 - 0s - loss: 0.5135 - accuracy: 0.7360 - val_loss: 1.0669 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 477/600\n",
            "2/2 - 0s - loss: 0.5118 - accuracy: 0.7280 - val_loss: 1.0680 - val_accuracy: 0.4762 - 48ms/epoch - 24ms/step\n",
            "Epoch 478/600\n",
            "2/2 - 0s - loss: 0.4980 - accuracy: 0.7440 - val_loss: 1.0634 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 479/600\n",
            "2/2 - 0s - loss: 0.4974 - accuracy: 0.7800 - val_loss: 1.0644 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 480/600\n",
            "2/2 - 0s - loss: 0.4944 - accuracy: 0.7440 - val_loss: 1.0718 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 481/600\n",
            "2/2 - 0s - loss: 0.4834 - accuracy: 0.7760 - val_loss: 1.0792 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 482/600\n",
            "2/2 - 0s - loss: 0.4602 - accuracy: 0.7960 - val_loss: 1.0816 - val_accuracy: 0.4921 - 39ms/epoch - 20ms/step\n",
            "Epoch 483/600\n",
            "2/2 - 0s - loss: 0.4875 - accuracy: 0.7640 - val_loss: 1.0817 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 484/600\n",
            "2/2 - 0s - loss: 0.4932 - accuracy: 0.7560 - val_loss: 1.0851 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 485/600\n",
            "2/2 - 0s - loss: 0.4820 - accuracy: 0.7680 - val_loss: 1.0859 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 486/600\n",
            "2/2 - 0s - loss: 0.4912 - accuracy: 0.7640 - val_loss: 1.0939 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 487/600\n",
            "2/2 - 0s - loss: 0.4845 - accuracy: 0.7760 - val_loss: 1.0989 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 488/600\n",
            "2/2 - 0s - loss: 0.4905 - accuracy: 0.7600 - val_loss: 1.1042 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 489/600\n",
            "2/2 - 0s - loss: 0.4801 - accuracy: 0.7560 - val_loss: 1.1032 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 490/600\n",
            "2/2 - 0s - loss: 0.4864 - accuracy: 0.7640 - val_loss: 1.0980 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 491/600\n",
            "2/2 - 0s - loss: 0.4938 - accuracy: 0.7480 - val_loss: 1.0919 - val_accuracy: 0.4921 - 53ms/epoch - 27ms/step\n",
            "Epoch 492/600\n",
            "2/2 - 0s - loss: 0.4701 - accuracy: 0.7800 - val_loss: 1.0842 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 493/600\n",
            "2/2 - 0s - loss: 0.4789 - accuracy: 0.7800 - val_loss: 1.0779 - val_accuracy: 0.4921 - 35ms/epoch - 18ms/step\n",
            "Epoch 494/600\n",
            "2/2 - 0s - loss: 0.4754 - accuracy: 0.7680 - val_loss: 1.0746 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 495/600\n",
            "2/2 - 0s - loss: 0.4579 - accuracy: 0.7680 - val_loss: 1.0734 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 496/600\n",
            "2/2 - 0s - loss: 0.4651 - accuracy: 0.7560 - val_loss: 1.0740 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 497/600\n",
            "2/2 - 0s - loss: 0.4952 - accuracy: 0.7360 - val_loss: 1.0778 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 498/600\n",
            "2/2 - 0s - loss: 0.4531 - accuracy: 0.7840 - val_loss: 1.0824 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 499/600\n",
            "2/2 - 0s - loss: 0.4429 - accuracy: 0.8040 - val_loss: 1.0957 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 500/600\n",
            "2/2 - 0s - loss: 0.4651 - accuracy: 0.7680 - val_loss: 1.1098 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 501/600\n",
            "2/2 - 0s - loss: 0.4859 - accuracy: 0.7800 - val_loss: 1.1201 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 502/600\n",
            "2/2 - 0s - loss: 0.4677 - accuracy: 0.7880 - val_loss: 1.1274 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 503/600\n",
            "2/2 - 0s - loss: 0.4888 - accuracy: 0.7800 - val_loss: 1.1240 - val_accuracy: 0.4921 - 47ms/epoch - 24ms/step\n",
            "Epoch 504/600\n",
            "2/2 - 0s - loss: 0.4834 - accuracy: 0.7640 - val_loss: 1.1285 - val_accuracy: 0.4921 - 40ms/epoch - 20ms/step\n",
            "Epoch 505/600\n",
            "2/2 - 0s - loss: 0.4875 - accuracy: 0.7600 - val_loss: 1.1369 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 506/600\n",
            "2/2 - 0s - loss: 0.4638 - accuracy: 0.7840 - val_loss: 1.1453 - val_accuracy: 0.4762 - 33ms/epoch - 16ms/step\n",
            "Epoch 507/600\n",
            "2/2 - 0s - loss: 0.4594 - accuracy: 0.8000 - val_loss: 1.1430 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 508/600\n",
            "2/2 - 0s - loss: 0.4726 - accuracy: 0.7640 - val_loss: 1.1366 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 509/600\n",
            "2/2 - 0s - loss: 0.4646 - accuracy: 0.7840 - val_loss: 1.1271 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 510/600\n",
            "2/2 - 0s - loss: 0.4694 - accuracy: 0.7440 - val_loss: 1.1255 - val_accuracy: 0.4762 - 35ms/epoch - 18ms/step\n",
            "Epoch 511/600\n",
            "2/2 - 0s - loss: 0.4792 - accuracy: 0.7840 - val_loss: 1.1273 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 512/600\n",
            "2/2 - 0s - loss: 0.4572 - accuracy: 0.7640 - val_loss: 1.1328 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 513/600\n",
            "2/2 - 0s - loss: 0.4602 - accuracy: 0.7640 - val_loss: 1.1429 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 514/600\n",
            "2/2 - 0s - loss: 0.4667 - accuracy: 0.7840 - val_loss: 1.1455 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 515/600\n",
            "2/2 - 0s - loss: 0.4874 - accuracy: 0.7600 - val_loss: 1.1446 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 516/600\n",
            "2/2 - 0s - loss: 0.4739 - accuracy: 0.7680 - val_loss: 1.1455 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 517/600\n",
            "2/2 - 0s - loss: 0.4773 - accuracy: 0.7600 - val_loss: 1.1490 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 518/600\n",
            "2/2 - 0s - loss: 0.5011 - accuracy: 0.7640 - val_loss: 1.1566 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 519/600\n",
            "2/2 - 0s - loss: 0.4378 - accuracy: 0.7920 - val_loss: 1.1626 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 520/600\n",
            "2/2 - 0s - loss: 0.4925 - accuracy: 0.7600 - val_loss: 1.1582 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 521/600\n",
            "2/2 - 0s - loss: 0.4866 - accuracy: 0.7440 - val_loss: 1.1473 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 522/600\n",
            "2/2 - 0s - loss: 0.4454 - accuracy: 0.8200 - val_loss: 1.1415 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 523/600\n",
            "2/2 - 0s - loss: 0.4649 - accuracy: 0.7800 - val_loss: 1.1362 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 524/600\n",
            "2/2 - 0s - loss: 0.4689 - accuracy: 0.7640 - val_loss: 1.1304 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 525/600\n",
            "2/2 - 0s - loss: 0.4849 - accuracy: 0.7640 - val_loss: 1.1218 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 526/600\n",
            "2/2 - 0s - loss: 0.4884 - accuracy: 0.7640 - val_loss: 1.1201 - val_accuracy: 0.4921 - 29ms/epoch - 14ms/step\n",
            "Epoch 527/600\n",
            "2/2 - 0s - loss: 0.4606 - accuracy: 0.7800 - val_loss: 1.1272 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 528/600\n",
            "2/2 - 0s - loss: 0.4525 - accuracy: 0.7680 - val_loss: 1.1456 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 529/600\n",
            "2/2 - 0s - loss: 0.4512 - accuracy: 0.7760 - val_loss: 1.1586 - val_accuracy: 0.4921 - 48ms/epoch - 24ms/step\n",
            "Epoch 530/600\n",
            "2/2 - 0s - loss: 0.4545 - accuracy: 0.7840 - val_loss: 1.1673 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 531/600\n",
            "2/2 - 0s - loss: 0.4658 - accuracy: 0.7800 - val_loss: 1.1709 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 532/600\n",
            "2/2 - 0s - loss: 0.4666 - accuracy: 0.7880 - val_loss: 1.1614 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 533/600\n",
            "2/2 - 0s - loss: 0.4606 - accuracy: 0.7800 - val_loss: 1.1579 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 534/600\n",
            "2/2 - 0s - loss: 0.4634 - accuracy: 0.7840 - val_loss: 1.1551 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 535/600\n",
            "2/2 - 0s - loss: 0.4287 - accuracy: 0.8200 - val_loss: 1.1560 - val_accuracy: 0.4921 - 39ms/epoch - 19ms/step\n",
            "Epoch 536/600\n",
            "2/2 - 0s - loss: 0.4424 - accuracy: 0.8040 - val_loss: 1.1526 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 537/600\n",
            "2/2 - 0s - loss: 0.4648 - accuracy: 0.7800 - val_loss: 1.1455 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 538/600\n",
            "2/2 - 0s - loss: 0.4851 - accuracy: 0.7560 - val_loss: 1.1431 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 539/600\n",
            "2/2 - 0s - loss: 0.4487 - accuracy: 0.8080 - val_loss: 1.1435 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 540/600\n",
            "2/2 - 0s - loss: 0.4858 - accuracy: 0.7680 - val_loss: 1.1501 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 541/600\n",
            "2/2 - 0s - loss: 0.4617 - accuracy: 0.7840 - val_loss: 1.1585 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 542/600\n",
            "2/2 - 0s - loss: 0.4664 - accuracy: 0.7880 - val_loss: 1.1643 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 543/600\n",
            "2/2 - 0s - loss: 0.4755 - accuracy: 0.7720 - val_loss: 1.1736 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 544/600\n",
            "2/2 - 0s - loss: 0.4785 - accuracy: 0.7600 - val_loss: 1.1797 - val_accuracy: 0.4762 - 31ms/epoch - 15ms/step\n",
            "Epoch 545/600\n",
            "2/2 - 0s - loss: 0.4730 - accuracy: 0.7360 - val_loss: 1.1846 - val_accuracy: 0.4603 - 37ms/epoch - 19ms/step\n",
            "Epoch 546/600\n",
            "2/2 - 0s - loss: 0.4568 - accuracy: 0.7640 - val_loss: 1.1834 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 547/600\n",
            "2/2 - 0s - loss: 0.4410 - accuracy: 0.7760 - val_loss: 1.1821 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 548/600\n",
            "2/2 - 0s - loss: 0.4521 - accuracy: 0.7640 - val_loss: 1.1838 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 549/600\n",
            "2/2 - 0s - loss: 0.4317 - accuracy: 0.8080 - val_loss: 1.1853 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 550/600\n",
            "2/2 - 0s - loss: 0.4541 - accuracy: 0.7880 - val_loss: 1.1848 - val_accuracy: 0.4921 - 40ms/epoch - 20ms/step\n",
            "Epoch 551/600\n",
            "2/2 - 0s - loss: 0.4582 - accuracy: 0.7840 - val_loss: 1.1825 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 552/600\n",
            "2/2 - 0s - loss: 0.4593 - accuracy: 0.7600 - val_loss: 1.1844 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 553/600\n",
            "2/2 - 0s - loss: 0.4637 - accuracy: 0.7520 - val_loss: 1.1910 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 554/600\n",
            "2/2 - 0s - loss: 0.4334 - accuracy: 0.7920 - val_loss: 1.1958 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 555/600\n",
            "2/2 - 0s - loss: 0.4596 - accuracy: 0.7680 - val_loss: 1.1985 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 556/600\n",
            "2/2 - 0s - loss: 0.4574 - accuracy: 0.7880 - val_loss: 1.1932 - val_accuracy: 0.4921 - 42ms/epoch - 21ms/step\n",
            "Epoch 557/600\n",
            "2/2 - 0s - loss: 0.4396 - accuracy: 0.8000 - val_loss: 1.1923 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 558/600\n",
            "2/2 - 0s - loss: 0.4616 - accuracy: 0.7960 - val_loss: 1.1839 - val_accuracy: 0.4762 - 57ms/epoch - 28ms/step\n",
            "Epoch 559/600\n",
            "2/2 - 0s - loss: 0.4653 - accuracy: 0.7520 - val_loss: 1.1828 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 560/600\n",
            "2/2 - 0s - loss: 0.4511 - accuracy: 0.8040 - val_loss: 1.1861 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 561/600\n",
            "2/2 - 0s - loss: 0.4950 - accuracy: 0.7560 - val_loss: 1.1832 - val_accuracy: 0.4921 - 40ms/epoch - 20ms/step\n",
            "Epoch 562/600\n",
            "2/2 - 0s - loss: 0.4763 - accuracy: 0.7440 - val_loss: 1.1892 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 563/600\n",
            "2/2 - 0s - loss: 0.4671 - accuracy: 0.7920 - val_loss: 1.2089 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 564/600\n",
            "2/2 - 0s - loss: 0.4792 - accuracy: 0.7640 - val_loss: 1.2213 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 565/600\n",
            "2/2 - 0s - loss: 0.4358 - accuracy: 0.8080 - val_loss: 1.2262 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 566/600\n",
            "2/2 - 0s - loss: 0.4458 - accuracy: 0.7840 - val_loss: 1.2186 - val_accuracy: 0.4762 - 41ms/epoch - 20ms/step\n",
            "Epoch 567/600\n",
            "2/2 - 0s - loss: 0.4497 - accuracy: 0.7840 - val_loss: 1.2098 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 568/600\n",
            "2/2 - 0s - loss: 0.4447 - accuracy: 0.7960 - val_loss: 1.2091 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 569/600\n",
            "2/2 - 0s - loss: 0.4615 - accuracy: 0.7680 - val_loss: 1.2076 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 570/600\n",
            "2/2 - 0s - loss: 0.4421 - accuracy: 0.7800 - val_loss: 1.2125 - val_accuracy: 0.4762 - 37ms/epoch - 19ms/step\n",
            "Epoch 571/600\n",
            "2/2 - 0s - loss: 0.4727 - accuracy: 0.7480 - val_loss: 1.2181 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 572/600\n",
            "2/2 - 0s - loss: 0.4258 - accuracy: 0.7880 - val_loss: 1.2267 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 573/600\n",
            "2/2 - 0s - loss: 0.4432 - accuracy: 0.7800 - val_loss: 1.2321 - val_accuracy: 0.4921 - 29ms/epoch - 15ms/step\n",
            "Epoch 574/600\n",
            "2/2 - 0s - loss: 0.4651 - accuracy: 0.7560 - val_loss: 1.2291 - val_accuracy: 0.4762 - 31ms/epoch - 15ms/step\n",
            "Epoch 575/600\n",
            "2/2 - 0s - loss: 0.4145 - accuracy: 0.8080 - val_loss: 1.2316 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 576/600\n",
            "2/2 - 0s - loss: 0.4636 - accuracy: 0.7720 - val_loss: 1.2328 - val_accuracy: 0.4762 - 28ms/epoch - 14ms/step\n",
            "Epoch 577/600\n",
            "2/2 - 0s - loss: 0.4465 - accuracy: 0.7960 - val_loss: 1.2354 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 578/600\n",
            "2/2 - 0s - loss: 0.4982 - accuracy: 0.7320 - val_loss: 1.2433 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 579/600\n",
            "2/2 - 0s - loss: 0.4586 - accuracy: 0.7680 - val_loss: 1.2486 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 580/600\n",
            "2/2 - 0s - loss: 0.4121 - accuracy: 0.8120 - val_loss: 1.2549 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 581/600\n",
            "2/2 - 0s - loss: 0.4493 - accuracy: 0.7920 - val_loss: 1.2551 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 582/600\n",
            "2/2 - 0s - loss: 0.4665 - accuracy: 0.7880 - val_loss: 1.2602 - val_accuracy: 0.4921 - 41ms/epoch - 20ms/step\n",
            "Epoch 583/600\n",
            "2/2 - 0s - loss: 0.4474 - accuracy: 0.7800 - val_loss: 1.2690 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 584/600\n",
            "2/2 - 0s - loss: 0.4290 - accuracy: 0.7880 - val_loss: 1.2720 - val_accuracy: 0.5079 - 41ms/epoch - 20ms/step\n",
            "Epoch 585/600\n",
            "2/2 - 0s - loss: 0.4608 - accuracy: 0.7800 - val_loss: 1.2656 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 586/600\n",
            "2/2 - 0s - loss: 0.4482 - accuracy: 0.7800 - val_loss: 1.2596 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 587/600\n",
            "2/2 - 0s - loss: 0.4696 - accuracy: 0.7640 - val_loss: 1.2464 - val_accuracy: 0.4762 - 33ms/epoch - 17ms/step\n",
            "Epoch 588/600\n",
            "2/2 - 0s - loss: 0.4237 - accuracy: 0.8120 - val_loss: 1.2290 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 589/600\n",
            "2/2 - 0s - loss: 0.4447 - accuracy: 0.7920 - val_loss: 1.2212 - val_accuracy: 0.4921 - 44ms/epoch - 22ms/step\n",
            "Epoch 590/600\n",
            "2/2 - 0s - loss: 0.4004 - accuracy: 0.8280 - val_loss: 1.2174 - val_accuracy: 0.4921 - 41ms/epoch - 20ms/step\n",
            "Epoch 591/600\n",
            "2/2 - 0s - loss: 0.4386 - accuracy: 0.7880 - val_loss: 1.2244 - val_accuracy: 0.4762 - 36ms/epoch - 18ms/step\n",
            "Epoch 592/600\n",
            "2/2 - 0s - loss: 0.4387 - accuracy: 0.7840 - val_loss: 1.2372 - val_accuracy: 0.4762 - 38ms/epoch - 19ms/step\n",
            "Epoch 593/600\n",
            "2/2 - 0s - loss: 0.4786 - accuracy: 0.7520 - val_loss: 1.2431 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 594/600\n",
            "2/2 - 0s - loss: 0.4456 - accuracy: 0.7840 - val_loss: 1.2484 - val_accuracy: 0.4762 - 38ms/epoch - 19ms/step\n",
            "Epoch 595/600\n",
            "2/2 - 0s - loss: 0.4697 - accuracy: 0.7680 - val_loss: 1.2496 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 596/600\n",
            "2/2 - 0s - loss: 0.4421 - accuracy: 0.7800 - val_loss: 1.2429 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 597/600\n",
            "2/2 - 0s - loss: 0.4399 - accuracy: 0.7920 - val_loss: 1.2484 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 598/600\n",
            "2/2 - 0s - loss: 0.4441 - accuracy: 0.7720 - val_loss: 1.2516 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 599/600\n",
            "2/2 - 0s - loss: 0.4585 - accuracy: 0.7840 - val_loss: 1.2529 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 600/600\n",
            "2/2 - 0s - loss: 0.4253 - accuracy: 0.8280 - val_loss: 1.2614 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc980ae5550>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#myPredict = model.predict_classes( X_test).astype('int64')\n",
        "myPredict=model.predict(X_test).astype('int64') \n",
        "classes_x=np.argmax(myPredict,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFteMboknXEI",
        "outputId": "902c15aa-af16-4c36-8b7f-b4ac5d65a0c6"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnctAHNo510",
        "outputId": "c9e2aa7c-74d8-4b11-d2e1-80d62ff207d8"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0064 - accuracy: 0.5696\n",
            "score [1.0063692331314087, 0.5696202516555786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(y_test.nonzero()[1:])\n",
        "print(myPredict,'\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-dU9M6LpNqb",
        "outputId": "5eeee359-a354-4958-d27c-c9bb62afef95"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]] \n",
            " [[1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0\n",
            "  1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 1 0\n",
            "  1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    }
  ]
}