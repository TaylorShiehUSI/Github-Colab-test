{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220814 2230.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR4Q+Vgw3JGJ1q3pLJUqeR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaylorShiehUSI/Github-Colab-test/blob/main/20220814_2230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k8nXyuRd_S",
        "outputId": "ddb6d75c-5b76-4ea9-c75f-4cd333f20cac"
      },
      "execution_count": 48,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cviUbaTWRSko"
      },
      "outputs": [],
      "source": [
        "# 下載資料套件\n",
        "import requests as r\n",
        "\n",
        "# 資料處理套件\n",
        "from lxml import etree\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "# 財經套件\n",
        "# import yfinance as yf\n",
        "\n",
        "# 畫圖套件\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tw_stock_data(start_year, start_month, end_year, end_month, stock_code):\n",
        "    start_date = str(date(start_year, start_month, 1))\n",
        "    end_date = str(date(end_year, end_month, 1))\n",
        "    month_list = pd.date_range(start_date, end_date, freq='MS').strftime(\"%Y%m%d\").tolist()\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    for month in month_list:\n",
        "        url = \"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"+ month + \"&stockNo=\" + str(stock_code)\n",
        "        res = r.get(url)\n",
        "        stock_json = res.json()\n",
        "        stock_df = pd.DataFrame.from_dict(stock_json['data'])\n",
        "        df = df.append(stock_df, ignore_index = True)\n",
        "        \n",
        "    # 資料轉型\n",
        "    for col in [0, 1, 2, 3, 4, 5, 6, 8]:\n",
        "        for row in range(df.shape[0]):\n",
        "            # 把\"日期\"從字串(string)換成時間(datetime)，並將民國年換成西元年\n",
        "            if col == 0:\n",
        "                day = df.iloc[row,0].split('/')\n",
        "                df.iloc[row, 0] = datetime(int(day[0]) + 1911, int(day[1]), int(day[2]))  \n",
        "            # 把\"開盤價\", \"最高價\", \"最低價\", \"收盤價\"帶有逗號的字串(string)換成浮點數(float) \n",
        "            elif col != 0:\n",
        "                df.iloc[row, col] = float(df.iloc[row,col].replace(',', ''))\n",
        "    \n",
        "    df.columns = ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數']\n",
        "    return df"
      ],
      "metadata": {
        "id": "6IuqlNYjRvxb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df = get_tw_stock_data(start_year = 2021, \n",
        "                start_month = 1, \n",
        "                end_year = 2022, \n",
        "                end_month = 8, \n",
        "                stock_code = 2330)\n",
        "stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tjxBWizKRyTK",
        "outputId": "114a7a7e-f50d-478a-949d-a2fe9a41b7a9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      日期        成交股數           成交金額    開盤價    最高價    最低價  \\\n",
              "0    2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0   \n",
              "1    2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0   \n",
              "2    2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0   \n",
              "3    2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0   \n",
              "4    2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0   \n",
              "..                   ...         ...            ...    ...    ...    ...   \n",
              "387  2022-08-08 00:00:00  20568971.0  10531710250.0  510.0  515.0  509.0   \n",
              "388  2022-08-09 00:00:00  24370709.0  12372442661.0  507.0  511.0  504.0   \n",
              "389  2022-08-10 00:00:00  22112239.0  11075581424.0  500.0  503.0  499.5   \n",
              "390  2022-08-11 00:00:00  24906177.0  12771121611.0  513.0  514.0  510.0   \n",
              "391  2022-08-12 00:00:00  21343450.0  11016097043.0  515.0  518.0  514.0   \n",
              "\n",
              "       收盤價    漲跌價差     成交筆數  \n",
              "0    536.0   +6.00  33316.0  \n",
              "1    542.0   +6.00  28512.0  \n",
              "2    549.0   +7.00  55462.0  \n",
              "3    565.0  +16.00  47905.0  \n",
              "4    580.0  +15.00  56426.0  \n",
              "..     ...     ...      ...  \n",
              "387  512.0   -4.00  18131.0  \n",
              "388  510.0   -2.00  25433.0  \n",
              "389  500.0  -10.00  35188.0  \n",
              "390  514.0  +14.00  23949.0  \n",
              "391  517.0   +3.00  21701.0  \n",
              "\n",
              "[392 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bb2a1a5-a28b-4603-8317-30e146522271\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>2022-08-08 00:00:00</td>\n",
              "      <td>20568971.0</td>\n",
              "      <td>10531710250.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>509.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>-4.00</td>\n",
              "      <td>18131.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>2022-08-09 00:00:00</td>\n",
              "      <td>24370709.0</td>\n",
              "      <td>12372442661.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>-2.00</td>\n",
              "      <td>25433.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>2022-08-10 00:00:00</td>\n",
              "      <td>22112239.0</td>\n",
              "      <td>11075581424.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>503.0</td>\n",
              "      <td>499.5</td>\n",
              "      <td>500.0</td>\n",
              "      <td>-10.00</td>\n",
              "      <td>35188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>2022-08-11 00:00:00</td>\n",
              "      <td>24906177.0</td>\n",
              "      <td>12771121611.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>+14.00</td>\n",
              "      <td>23949.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>2022-08-12 00:00:00</td>\n",
              "      <td>21343450.0</td>\n",
              "      <td>11016097043.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>518.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>+3.00</td>\n",
              "      <td>21701.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bb2a1a5-a28b-4603-8317-30e146522271')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bb2a1a5-a28b-4603-8317-30e146522271 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bb2a1a5-a28b-4603-8317-30e146522271');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.to_csv('2230.csv',encoding='utf-8_sig')"
      ],
      "metadata": {
        "id": "aa45vys1Vefv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Processing // Add is_up\n",
        "import numpy as np\n",
        "\n",
        "stock_df['is_up'] = (stock_df['開盤價'].shift(-1) - stock_df['收盤價'] >0).astype('int')\n",
        "stock_df['開收價差'] = (stock_df['收盤價'])-(stock_df['開盤價']).astype('int')\n",
        "stock_df['高低價差'] = (stock_df['最高價'])-(stock_df['最低價']).astype('int')\n",
        "stock_df['每筆股數'] = ((stock_df['成交股數'])/(stock_df['成交筆數']).astype('int'))\n",
        "def one_hot(targets, nb_classes):\n",
        "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "y_data = one_hot(stock_df['is_up'], 2)\n",
        "stock_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s28R2AUsYOgW",
        "outputId": "d28e100e-7a94-45cb-8abf-2c5f16d59c15"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    日期        成交股數           成交金額    開盤價    最高價    最低價    收盤價  \\\n",
              "0  2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0  536.0   \n",
              "1  2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0  542.0   \n",
              "2  2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0  549.0   \n",
              "3  2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0  565.0   \n",
              "4  2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0  580.0   \n",
              "\n",
              "     漲跌價差     成交筆數  is_up  開收價差  高低價差         每筆股數  \n",
              "0   +6.00  33316.0      0   6.0  12.0  1185.315134  \n",
              "1   +6.00  28512.0      1   6.0   7.0  1221.920279  \n",
              "2   +7.00  55462.0      1  -6.0  14.0   1002.74844  \n",
              "3  +16.00  47905.0      1  11.0  17.0   1114.55512  \n",
              "4  +15.00  56426.0      0   0.0   9.0  1115.747138  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-422cd558-5726-4211-acd2-597266f9024d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>is_up</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1185.315134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1221.920279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1002.74844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1114.55512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1115.747138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-422cd558-5726-4211-acd2-597266f9024d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-422cd558-5726-4211-acd2-597266f9024d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-422cd558-5726-4211-acd2-597266f9024d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare Feature Data\n",
        "X_data = stock_df.drop(['成交股數','日期','開盤價','收盤價','最高價','最低價','is_up','漲跌價差','成交筆數'], axis=1)\n",
        "X_data.head()\n",
        "#X_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U6L5IslyY-A0",
        "outputId": "c8e5402a-fb3b-4c08-e17e-17d3d94696c4"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            成交金額  開收價差  高低價差         每筆股數\n",
              "0  21127581248.0   6.0  12.0  1185.315134\n",
              "1  18761831567.0   6.0   7.0  1221.920279\n",
              "2  30572783229.0  -6.0  14.0   1002.74844\n",
              "3  30018630685.0  11.0  17.0   1114.55512\n",
              "4  36339702855.0   0.0   9.0  1115.747138"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea32ec31-aa15-40c9-b423-7e80b5c45beb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1185.315134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1221.920279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1002.74844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1114.55512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1115.747138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea32ec31-aa15-40c9-b423-7e80b5c45beb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea32ec31-aa15-40c9-b423-7e80b5c45beb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea32ec31-aa15-40c9-b423-7e80b5c45beb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalized\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "scaled = scaler.fit_transform(X_data)\n",
        "X_data = pd.DataFrame(scaled, columns=X_data.columns)\n",
        "#print(X_data)\n",
        "X_data.head()"
      ],
      "metadata": {
        "id": "WeNiJCBNQ3x9",
        "outputId": "2a0276e9-b947-4725-be62-eb078c60b430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       成交金額      開收價差      高低價差      每筆股數\n",
              "0 -0.079254  1.008965  0.602092  0.738068\n",
              "1 -0.255043  1.008965 -0.397146  0.842745\n",
              "2  0.622583 -0.899811  1.001788  0.215994\n",
              "3  0.581406  1.804289  1.601331  0.535720\n",
              "4  1.051100  0.054577  0.002549  0.539129"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21dc8e1d-510c-4fb6-9f79-f89ab9ec4cef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開收價差</th>\n",
              "      <th>高低價差</th>\n",
              "      <th>每筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.079254</td>\n",
              "      <td>1.008965</td>\n",
              "      <td>0.602092</td>\n",
              "      <td>0.738068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.255043</td>\n",
              "      <td>1.008965</td>\n",
              "      <td>-0.397146</td>\n",
              "      <td>0.842745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.622583</td>\n",
              "      <td>-0.899811</td>\n",
              "      <td>1.001788</td>\n",
              "      <td>0.215994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.581406</td>\n",
              "      <td>1.804289</td>\n",
              "      <td>1.601331</td>\n",
              "      <td>0.535720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.051100</td>\n",
              "      <td>0.054577</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.539129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21dc8e1d-510c-4fb6-9f79-f89ab9ec4cef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21dc8e1d-510c-4fb6-9f79-f89ab9ec4cef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21dc8e1d-510c-4fb6-9f79-f89ab9ec4cef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model, with preparing the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "X_train = K.cast_to_floatx(X_train)\n",
        "y_train = K.cast_to_floatx(y_train)\n",
        "X_test = K.cast_to_floatx(X_test)\n",
        "y_test = K.cast_to_floatx(y_test)"
      ],
      "metadata": {
        "id": "dSxbm6ltjPHa"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot( stock_df['收盤價'], '--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2M7fNrNijimi",
        "outputId": "8f481229-538b-4574-ed3d-0a5a724a8f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ],
      "metadata": {
        "id": "G_DulbtRjrdy"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set up model, and print the model summary\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 256,\n",
        "                input_shape=X_train.shape[1:],\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 16,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dense(units = 2,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f98ijyGEjunx",
        "outputId": "9c49770d-898a-4dd1-b7b3-04eba9818c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_39 (Dense)            (None, 256)               1280      \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 16)                4112      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,426\n",
            "Trainable params: 5,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "model.fit(x = X_train,\n",
        "          y = y_train,\n",
        "          validation_split = 0.2,\n",
        "          batch_size=256,\n",
        "          epochs=500,\n",
        "          verbose = 2) "
      ],
      "metadata": {
        "id": "Kd8QlzjZkAG4",
        "outputId": "fc811e41-f1f4-4baf-d24b-b0a31c85dd97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 - 1s - loss: 0.6926 - accuracy: 0.5160 - val_loss: 0.6939 - val_accuracy: 0.4762 - 614ms/epoch - 614ms/step\n",
            "Epoch 2/500\n",
            "1/1 - 0s - loss: 0.6926 - accuracy: 0.5120 - val_loss: 0.6940 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 3/500\n",
            "1/1 - 0s - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6941 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 4/500\n",
            "1/1 - 0s - loss: 0.6919 - accuracy: 0.5080 - val_loss: 0.6942 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 5/500\n",
            "1/1 - 0s - loss: 0.6917 - accuracy: 0.5080 - val_loss: 0.6944 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 6/500\n",
            "1/1 - 0s - loss: 0.6918 - accuracy: 0.5080 - val_loss: 0.6944 - val_accuracy: 0.4762 - 40ms/epoch - 40ms/step\n",
            "Epoch 7/500\n",
            "1/1 - 0s - loss: 0.6912 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 8/500\n",
            "1/1 - 0s - loss: 0.6907 - accuracy: 0.5080 - val_loss: 0.6946 - val_accuracy: 0.4762 - 37ms/epoch - 37ms/step\n",
            "Epoch 9/500\n",
            "1/1 - 0s - loss: 0.6907 - accuracy: 0.5080 - val_loss: 0.6947 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 10/500\n",
            "1/1 - 0s - loss: 0.6904 - accuracy: 0.5120 - val_loss: 0.6948 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 11/500\n",
            "1/1 - 0s - loss: 0.6896 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.5079 - 28ms/epoch - 28ms/step\n",
            "Epoch 12/500\n",
            "1/1 - 0s - loss: 0.6893 - accuracy: 0.5120 - val_loss: 0.6949 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 13/500\n",
            "1/1 - 0s - loss: 0.6894 - accuracy: 0.5120 - val_loss: 0.6950 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 14/500\n",
            "1/1 - 0s - loss: 0.6889 - accuracy: 0.5040 - val_loss: 0.6951 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 15/500\n",
            "1/1 - 0s - loss: 0.6883 - accuracy: 0.5200 - val_loss: 0.6952 - val_accuracy: 0.5238 - 28ms/epoch - 28ms/step\n",
            "Epoch 16/500\n",
            "1/1 - 0s - loss: 0.6881 - accuracy: 0.5200 - val_loss: 0.6953 - val_accuracy: 0.5556 - 29ms/epoch - 29ms/step\n",
            "Epoch 17/500\n",
            "1/1 - 0s - loss: 0.6876 - accuracy: 0.5120 - val_loss: 0.6955 - val_accuracy: 0.6032 - 37ms/epoch - 37ms/step\n",
            "Epoch 18/500\n",
            "1/1 - 0s - loss: 0.6874 - accuracy: 0.5440 - val_loss: 0.6957 - val_accuracy: 0.6032 - 28ms/epoch - 28ms/step\n",
            "Epoch 19/500\n",
            "1/1 - 0s - loss: 0.6869 - accuracy: 0.5320 - val_loss: 0.6960 - val_accuracy: 0.6032 - 34ms/epoch - 34ms/step\n",
            "Epoch 20/500\n",
            "1/1 - 0s - loss: 0.6856 - accuracy: 0.5560 - val_loss: 0.6963 - val_accuracy: 0.5873 - 27ms/epoch - 27ms/step\n",
            "Epoch 21/500\n",
            "1/1 - 0s - loss: 0.6855 - accuracy: 0.5520 - val_loss: 0.6967 - val_accuracy: 0.6032 - 35ms/epoch - 35ms/step\n",
            "Epoch 22/500\n",
            "1/1 - 0s - loss: 0.6851 - accuracy: 0.5560 - val_loss: 0.6971 - val_accuracy: 0.6190 - 28ms/epoch - 28ms/step\n",
            "Epoch 23/500\n",
            "1/1 - 0s - loss: 0.6839 - accuracy: 0.5840 - val_loss: 0.6975 - val_accuracy: 0.6190 - 31ms/epoch - 31ms/step\n",
            "Epoch 24/500\n",
            "1/1 - 0s - loss: 0.6853 - accuracy: 0.5520 - val_loss: 0.6980 - val_accuracy: 0.6190 - 31ms/epoch - 31ms/step\n",
            "Epoch 25/500\n",
            "1/1 - 0s - loss: 0.6849 - accuracy: 0.5640 - val_loss: 0.6985 - val_accuracy: 0.6190 - 32ms/epoch - 32ms/step\n",
            "Epoch 26/500\n",
            "1/1 - 0s - loss: 0.6838 - accuracy: 0.5800 - val_loss: 0.6990 - val_accuracy: 0.5873 - 34ms/epoch - 34ms/step\n",
            "Epoch 27/500\n",
            "1/1 - 0s - loss: 0.6824 - accuracy: 0.5720 - val_loss: 0.6996 - val_accuracy: 0.5873 - 32ms/epoch - 32ms/step\n",
            "Epoch 28/500\n",
            "1/1 - 0s - loss: 0.6821 - accuracy: 0.5680 - val_loss: 0.7003 - val_accuracy: 0.5873 - 28ms/epoch - 28ms/step\n",
            "Epoch 29/500\n",
            "1/1 - 0s - loss: 0.6813 - accuracy: 0.5720 - val_loss: 0.7009 - val_accuracy: 0.6032 - 31ms/epoch - 31ms/step\n",
            "Epoch 30/500\n",
            "1/1 - 0s - loss: 0.6818 - accuracy: 0.5840 - val_loss: 0.7016 - val_accuracy: 0.6032 - 32ms/epoch - 32ms/step\n",
            "Epoch 31/500\n",
            "1/1 - 0s - loss: 0.6812 - accuracy: 0.5880 - val_loss: 0.7024 - val_accuracy: 0.6032 - 28ms/epoch - 28ms/step\n",
            "Epoch 32/500\n",
            "1/1 - 0s - loss: 0.6790 - accuracy: 0.6000 - val_loss: 0.7032 - val_accuracy: 0.6032 - 40ms/epoch - 40ms/step\n",
            "Epoch 33/500\n",
            "1/1 - 0s - loss: 0.6789 - accuracy: 0.5880 - val_loss: 0.7042 - val_accuracy: 0.6032 - 37ms/epoch - 37ms/step\n",
            "Epoch 34/500\n",
            "1/1 - 0s - loss: 0.6772 - accuracy: 0.5920 - val_loss: 0.7052 - val_accuracy: 0.6032 - 34ms/epoch - 34ms/step\n",
            "Epoch 35/500\n",
            "1/1 - 0s - loss: 0.6776 - accuracy: 0.5920 - val_loss: 0.7063 - val_accuracy: 0.6032 - 28ms/epoch - 28ms/step\n",
            "Epoch 36/500\n",
            "1/1 - 0s - loss: 0.6768 - accuracy: 0.5720 - val_loss: 0.7074 - val_accuracy: 0.5714 - 28ms/epoch - 28ms/step\n",
            "Epoch 37/500\n",
            "1/1 - 0s - loss: 0.6752 - accuracy: 0.6000 - val_loss: 0.7086 - val_accuracy: 0.5714 - 28ms/epoch - 28ms/step\n",
            "Epoch 38/500\n",
            "1/1 - 0s - loss: 0.6761 - accuracy: 0.5880 - val_loss: 0.7098 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 39/500\n",
            "1/1 - 0s - loss: 0.6738 - accuracy: 0.5920 - val_loss: 0.7111 - val_accuracy: 0.5556 - 27ms/epoch - 27ms/step\n",
            "Epoch 40/500\n",
            "1/1 - 0s - loss: 0.6744 - accuracy: 0.5880 - val_loss: 0.7124 - val_accuracy: 0.5556 - 48ms/epoch - 48ms/step\n",
            "Epoch 41/500\n",
            "1/1 - 0s - loss: 0.6741 - accuracy: 0.5800 - val_loss: 0.7136 - val_accuracy: 0.5556 - 28ms/epoch - 28ms/step\n",
            "Epoch 42/500\n",
            "1/1 - 0s - loss: 0.6746 - accuracy: 0.5920 - val_loss: 0.7149 - val_accuracy: 0.5556 - 28ms/epoch - 28ms/step\n",
            "Epoch 43/500\n",
            "1/1 - 0s - loss: 0.6717 - accuracy: 0.5920 - val_loss: 0.7162 - val_accuracy: 0.5556 - 30ms/epoch - 30ms/step\n",
            "Epoch 44/500\n",
            "1/1 - 0s - loss: 0.6701 - accuracy: 0.5840 - val_loss: 0.7174 - val_accuracy: 0.5556 - 27ms/epoch - 27ms/step\n",
            "Epoch 45/500\n",
            "1/1 - 0s - loss: 0.6700 - accuracy: 0.5920 - val_loss: 0.7187 - val_accuracy: 0.5556 - 37ms/epoch - 37ms/step\n",
            "Epoch 46/500\n",
            "1/1 - 0s - loss: 0.6702 - accuracy: 0.5840 - val_loss: 0.7200 - val_accuracy: 0.5556 - 28ms/epoch - 28ms/step\n",
            "Epoch 47/500\n",
            "1/1 - 0s - loss: 0.6670 - accuracy: 0.5960 - val_loss: 0.7212 - val_accuracy: 0.5556 - 34ms/epoch - 34ms/step\n",
            "Epoch 48/500\n",
            "1/1 - 0s - loss: 0.6676 - accuracy: 0.5960 - val_loss: 0.7223 - val_accuracy: 0.5556 - 29ms/epoch - 29ms/step\n",
            "Epoch 49/500\n",
            "1/1 - 0s - loss: 0.6676 - accuracy: 0.6040 - val_loss: 0.7234 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 50/500\n",
            "1/1 - 0s - loss: 0.6663 - accuracy: 0.5880 - val_loss: 0.7244 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 51/500\n",
            "1/1 - 0s - loss: 0.6679 - accuracy: 0.5880 - val_loss: 0.7255 - val_accuracy: 0.5873 - 34ms/epoch - 34ms/step\n",
            "Epoch 52/500\n",
            "1/1 - 0s - loss: 0.6660 - accuracy: 0.6080 - val_loss: 0.7264 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 53/500\n",
            "1/1 - 0s - loss: 0.6634 - accuracy: 0.5960 - val_loss: 0.7274 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 54/500\n",
            "1/1 - 0s - loss: 0.6639 - accuracy: 0.5800 - val_loss: 0.7283 - val_accuracy: 0.5873 - 29ms/epoch - 29ms/step\n",
            "Epoch 55/500\n",
            "1/1 - 0s - loss: 0.6652 - accuracy: 0.5920 - val_loss: 0.7293 - val_accuracy: 0.5714 - 27ms/epoch - 27ms/step\n",
            "Epoch 56/500\n",
            "1/1 - 0s - loss: 0.6622 - accuracy: 0.5720 - val_loss: 0.7302 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 57/500\n",
            "1/1 - 0s - loss: 0.6620 - accuracy: 0.6080 - val_loss: 0.7313 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 58/500\n",
            "1/1 - 0s - loss: 0.6612 - accuracy: 0.5880 - val_loss: 0.7323 - val_accuracy: 0.5714 - 39ms/epoch - 39ms/step\n",
            "Epoch 59/500\n",
            "1/1 - 0s - loss: 0.6600 - accuracy: 0.5880 - val_loss: 0.7334 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 60/500\n",
            "1/1 - 0s - loss: 0.6579 - accuracy: 0.6200 - val_loss: 0.7346 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 61/500\n",
            "1/1 - 0s - loss: 0.6577 - accuracy: 0.5960 - val_loss: 0.7358 - val_accuracy: 0.5873 - 35ms/epoch - 35ms/step\n",
            "Epoch 62/500\n",
            "1/1 - 0s - loss: 0.6589 - accuracy: 0.5760 - val_loss: 0.7370 - val_accuracy: 0.5873 - 33ms/epoch - 33ms/step\n",
            "Epoch 63/500\n",
            "1/1 - 0s - loss: 0.6618 - accuracy: 0.6000 - val_loss: 0.7383 - val_accuracy: 0.5873 - 32ms/epoch - 32ms/step\n",
            "Epoch 64/500\n",
            "1/1 - 0s - loss: 0.6589 - accuracy: 0.5960 - val_loss: 0.7396 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 65/500\n",
            "1/1 - 0s - loss: 0.6565 - accuracy: 0.5960 - val_loss: 0.7407 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 66/500\n",
            "1/1 - 0s - loss: 0.6570 - accuracy: 0.5920 - val_loss: 0.7420 - val_accuracy: 0.5556 - 32ms/epoch - 32ms/step\n",
            "Epoch 67/500\n",
            "1/1 - 0s - loss: 0.6572 - accuracy: 0.6080 - val_loss: 0.7433 - val_accuracy: 0.5397 - 28ms/epoch - 28ms/step\n",
            "Epoch 68/500\n",
            "1/1 - 0s - loss: 0.6560 - accuracy: 0.5880 - val_loss: 0.7447 - val_accuracy: 0.5397 - 50ms/epoch - 50ms/step\n",
            "Epoch 69/500\n",
            "1/1 - 0s - loss: 0.6521 - accuracy: 0.5920 - val_loss: 0.7462 - val_accuracy: 0.5397 - 38ms/epoch - 38ms/step\n",
            "Epoch 70/500\n",
            "1/1 - 0s - loss: 0.6563 - accuracy: 0.5840 - val_loss: 0.7477 - val_accuracy: 0.5556 - 30ms/epoch - 30ms/step\n",
            "Epoch 71/500\n",
            "1/1 - 0s - loss: 0.6542 - accuracy: 0.5840 - val_loss: 0.7491 - val_accuracy: 0.5556 - 27ms/epoch - 27ms/step\n",
            "Epoch 72/500\n",
            "1/1 - 0s - loss: 0.6538 - accuracy: 0.5960 - val_loss: 0.7504 - val_accuracy: 0.5556 - 33ms/epoch - 33ms/step\n",
            "Epoch 73/500\n",
            "1/1 - 0s - loss: 0.6517 - accuracy: 0.5920 - val_loss: 0.7518 - val_accuracy: 0.5556 - 29ms/epoch - 29ms/step\n",
            "Epoch 74/500\n",
            "1/1 - 0s - loss: 0.6534 - accuracy: 0.5960 - val_loss: 0.7531 - val_accuracy: 0.5556 - 27ms/epoch - 27ms/step\n",
            "Epoch 75/500\n",
            "1/1 - 0s - loss: 0.6559 - accuracy: 0.5840 - val_loss: 0.7543 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 76/500\n",
            "1/1 - 0s - loss: 0.6505 - accuracy: 0.6120 - val_loss: 0.7555 - val_accuracy: 0.5714 - 27ms/epoch - 27ms/step\n",
            "Epoch 77/500\n",
            "1/1 - 0s - loss: 0.6506 - accuracy: 0.6000 - val_loss: 0.7567 - val_accuracy: 0.5397 - 30ms/epoch - 30ms/step\n",
            "Epoch 78/500\n",
            "1/1 - 0s - loss: 0.6520 - accuracy: 0.5840 - val_loss: 0.7579 - val_accuracy: 0.5556 - 36ms/epoch - 36ms/step\n",
            "Epoch 79/500\n",
            "1/1 - 0s - loss: 0.6485 - accuracy: 0.6200 - val_loss: 0.7592 - val_accuracy: 0.5556 - 29ms/epoch - 29ms/step\n",
            "Epoch 80/500\n",
            "1/1 - 0s - loss: 0.6473 - accuracy: 0.6080 - val_loss: 0.7605 - val_accuracy: 0.5397 - 27ms/epoch - 27ms/step\n",
            "Epoch 81/500\n",
            "1/1 - 0s - loss: 0.6506 - accuracy: 0.6200 - val_loss: 0.7618 - val_accuracy: 0.5238 - 26ms/epoch - 26ms/step\n",
            "Epoch 82/500\n",
            "1/1 - 0s - loss: 0.6434 - accuracy: 0.6200 - val_loss: 0.7634 - val_accuracy: 0.5238 - 29ms/epoch - 29ms/step\n",
            "Epoch 83/500\n",
            "1/1 - 0s - loss: 0.6487 - accuracy: 0.6160 - val_loss: 0.7650 - val_accuracy: 0.5397 - 28ms/epoch - 28ms/step\n",
            "Epoch 84/500\n",
            "1/1 - 0s - loss: 0.6463 - accuracy: 0.6080 - val_loss: 0.7664 - val_accuracy: 0.5397 - 29ms/epoch - 29ms/step\n",
            "Epoch 85/500\n",
            "1/1 - 0s - loss: 0.6481 - accuracy: 0.5880 - val_loss: 0.7676 - val_accuracy: 0.5397 - 28ms/epoch - 28ms/step\n",
            "Epoch 86/500\n",
            "1/1 - 0s - loss: 0.6464 - accuracy: 0.6360 - val_loss: 0.7687 - val_accuracy: 0.5397 - 36ms/epoch - 36ms/step\n",
            "Epoch 87/500\n",
            "1/1 - 0s - loss: 0.6492 - accuracy: 0.6000 - val_loss: 0.7698 - val_accuracy: 0.5238 - 29ms/epoch - 29ms/step\n",
            "Epoch 88/500\n",
            "1/1 - 0s - loss: 0.6461 - accuracy: 0.6360 - val_loss: 0.7707 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 89/500\n",
            "1/1 - 0s - loss: 0.6446 - accuracy: 0.6200 - val_loss: 0.7715 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 90/500\n",
            "1/1 - 0s - loss: 0.6425 - accuracy: 0.6240 - val_loss: 0.7723 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 91/500\n",
            "1/1 - 0s - loss: 0.6441 - accuracy: 0.6280 - val_loss: 0.7730 - val_accuracy: 0.4921 - 36ms/epoch - 36ms/step\n",
            "Epoch 92/500\n",
            "1/1 - 0s - loss: 0.6470 - accuracy: 0.6040 - val_loss: 0.7736 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 93/500\n",
            "1/1 - 0s - loss: 0.6400 - accuracy: 0.6160 - val_loss: 0.7742 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 94/500\n",
            "1/1 - 0s - loss: 0.6404 - accuracy: 0.6120 - val_loss: 0.7750 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 95/500\n",
            "1/1 - 0s - loss: 0.6386 - accuracy: 0.6400 - val_loss: 0.7762 - val_accuracy: 0.5079 - 31ms/epoch - 31ms/step\n",
            "Epoch 96/500\n",
            "1/1 - 0s - loss: 0.6445 - accuracy: 0.6160 - val_loss: 0.7777 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 97/500\n",
            "1/1 - 0s - loss: 0.6392 - accuracy: 0.6280 - val_loss: 0.7794 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 98/500\n",
            "1/1 - 0s - loss: 0.6397 - accuracy: 0.6360 - val_loss: 0.7812 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 99/500\n",
            "1/1 - 0s - loss: 0.6365 - accuracy: 0.6600 - val_loss: 0.7829 - val_accuracy: 0.5079 - 29ms/epoch - 29ms/step\n",
            "Epoch 100/500\n",
            "1/1 - 0s - loss: 0.6469 - accuracy: 0.6360 - val_loss: 0.7846 - val_accuracy: 0.5079 - 26ms/epoch - 26ms/step\n",
            "Epoch 101/500\n",
            "1/1 - 0s - loss: 0.6413 - accuracy: 0.6280 - val_loss: 0.7863 - val_accuracy: 0.5079 - 31ms/epoch - 31ms/step\n",
            "Epoch 102/500\n",
            "1/1 - 0s - loss: 0.6390 - accuracy: 0.6360 - val_loss: 0.7880 - val_accuracy: 0.5079 - 31ms/epoch - 31ms/step\n",
            "Epoch 103/500\n",
            "1/1 - 0s - loss: 0.6393 - accuracy: 0.6360 - val_loss: 0.7896 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 104/500\n",
            "1/1 - 0s - loss: 0.6379 - accuracy: 0.6160 - val_loss: 0.7911 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 105/500\n",
            "1/1 - 0s - loss: 0.6345 - accuracy: 0.6520 - val_loss: 0.7924 - val_accuracy: 0.5079 - 37ms/epoch - 37ms/step\n",
            "Epoch 106/500\n",
            "1/1 - 0s - loss: 0.6351 - accuracy: 0.6440 - val_loss: 0.7935 - val_accuracy: 0.5079 - 28ms/epoch - 28ms/step\n",
            "Epoch 107/500\n",
            "1/1 - 0s - loss: 0.6398 - accuracy: 0.6360 - val_loss: 0.7943 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 108/500\n",
            "1/1 - 0s - loss: 0.6387 - accuracy: 0.6240 - val_loss: 0.7947 - val_accuracy: 0.5079 - 27ms/epoch - 27ms/step\n",
            "Epoch 109/500\n",
            "1/1 - 0s - loss: 0.6400 - accuracy: 0.6360 - val_loss: 0.7948 - val_accuracy: 0.5079 - 32ms/epoch - 32ms/step\n",
            "Epoch 110/500\n",
            "1/1 - 0s - loss: 0.6361 - accuracy: 0.6480 - val_loss: 0.7946 - val_accuracy: 0.5079 - 29ms/epoch - 29ms/step\n",
            "Epoch 111/500\n",
            "1/1 - 0s - loss: 0.6373 - accuracy: 0.6680 - val_loss: 0.7944 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 112/500\n",
            "1/1 - 0s - loss: 0.6316 - accuracy: 0.6520 - val_loss: 0.7942 - val_accuracy: 0.5079 - 28ms/epoch - 28ms/step\n",
            "Epoch 113/500\n",
            "1/1 - 0s - loss: 0.6359 - accuracy: 0.6720 - val_loss: 0.7938 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 114/500\n",
            "1/1 - 0s - loss: 0.6330 - accuracy: 0.6440 - val_loss: 0.7938 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 115/500\n",
            "1/1 - 0s - loss: 0.6352 - accuracy: 0.6440 - val_loss: 0.7939 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 116/500\n",
            "1/1 - 0s - loss: 0.6317 - accuracy: 0.6600 - val_loss: 0.7942 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 117/500\n",
            "1/1 - 0s - loss: 0.6298 - accuracy: 0.6600 - val_loss: 0.7949 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 118/500\n",
            "1/1 - 0s - loss: 0.6322 - accuracy: 0.6440 - val_loss: 0.7959 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 119/500\n",
            "1/1 - 0s - loss: 0.6290 - accuracy: 0.6600 - val_loss: 0.7973 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 120/500\n",
            "1/1 - 0s - loss: 0.6293 - accuracy: 0.6560 - val_loss: 0.7989 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 121/500\n",
            "1/1 - 0s - loss: 0.6303 - accuracy: 0.6320 - val_loss: 0.8001 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 122/500\n",
            "1/1 - 0s - loss: 0.6274 - accuracy: 0.6640 - val_loss: 0.8012 - val_accuracy: 0.4762 - 50ms/epoch - 50ms/step\n",
            "Epoch 123/500\n",
            "1/1 - 0s - loss: 0.6250 - accuracy: 0.6640 - val_loss: 0.8021 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 124/500\n",
            "1/1 - 0s - loss: 0.6432 - accuracy: 0.6360 - val_loss: 0.8029 - val_accuracy: 0.4603 - 36ms/epoch - 36ms/step\n",
            "Epoch 125/500\n",
            "1/1 - 0s - loss: 0.6268 - accuracy: 0.6680 - val_loss: 0.8038 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 126/500\n",
            "1/1 - 0s - loss: 0.6322 - accuracy: 0.6720 - val_loss: 0.8045 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 127/500\n",
            "1/1 - 0s - loss: 0.6335 - accuracy: 0.6720 - val_loss: 0.8050 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 128/500\n",
            "1/1 - 0s - loss: 0.6288 - accuracy: 0.6520 - val_loss: 0.8054 - val_accuracy: 0.4603 - 35ms/epoch - 35ms/step\n",
            "Epoch 129/500\n",
            "1/1 - 0s - loss: 0.6282 - accuracy: 0.6600 - val_loss: 0.8060 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 130/500\n",
            "1/1 - 0s - loss: 0.6301 - accuracy: 0.6360 - val_loss: 0.8065 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 131/500\n",
            "1/1 - 0s - loss: 0.6243 - accuracy: 0.6680 - val_loss: 0.8070 - val_accuracy: 0.4603 - 26ms/epoch - 26ms/step\n",
            "Epoch 132/500\n",
            "1/1 - 0s - loss: 0.6273 - accuracy: 0.6440 - val_loss: 0.8074 - val_accuracy: 0.4603 - 36ms/epoch - 36ms/step\n",
            "Epoch 133/500\n",
            "1/1 - 0s - loss: 0.6238 - accuracy: 0.6760 - val_loss: 0.8080 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 134/500\n",
            "1/1 - 0s - loss: 0.6266 - accuracy: 0.6760 - val_loss: 0.8085 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 135/500\n",
            "1/1 - 0s - loss: 0.6160 - accuracy: 0.6800 - val_loss: 0.8093 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 136/500\n",
            "1/1 - 0s - loss: 0.6205 - accuracy: 0.6880 - val_loss: 0.8103 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 137/500\n",
            "1/1 - 0s - loss: 0.6118 - accuracy: 0.6840 - val_loss: 0.8120 - val_accuracy: 0.4444 - 40ms/epoch - 40ms/step\n",
            "Epoch 138/500\n",
            "1/1 - 0s - loss: 0.6193 - accuracy: 0.6560 - val_loss: 0.8139 - val_accuracy: 0.4444 - 28ms/epoch - 28ms/step\n",
            "Epoch 139/500\n",
            "1/1 - 0s - loss: 0.6203 - accuracy: 0.6840 - val_loss: 0.8158 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 140/500\n",
            "1/1 - 0s - loss: 0.6237 - accuracy: 0.6640 - val_loss: 0.8169 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 141/500\n",
            "1/1 - 0s - loss: 0.6239 - accuracy: 0.6840 - val_loss: 0.8178 - val_accuracy: 0.4444 - 28ms/epoch - 28ms/step\n",
            "Epoch 142/500\n",
            "1/1 - 0s - loss: 0.6178 - accuracy: 0.6880 - val_loss: 0.8187 - val_accuracy: 0.4444 - 30ms/epoch - 30ms/step\n",
            "Epoch 143/500\n",
            "1/1 - 0s - loss: 0.6259 - accuracy: 0.6640 - val_loss: 0.8190 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 144/500\n",
            "1/1 - 0s - loss: 0.6275 - accuracy: 0.6720 - val_loss: 0.8190 - val_accuracy: 0.4603 - 34ms/epoch - 34ms/step\n",
            "Epoch 145/500\n",
            "1/1 - 0s - loss: 0.6207 - accuracy: 0.6800 - val_loss: 0.8195 - val_accuracy: 0.4603 - 32ms/epoch - 32ms/step\n",
            "Epoch 146/500\n",
            "1/1 - 0s - loss: 0.6211 - accuracy: 0.6840 - val_loss: 0.8198 - val_accuracy: 0.4603 - 42ms/epoch - 42ms/step\n",
            "Epoch 147/500\n",
            "1/1 - 0s - loss: 0.6314 - accuracy: 0.6600 - val_loss: 0.8199 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 148/500\n",
            "1/1 - 0s - loss: 0.6190 - accuracy: 0.6440 - val_loss: 0.8205 - val_accuracy: 0.4444 - 32ms/epoch - 32ms/step\n",
            "Epoch 149/500\n",
            "1/1 - 0s - loss: 0.6184 - accuracy: 0.6840 - val_loss: 0.8214 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 150/500\n",
            "1/1 - 0s - loss: 0.6280 - accuracy: 0.6680 - val_loss: 0.8216 - val_accuracy: 0.4444 - 30ms/epoch - 30ms/step\n",
            "Epoch 151/500\n",
            "1/1 - 0s - loss: 0.6188 - accuracy: 0.6640 - val_loss: 0.8214 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 152/500\n",
            "1/1 - 0s - loss: 0.6141 - accuracy: 0.6720 - val_loss: 0.8211 - val_accuracy: 0.4444 - 31ms/epoch - 31ms/step\n",
            "Epoch 153/500\n",
            "1/1 - 0s - loss: 0.6176 - accuracy: 0.6600 - val_loss: 0.8211 - val_accuracy: 0.4444 - 30ms/epoch - 30ms/step\n",
            "Epoch 154/500\n",
            "1/1 - 0s - loss: 0.6195 - accuracy: 0.6720 - val_loss: 0.8218 - val_accuracy: 0.4444 - 33ms/epoch - 33ms/step\n",
            "Epoch 155/500\n",
            "1/1 - 0s - loss: 0.6244 - accuracy: 0.6560 - val_loss: 0.8223 - val_accuracy: 0.4444 - 34ms/epoch - 34ms/step\n",
            "Epoch 156/500\n",
            "1/1 - 0s - loss: 0.6146 - accuracy: 0.6720 - val_loss: 0.8232 - val_accuracy: 0.4444 - 29ms/epoch - 29ms/step\n",
            "Epoch 157/500\n",
            "1/1 - 0s - loss: 0.6204 - accuracy: 0.6600 - val_loss: 0.8239 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 158/500\n",
            "1/1 - 0s - loss: 0.6319 - accuracy: 0.6400 - val_loss: 0.8248 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 159/500\n",
            "1/1 - 0s - loss: 0.6165 - accuracy: 0.6560 - val_loss: 0.8253 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 160/500\n",
            "1/1 - 0s - loss: 0.6094 - accuracy: 0.6840 - val_loss: 0.8261 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 161/500\n",
            "1/1 - 0s - loss: 0.6136 - accuracy: 0.6680 - val_loss: 0.8270 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 162/500\n",
            "1/1 - 0s - loss: 0.6055 - accuracy: 0.6840 - val_loss: 0.8284 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 163/500\n",
            "1/1 - 0s - loss: 0.6094 - accuracy: 0.6920 - val_loss: 0.8300 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 164/500\n",
            "1/1 - 0s - loss: 0.6122 - accuracy: 0.6520 - val_loss: 0.8308 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 165/500\n",
            "1/1 - 0s - loss: 0.6210 - accuracy: 0.6560 - val_loss: 0.8310 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 166/500\n",
            "1/1 - 0s - loss: 0.6099 - accuracy: 0.6800 - val_loss: 0.8313 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 167/500\n",
            "1/1 - 0s - loss: 0.6095 - accuracy: 0.6680 - val_loss: 0.8317 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 168/500\n",
            "1/1 - 0s - loss: 0.6062 - accuracy: 0.6840 - val_loss: 0.8329 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 169/500\n",
            "1/1 - 0s - loss: 0.6243 - accuracy: 0.6680 - val_loss: 0.8335 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 170/500\n",
            "1/1 - 0s - loss: 0.6111 - accuracy: 0.6880 - val_loss: 0.8335 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 171/500\n",
            "1/1 - 0s - loss: 0.6054 - accuracy: 0.6840 - val_loss: 0.8335 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 172/500\n",
            "1/1 - 0s - loss: 0.6116 - accuracy: 0.6720 - val_loss: 0.8336 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 173/500\n",
            "1/1 - 0s - loss: 0.6008 - accuracy: 0.6920 - val_loss: 0.8334 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 174/500\n",
            "1/1 - 0s - loss: 0.6101 - accuracy: 0.6680 - val_loss: 0.8328 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 175/500\n",
            "1/1 - 0s - loss: 0.6088 - accuracy: 0.6640 - val_loss: 0.8322 - val_accuracy: 0.4603 - 35ms/epoch - 35ms/step\n",
            "Epoch 176/500\n",
            "1/1 - 0s - loss: 0.5981 - accuracy: 0.6920 - val_loss: 0.8324 - val_accuracy: 0.4603 - 34ms/epoch - 34ms/step\n",
            "Epoch 177/500\n",
            "1/1 - 0s - loss: 0.6153 - accuracy: 0.6880 - val_loss: 0.8330 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 178/500\n",
            "1/1 - 0s - loss: 0.5999 - accuracy: 0.6880 - val_loss: 0.8342 - val_accuracy: 0.4444 - 28ms/epoch - 28ms/step\n",
            "Epoch 179/500\n",
            "1/1 - 0s - loss: 0.6044 - accuracy: 0.6800 - val_loss: 0.8353 - val_accuracy: 0.4444 - 36ms/epoch - 36ms/step\n",
            "Epoch 180/500\n",
            "1/1 - 0s - loss: 0.5924 - accuracy: 0.6880 - val_loss: 0.8366 - val_accuracy: 0.4444 - 29ms/epoch - 29ms/step\n",
            "Epoch 181/500\n",
            "1/1 - 0s - loss: 0.5978 - accuracy: 0.6840 - val_loss: 0.8386 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 182/500\n",
            "1/1 - 0s - loss: 0.6159 - accuracy: 0.6800 - val_loss: 0.8401 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 183/500\n",
            "1/1 - 0s - loss: 0.6006 - accuracy: 0.6960 - val_loss: 0.8411 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 184/500\n",
            "1/1 - 0s - loss: 0.5989 - accuracy: 0.6920 - val_loss: 0.8417 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 185/500\n",
            "1/1 - 0s - loss: 0.6061 - accuracy: 0.6680 - val_loss: 0.8415 - val_accuracy: 0.4603 - 34ms/epoch - 34ms/step\n",
            "Epoch 186/500\n",
            "1/1 - 0s - loss: 0.6108 - accuracy: 0.6640 - val_loss: 0.8403 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 187/500\n",
            "1/1 - 0s - loss: 0.6168 - accuracy: 0.6440 - val_loss: 0.8392 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 188/500\n",
            "1/1 - 0s - loss: 0.6007 - accuracy: 0.6720 - val_loss: 0.8391 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 189/500\n",
            "1/1 - 0s - loss: 0.6026 - accuracy: 0.6800 - val_loss: 0.8385 - val_accuracy: 0.4603 - 35ms/epoch - 35ms/step\n",
            "Epoch 190/500\n",
            "1/1 - 0s - loss: 0.5993 - accuracy: 0.7000 - val_loss: 0.8383 - val_accuracy: 0.4603 - 32ms/epoch - 32ms/step\n",
            "Epoch 191/500\n",
            "1/1 - 0s - loss: 0.5970 - accuracy: 0.6800 - val_loss: 0.8393 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 192/500\n",
            "1/1 - 0s - loss: 0.5978 - accuracy: 0.6920 - val_loss: 0.8412 - val_accuracy: 0.4444 - 31ms/epoch - 31ms/step\n",
            "Epoch 193/500\n",
            "1/1 - 0s - loss: 0.5879 - accuracy: 0.7000 - val_loss: 0.8429 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 194/500\n",
            "1/1 - 0s - loss: 0.6120 - accuracy: 0.6560 - val_loss: 0.8441 - val_accuracy: 0.4286 - 29ms/epoch - 29ms/step\n",
            "Epoch 195/500\n",
            "1/1 - 0s - loss: 0.5924 - accuracy: 0.6800 - val_loss: 0.8451 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 196/500\n",
            "1/1 - 0s - loss: 0.5919 - accuracy: 0.6880 - val_loss: 0.8464 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 197/500\n",
            "1/1 - 0s - loss: 0.5912 - accuracy: 0.6760 - val_loss: 0.8461 - val_accuracy: 0.4444 - 33ms/epoch - 33ms/step\n",
            "Epoch 198/500\n",
            "1/1 - 0s - loss: 0.5965 - accuracy: 0.6880 - val_loss: 0.8454 - val_accuracy: 0.4444 - 32ms/epoch - 32ms/step\n",
            "Epoch 199/500\n",
            "1/1 - 0s - loss: 0.6018 - accuracy: 0.6840 - val_loss: 0.8451 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 200/500\n",
            "1/1 - 0s - loss: 0.5991 - accuracy: 0.6800 - val_loss: 0.8454 - val_accuracy: 0.4603 - 37ms/epoch - 37ms/step\n",
            "Epoch 201/500\n",
            "1/1 - 0s - loss: 0.5841 - accuracy: 0.7160 - val_loss: 0.8464 - val_accuracy: 0.4603 - 27ms/epoch - 27ms/step\n",
            "Epoch 202/500\n",
            "1/1 - 0s - loss: 0.5933 - accuracy: 0.6840 - val_loss: 0.8484 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 203/500\n",
            "1/1 - 0s - loss: 0.5909 - accuracy: 0.6880 - val_loss: 0.8489 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 204/500\n",
            "1/1 - 0s - loss: 0.5913 - accuracy: 0.6800 - val_loss: 0.8498 - val_accuracy: 0.4603 - 40ms/epoch - 40ms/step\n",
            "Epoch 205/500\n",
            "1/1 - 0s - loss: 0.5878 - accuracy: 0.6840 - val_loss: 0.8501 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 206/500\n",
            "1/1 - 0s - loss: 0.6032 - accuracy: 0.6680 - val_loss: 0.8507 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 207/500\n",
            "1/1 - 0s - loss: 0.5945 - accuracy: 0.6960 - val_loss: 0.8504 - val_accuracy: 0.4603 - 25ms/epoch - 25ms/step\n",
            "Epoch 208/500\n",
            "1/1 - 0s - loss: 0.5848 - accuracy: 0.6920 - val_loss: 0.8508 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 209/500\n",
            "1/1 - 0s - loss: 0.6042 - accuracy: 0.6560 - val_loss: 0.8515 - val_accuracy: 0.4603 - 50ms/epoch - 50ms/step\n",
            "Epoch 210/500\n",
            "1/1 - 0s - loss: 0.5908 - accuracy: 0.6800 - val_loss: 0.8530 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 211/500\n",
            "1/1 - 0s - loss: 0.5897 - accuracy: 0.6920 - val_loss: 0.8557 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 212/500\n",
            "1/1 - 0s - loss: 0.5935 - accuracy: 0.6800 - val_loss: 0.8587 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 213/500\n",
            "1/1 - 0s - loss: 0.5888 - accuracy: 0.7080 - val_loss: 0.8627 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 214/500\n",
            "1/1 - 0s - loss: 0.5849 - accuracy: 0.7000 - val_loss: 0.8664 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 215/500\n",
            "1/1 - 0s - loss: 0.5919 - accuracy: 0.6720 - val_loss: 0.8696 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 216/500\n",
            "1/1 - 0s - loss: 0.5834 - accuracy: 0.6960 - val_loss: 0.8708 - val_accuracy: 0.4603 - 35ms/epoch - 35ms/step\n",
            "Epoch 217/500\n",
            "1/1 - 0s - loss: 0.5872 - accuracy: 0.6880 - val_loss: 0.8707 - val_accuracy: 0.4603 - 37ms/epoch - 37ms/step\n",
            "Epoch 218/500\n",
            "1/1 - 0s - loss: 0.5852 - accuracy: 0.7120 - val_loss: 0.8691 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 219/500\n",
            "1/1 - 0s - loss: 0.5910 - accuracy: 0.6880 - val_loss: 0.8681 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 220/500\n",
            "1/1 - 0s - loss: 0.5732 - accuracy: 0.7120 - val_loss: 0.8680 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 221/500\n",
            "1/1 - 0s - loss: 0.5879 - accuracy: 0.6600 - val_loss: 0.8677 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 222/500\n",
            "1/1 - 0s - loss: 0.5834 - accuracy: 0.6960 - val_loss: 0.8679 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 223/500\n",
            "1/1 - 0s - loss: 0.5829 - accuracy: 0.7080 - val_loss: 0.8687 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 224/500\n",
            "1/1 - 0s - loss: 0.5923 - accuracy: 0.6720 - val_loss: 0.8704 - val_accuracy: 0.4762 - 46ms/epoch - 46ms/step\n",
            "Epoch 225/500\n",
            "1/1 - 0s - loss: 0.5729 - accuracy: 0.6960 - val_loss: 0.8739 - val_accuracy: 0.4762 - 56ms/epoch - 56ms/step\n",
            "Epoch 226/500\n",
            "1/1 - 0s - loss: 0.5836 - accuracy: 0.6960 - val_loss: 0.8756 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 227/500\n",
            "1/1 - 0s - loss: 0.5887 - accuracy: 0.6760 - val_loss: 0.8775 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 228/500\n",
            "1/1 - 0s - loss: 0.5854 - accuracy: 0.6800 - val_loss: 0.8775 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 229/500\n",
            "1/1 - 0s - loss: 0.5769 - accuracy: 0.6960 - val_loss: 0.8777 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 230/500\n",
            "1/1 - 0s - loss: 0.5822 - accuracy: 0.7080 - val_loss: 0.8770 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 231/500\n",
            "1/1 - 0s - loss: 0.6028 - accuracy: 0.6680 - val_loss: 0.8774 - val_accuracy: 0.4603 - 38ms/epoch - 38ms/step\n",
            "Epoch 232/500\n",
            "1/1 - 0s - loss: 0.5715 - accuracy: 0.7240 - val_loss: 0.8782 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 233/500\n",
            "1/1 - 0s - loss: 0.5767 - accuracy: 0.6960 - val_loss: 0.8790 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 234/500\n",
            "1/1 - 0s - loss: 0.5748 - accuracy: 0.7120 - val_loss: 0.8793 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 235/500\n",
            "1/1 - 0s - loss: 0.5822 - accuracy: 0.7080 - val_loss: 0.8798 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 236/500\n",
            "1/1 - 0s - loss: 0.5686 - accuracy: 0.6960 - val_loss: 0.8805 - val_accuracy: 0.4603 - 29ms/epoch - 29ms/step\n",
            "Epoch 237/500\n",
            "1/1 - 0s - loss: 0.5855 - accuracy: 0.6800 - val_loss: 0.8803 - val_accuracy: 0.4603 - 54ms/epoch - 54ms/step\n",
            "Epoch 238/500\n",
            "1/1 - 0s - loss: 0.5881 - accuracy: 0.6680 - val_loss: 0.8776 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 239/500\n",
            "1/1 - 0s - loss: 0.5756 - accuracy: 0.7000 - val_loss: 0.8776 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 240/500\n",
            "1/1 - 0s - loss: 0.5802 - accuracy: 0.6800 - val_loss: 0.8788 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 241/500\n",
            "1/1 - 0s - loss: 0.5787 - accuracy: 0.6760 - val_loss: 0.8812 - val_accuracy: 0.4603 - 26ms/epoch - 26ms/step\n",
            "Epoch 242/500\n",
            "1/1 - 0s - loss: 0.5794 - accuracy: 0.6920 - val_loss: 0.8857 - val_accuracy: 0.4444 - 27ms/epoch - 27ms/step\n",
            "Epoch 243/500\n",
            "1/1 - 0s - loss: 0.5766 - accuracy: 0.6920 - val_loss: 0.8886 - val_accuracy: 0.4444 - 28ms/epoch - 28ms/step\n",
            "Epoch 244/500\n",
            "1/1 - 0s - loss: 0.5771 - accuracy: 0.7160 - val_loss: 0.8917 - val_accuracy: 0.4444 - 34ms/epoch - 34ms/step\n",
            "Epoch 245/500\n",
            "1/1 - 0s - loss: 0.5722 - accuracy: 0.6840 - val_loss: 0.8954 - val_accuracy: 0.4444 - 31ms/epoch - 31ms/step\n",
            "Epoch 246/500\n",
            "1/1 - 0s - loss: 0.6006 - accuracy: 0.6800 - val_loss: 0.8985 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 247/500\n",
            "1/1 - 0s - loss: 0.5706 - accuracy: 0.6960 - val_loss: 0.9001 - val_accuracy: 0.4444 - 29ms/epoch - 29ms/step\n",
            "Epoch 248/500\n",
            "1/1 - 0s - loss: 0.5819 - accuracy: 0.7000 - val_loss: 0.9014 - val_accuracy: 0.4444 - 32ms/epoch - 32ms/step\n",
            "Epoch 249/500\n",
            "1/1 - 0s - loss: 0.5760 - accuracy: 0.6920 - val_loss: 0.9018 - val_accuracy: 0.4603 - 32ms/epoch - 32ms/step\n",
            "Epoch 250/500\n",
            "1/1 - 0s - loss: 0.5745 - accuracy: 0.6760 - val_loss: 0.9026 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 251/500\n",
            "1/1 - 0s - loss: 0.5862 - accuracy: 0.6760 - val_loss: 0.9030 - val_accuracy: 0.4603 - 32ms/epoch - 32ms/step\n",
            "Epoch 252/500\n",
            "1/1 - 0s - loss: 0.5649 - accuracy: 0.6800 - val_loss: 0.9041 - val_accuracy: 0.4603 - 32ms/epoch - 32ms/step\n",
            "Epoch 253/500\n",
            "1/1 - 0s - loss: 0.5480 - accuracy: 0.7080 - val_loss: 0.9064 - val_accuracy: 0.4444 - 36ms/epoch - 36ms/step\n",
            "Epoch 254/500\n",
            "1/1 - 0s - loss: 0.5713 - accuracy: 0.6800 - val_loss: 0.9095 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 255/500\n",
            "1/1 - 0s - loss: 0.5655 - accuracy: 0.6760 - val_loss: 0.9108 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 256/500\n",
            "1/1 - 0s - loss: 0.5543 - accuracy: 0.7280 - val_loss: 0.9123 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 257/500\n",
            "1/1 - 0s - loss: 0.5550 - accuracy: 0.6920 - val_loss: 0.9132 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 258/500\n",
            "1/1 - 0s - loss: 0.5851 - accuracy: 0.6840 - val_loss: 0.9131 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 259/500\n",
            "1/1 - 0s - loss: 0.5710 - accuracy: 0.6880 - val_loss: 0.9128 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 260/500\n",
            "1/1 - 0s - loss: 0.5665 - accuracy: 0.6920 - val_loss: 0.9127 - val_accuracy: 0.4603 - 38ms/epoch - 38ms/step\n",
            "Epoch 261/500\n",
            "1/1 - 0s - loss: 0.5884 - accuracy: 0.6960 - val_loss: 0.9129 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 262/500\n",
            "1/1 - 0s - loss: 0.5727 - accuracy: 0.7080 - val_loss: 0.9146 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 263/500\n",
            "1/1 - 0s - loss: 0.5656 - accuracy: 0.7160 - val_loss: 0.9180 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 264/500\n",
            "1/1 - 0s - loss: 0.5801 - accuracy: 0.6720 - val_loss: 0.9223 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 265/500\n",
            "1/1 - 0s - loss: 0.5625 - accuracy: 0.7200 - val_loss: 0.9267 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 266/500\n",
            "1/1 - 0s - loss: 0.5689 - accuracy: 0.7120 - val_loss: 0.9304 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 267/500\n",
            "1/1 - 0s - loss: 0.5713 - accuracy: 0.6880 - val_loss: 0.9312 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 268/500\n",
            "1/1 - 0s - loss: 0.5452 - accuracy: 0.7280 - val_loss: 0.9332 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 269/500\n",
            "1/1 - 0s - loss: 0.5558 - accuracy: 0.7280 - val_loss: 0.9328 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 270/500\n",
            "1/1 - 0s - loss: 0.5525 - accuracy: 0.6840 - val_loss: 0.9283 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 271/500\n",
            "1/1 - 0s - loss: 0.5708 - accuracy: 0.7080 - val_loss: 0.9228 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 272/500\n",
            "1/1 - 0s - loss: 0.5657 - accuracy: 0.7280 - val_loss: 0.9195 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 273/500\n",
            "1/1 - 0s - loss: 0.5494 - accuracy: 0.7080 - val_loss: 0.9179 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 274/500\n",
            "1/1 - 0s - loss: 0.5574 - accuracy: 0.7120 - val_loss: 0.9181 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 275/500\n",
            "1/1 - 0s - loss: 0.5644 - accuracy: 0.7080 - val_loss: 0.9209 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 276/500\n",
            "1/1 - 0s - loss: 0.5639 - accuracy: 0.7080 - val_loss: 0.9254 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 277/500\n",
            "1/1 - 0s - loss: 0.5673 - accuracy: 0.7160 - val_loss: 0.9295 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 278/500\n",
            "1/1 - 0s - loss: 0.5480 - accuracy: 0.7080 - val_loss: 0.9357 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 279/500\n",
            "1/1 - 0s - loss: 0.5402 - accuracy: 0.7080 - val_loss: 0.9399 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 280/500\n",
            "1/1 - 0s - loss: 0.5660 - accuracy: 0.7160 - val_loss: 0.9419 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 281/500\n",
            "1/1 - 0s - loss: 0.5487 - accuracy: 0.7160 - val_loss: 0.9389 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 282/500\n",
            "1/1 - 0s - loss: 0.5556 - accuracy: 0.7040 - val_loss: 0.9366 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 283/500\n",
            "1/1 - 0s - loss: 0.5633 - accuracy: 0.6760 - val_loss: 0.9359 - val_accuracy: 0.4921 - 42ms/epoch - 42ms/step\n",
            "Epoch 284/500\n",
            "1/1 - 0s - loss: 0.5709 - accuracy: 0.7000 - val_loss: 0.9366 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 285/500\n",
            "1/1 - 0s - loss: 0.5658 - accuracy: 0.7000 - val_loss: 0.9383 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 286/500\n",
            "1/1 - 0s - loss: 0.5530 - accuracy: 0.7360 - val_loss: 0.9386 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 287/500\n",
            "1/1 - 0s - loss: 0.5783 - accuracy: 0.6840 - val_loss: 0.9401 - val_accuracy: 0.4921 - 40ms/epoch - 40ms/step\n",
            "Epoch 288/500\n",
            "1/1 - 0s - loss: 0.5681 - accuracy: 0.6920 - val_loss: 0.9395 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 289/500\n",
            "1/1 - 0s - loss: 0.5716 - accuracy: 0.6720 - val_loss: 0.9407 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 290/500\n",
            "1/1 - 0s - loss: 0.5461 - accuracy: 0.7040 - val_loss: 0.9448 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 291/500\n",
            "1/1 - 0s - loss: 0.5484 - accuracy: 0.7200 - val_loss: 0.9486 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 292/500\n",
            "1/1 - 0s - loss: 0.5495 - accuracy: 0.6920 - val_loss: 0.9517 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 293/500\n",
            "1/1 - 0s - loss: 0.5360 - accuracy: 0.7200 - val_loss: 0.9515 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 294/500\n",
            "1/1 - 0s - loss: 0.5506 - accuracy: 0.7160 - val_loss: 0.9510 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 295/500\n",
            "1/1 - 0s - loss: 0.5438 - accuracy: 0.7160 - val_loss: 0.9501 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 296/500\n",
            "1/1 - 0s - loss: 0.5580 - accuracy: 0.6760 - val_loss: 0.9514 - val_accuracy: 0.4762 - 45ms/epoch - 45ms/step\n",
            "Epoch 297/500\n",
            "1/1 - 0s - loss: 0.5276 - accuracy: 0.7440 - val_loss: 0.9534 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 298/500\n",
            "1/1 - 0s - loss: 0.5582 - accuracy: 0.7000 - val_loss: 0.9572 - val_accuracy: 0.4921 - 39ms/epoch - 39ms/step\n",
            "Epoch 299/500\n",
            "1/1 - 0s - loss: 0.5561 - accuracy: 0.6840 - val_loss: 0.9608 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 300/500\n",
            "1/1 - 0s - loss: 0.5824 - accuracy: 0.6960 - val_loss: 0.9635 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 301/500\n",
            "1/1 - 0s - loss: 0.5497 - accuracy: 0.7080 - val_loss: 0.9640 - val_accuracy: 0.4921 - 34ms/epoch - 34ms/step\n",
            "Epoch 302/500\n",
            "1/1 - 0s - loss: 0.5437 - accuracy: 0.7040 - val_loss: 0.9618 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 303/500\n",
            "1/1 - 0s - loss: 0.5342 - accuracy: 0.7280 - val_loss: 0.9581 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 304/500\n",
            "1/1 - 0s - loss: 0.5418 - accuracy: 0.7160 - val_loss: 0.9558 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 305/500\n",
            "1/1 - 0s - loss: 0.5573 - accuracy: 0.7200 - val_loss: 0.9556 - val_accuracy: 0.4921 - 34ms/epoch - 34ms/step\n",
            "Epoch 306/500\n",
            "1/1 - 0s - loss: 0.5427 - accuracy: 0.6880 - val_loss: 0.9570 - val_accuracy: 0.4921 - 36ms/epoch - 36ms/step\n",
            "Epoch 307/500\n",
            "1/1 - 0s - loss: 0.5649 - accuracy: 0.6960 - val_loss: 0.9587 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 308/500\n",
            "1/1 - 0s - loss: 0.5396 - accuracy: 0.7080 - val_loss: 0.9609 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 309/500\n",
            "1/1 - 0s - loss: 0.5481 - accuracy: 0.7360 - val_loss: 0.9628 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 310/500\n",
            "1/1 - 0s - loss: 0.5437 - accuracy: 0.7200 - val_loss: 0.9657 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 311/500\n",
            "1/1 - 0s - loss: 0.5547 - accuracy: 0.7040 - val_loss: 0.9669 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 312/500\n",
            "1/1 - 0s - loss: 0.5501 - accuracy: 0.7120 - val_loss: 0.9687 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 313/500\n",
            "1/1 - 0s - loss: 0.5455 - accuracy: 0.6920 - val_loss: 0.9707 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 314/500\n",
            "1/1 - 0s - loss: 0.5326 - accuracy: 0.7160 - val_loss: 0.9705 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 315/500\n",
            "1/1 - 0s - loss: 0.5607 - accuracy: 0.7040 - val_loss: 0.9706 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 316/500\n",
            "1/1 - 0s - loss: 0.5480 - accuracy: 0.7080 - val_loss: 0.9727 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 317/500\n",
            "1/1 - 0s - loss: 0.5391 - accuracy: 0.7120 - val_loss: 0.9734 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 318/500\n",
            "1/1 - 0s - loss: 0.5408 - accuracy: 0.7040 - val_loss: 0.9714 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 319/500\n",
            "1/1 - 0s - loss: 0.5332 - accuracy: 0.7200 - val_loss: 0.9702 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 320/500\n",
            "1/1 - 0s - loss: 0.5413 - accuracy: 0.7360 - val_loss: 0.9686 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 321/500\n",
            "1/1 - 0s - loss: 0.5604 - accuracy: 0.7080 - val_loss: 0.9666 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 322/500\n",
            "1/1 - 0s - loss: 0.5318 - accuracy: 0.6960 - val_loss: 0.9655 - val_accuracy: 0.4921 - 47ms/epoch - 47ms/step\n",
            "Epoch 323/500\n",
            "1/1 - 0s - loss: 0.5623 - accuracy: 0.7160 - val_loss: 0.9652 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 324/500\n",
            "1/1 - 0s - loss: 0.5233 - accuracy: 0.7080 - val_loss: 0.9661 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 325/500\n",
            "1/1 - 0s - loss: 0.5534 - accuracy: 0.7000 - val_loss: 0.9681 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 326/500\n",
            "1/1 - 0s - loss: 0.5455 - accuracy: 0.7200 - val_loss: 0.9681 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 327/500\n",
            "1/1 - 0s - loss: 0.5413 - accuracy: 0.7040 - val_loss: 0.9689 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 328/500\n",
            "1/1 - 0s - loss: 0.5303 - accuracy: 0.7240 - val_loss: 0.9699 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 329/500\n",
            "1/1 - 0s - loss: 0.5357 - accuracy: 0.7240 - val_loss: 0.9698 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 330/500\n",
            "1/1 - 0s - loss: 0.5182 - accuracy: 0.7400 - val_loss: 0.9705 - val_accuracy: 0.4921 - 38ms/epoch - 38ms/step\n",
            "Epoch 331/500\n",
            "1/1 - 0s - loss: 0.5516 - accuracy: 0.7080 - val_loss: 0.9699 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 332/500\n",
            "1/1 - 0s - loss: 0.5257 - accuracy: 0.7280 - val_loss: 0.9679 - val_accuracy: 0.4921 - 39ms/epoch - 39ms/step\n",
            "Epoch 333/500\n",
            "1/1 - 0s - loss: 0.5256 - accuracy: 0.7480 - val_loss: 0.9675 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 334/500\n",
            "1/1 - 0s - loss: 0.5317 - accuracy: 0.7240 - val_loss: 0.9685 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 335/500\n",
            "1/1 - 0s - loss: 0.5297 - accuracy: 0.7240 - val_loss: 0.9703 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 336/500\n",
            "1/1 - 0s - loss: 0.5248 - accuracy: 0.7200 - val_loss: 0.9718 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 337/500\n",
            "1/1 - 0s - loss: 0.5263 - accuracy: 0.7440 - val_loss: 0.9720 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 338/500\n",
            "1/1 - 0s - loss: 0.5418 - accuracy: 0.7080 - val_loss: 0.9714 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 339/500\n",
            "1/1 - 0s - loss: 0.5486 - accuracy: 0.7000 - val_loss: 0.9733 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 340/500\n",
            "1/1 - 0s - loss: 0.5290 - accuracy: 0.7200 - val_loss: 0.9785 - val_accuracy: 0.4603 - 30ms/epoch - 30ms/step\n",
            "Epoch 341/500\n",
            "1/1 - 0s - loss: 0.5363 - accuracy: 0.7200 - val_loss: 0.9851 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 342/500\n",
            "1/1 - 0s - loss: 0.5467 - accuracy: 0.7200 - val_loss: 0.9902 - val_accuracy: 0.4762 - 38ms/epoch - 38ms/step\n",
            "Epoch 343/500\n",
            "1/1 - 0s - loss: 0.5378 - accuracy: 0.7040 - val_loss: 0.9939 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 344/500\n",
            "1/1 - 0s - loss: 0.5484 - accuracy: 0.7080 - val_loss: 0.9930 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 345/500\n",
            "1/1 - 0s - loss: 0.5372 - accuracy: 0.7200 - val_loss: 0.9908 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 346/500\n",
            "1/1 - 0s - loss: 0.5196 - accuracy: 0.7400 - val_loss: 0.9882 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 347/500\n",
            "1/1 - 0s - loss: 0.5234 - accuracy: 0.7240 - val_loss: 0.9864 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 348/500\n",
            "1/1 - 0s - loss: 0.5419 - accuracy: 0.7200 - val_loss: 0.9852 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 349/500\n",
            "1/1 - 0s - loss: 0.5431 - accuracy: 0.7320 - val_loss: 0.9861 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 350/500\n",
            "1/1 - 0s - loss: 0.5352 - accuracy: 0.7040 - val_loss: 0.9870 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 351/500\n",
            "1/1 - 0s - loss: 0.5241 - accuracy: 0.7400 - val_loss: 0.9888 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 352/500\n",
            "1/1 - 0s - loss: 0.5324 - accuracy: 0.7000 - val_loss: 0.9874 - val_accuracy: 0.4762 - 37ms/epoch - 37ms/step\n",
            "Epoch 353/500\n",
            "1/1 - 0s - loss: 0.5227 - accuracy: 0.7360 - val_loss: 0.9860 - val_accuracy: 0.4603 - 28ms/epoch - 28ms/step\n",
            "Epoch 354/500\n",
            "1/1 - 0s - loss: 0.5267 - accuracy: 0.7240 - val_loss: 0.9845 - val_accuracy: 0.4603 - 33ms/epoch - 33ms/step\n",
            "Epoch 355/500\n",
            "1/1 - 0s - loss: 0.5190 - accuracy: 0.7360 - val_loss: 0.9858 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 356/500\n",
            "1/1 - 0s - loss: 0.5188 - accuracy: 0.7440 - val_loss: 0.9898 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 357/500\n",
            "1/1 - 0s - loss: 0.5556 - accuracy: 0.7120 - val_loss: 0.9928 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 358/500\n",
            "1/1 - 0s - loss: 0.5457 - accuracy: 0.7160 - val_loss: 0.9947 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 359/500\n",
            "1/1 - 0s - loss: 0.5369 - accuracy: 0.7440 - val_loss: 0.9913 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 360/500\n",
            "1/1 - 0s - loss: 0.5476 - accuracy: 0.6960 - val_loss: 0.9873 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 361/500\n",
            "1/1 - 0s - loss: 0.5162 - accuracy: 0.7320 - val_loss: 0.9838 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 362/500\n",
            "1/1 - 0s - loss: 0.5151 - accuracy: 0.7160 - val_loss: 0.9827 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 363/500\n",
            "1/1 - 0s - loss: 0.5195 - accuracy: 0.7200 - val_loss: 0.9842 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 364/500\n",
            "1/1 - 0s - loss: 0.5203 - accuracy: 0.7200 - val_loss: 0.9868 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 365/500\n",
            "1/1 - 0s - loss: 0.5412 - accuracy: 0.6840 - val_loss: 0.9894 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 366/500\n",
            "1/1 - 0s - loss: 0.5263 - accuracy: 0.7160 - val_loss: 0.9935 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 367/500\n",
            "1/1 - 0s - loss: 0.5109 - accuracy: 0.7640 - val_loss: 0.9956 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 368/500\n",
            "1/1 - 0s - loss: 0.5233 - accuracy: 0.7160 - val_loss: 0.9965 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 369/500\n",
            "1/1 - 0s - loss: 0.5158 - accuracy: 0.7440 - val_loss: 0.9976 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 370/500\n",
            "1/1 - 0s - loss: 0.5420 - accuracy: 0.7120 - val_loss: 0.9969 - val_accuracy: 0.4762 - 46ms/epoch - 46ms/step\n",
            "Epoch 371/500\n",
            "1/1 - 0s - loss: 0.5163 - accuracy: 0.7480 - val_loss: 0.9975 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 372/500\n",
            "1/1 - 0s - loss: 0.5271 - accuracy: 0.7160 - val_loss: 0.9986 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 373/500\n",
            "1/1 - 0s - loss: 0.5109 - accuracy: 0.7360 - val_loss: 1.0027 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 374/500\n",
            "1/1 - 0s - loss: 0.4922 - accuracy: 0.7440 - val_loss: 1.0083 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 375/500\n",
            "1/1 - 0s - loss: 0.5250 - accuracy: 0.7440 - val_loss: 1.0143 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 376/500\n",
            "1/1 - 0s - loss: 0.5051 - accuracy: 0.7320 - val_loss: 1.0171 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 377/500\n",
            "1/1 - 0s - loss: 0.5139 - accuracy: 0.7400 - val_loss: 1.0169 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 378/500\n",
            "1/1 - 0s - loss: 0.5239 - accuracy: 0.7280 - val_loss: 1.0145 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 379/500\n",
            "1/1 - 0s - loss: 0.5199 - accuracy: 0.7360 - val_loss: 1.0105 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 380/500\n",
            "1/1 - 0s - loss: 0.5091 - accuracy: 0.7240 - val_loss: 1.0075 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 381/500\n",
            "1/1 - 0s - loss: 0.5056 - accuracy: 0.7320 - val_loss: 1.0052 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 382/500\n",
            "1/1 - 0s - loss: 0.5287 - accuracy: 0.7360 - val_loss: 1.0040 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 383/500\n",
            "1/1 - 0s - loss: 0.5154 - accuracy: 0.7240 - val_loss: 1.0013 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 384/500\n",
            "1/1 - 0s - loss: 0.5143 - accuracy: 0.7120 - val_loss: 1.0018 - val_accuracy: 0.4762 - 26ms/epoch - 26ms/step\n",
            "Epoch 385/500\n",
            "1/1 - 0s - loss: 0.4977 - accuracy: 0.7440 - val_loss: 1.0033 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 386/500\n",
            "1/1 - 0s - loss: 0.5111 - accuracy: 0.7320 - val_loss: 1.0073 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 387/500\n",
            "1/1 - 0s - loss: 0.5079 - accuracy: 0.7440 - val_loss: 1.0123 - val_accuracy: 0.4762 - 27ms/epoch - 27ms/step\n",
            "Epoch 388/500\n",
            "1/1 - 0s - loss: 0.5246 - accuracy: 0.7600 - val_loss: 1.0171 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 389/500\n",
            "1/1 - 0s - loss: 0.5209 - accuracy: 0.7160 - val_loss: 1.0207 - val_accuracy: 0.4762 - 26ms/epoch - 26ms/step\n",
            "Epoch 390/500\n",
            "1/1 - 0s - loss: 0.5038 - accuracy: 0.7560 - val_loss: 1.0233 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 391/500\n",
            "1/1 - 0s - loss: 0.5009 - accuracy: 0.7640 - val_loss: 1.0240 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 392/500\n",
            "1/1 - 0s - loss: 0.5141 - accuracy: 0.7360 - val_loss: 1.0236 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 393/500\n",
            "1/1 - 0s - loss: 0.5073 - accuracy: 0.7400 - val_loss: 1.0239 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 394/500\n",
            "1/1 - 0s - loss: 0.4997 - accuracy: 0.7400 - val_loss: 1.0248 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 395/500\n",
            "1/1 - 0s - loss: 0.5156 - accuracy: 0.7280 - val_loss: 1.0269 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 396/500\n",
            "1/1 - 0s - loss: 0.4988 - accuracy: 0.7520 - val_loss: 1.0284 - val_accuracy: 0.4921 - 26ms/epoch - 26ms/step\n",
            "Epoch 397/500\n",
            "1/1 - 0s - loss: 0.5185 - accuracy: 0.7240 - val_loss: 1.0299 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 398/500\n",
            "1/1 - 0s - loss: 0.5470 - accuracy: 0.7080 - val_loss: 1.0337 - val_accuracy: 0.4921 - 38ms/epoch - 38ms/step\n",
            "Epoch 399/500\n",
            "1/1 - 0s - loss: 0.5016 - accuracy: 0.7120 - val_loss: 1.0376 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 400/500\n",
            "1/1 - 0s - loss: 0.4996 - accuracy: 0.7600 - val_loss: 1.0419 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 401/500\n",
            "1/1 - 0s - loss: 0.5128 - accuracy: 0.7520 - val_loss: 1.0430 - val_accuracy: 0.4603 - 40ms/epoch - 40ms/step\n",
            "Epoch 402/500\n",
            "1/1 - 0s - loss: 0.4946 - accuracy: 0.7480 - val_loss: 1.0398 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 403/500\n",
            "1/1 - 0s - loss: 0.4990 - accuracy: 0.7320 - val_loss: 1.0368 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 404/500\n",
            "1/1 - 0s - loss: 0.5276 - accuracy: 0.7120 - val_loss: 1.0301 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 405/500\n",
            "1/1 - 0s - loss: 0.5043 - accuracy: 0.7320 - val_loss: 1.0223 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 406/500\n",
            "1/1 - 0s - loss: 0.4856 - accuracy: 0.7600 - val_loss: 1.0169 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 407/500\n",
            "1/1 - 0s - loss: 0.5054 - accuracy: 0.7560 - val_loss: 1.0139 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 408/500\n",
            "1/1 - 0s - loss: 0.5034 - accuracy: 0.7400 - val_loss: 1.0146 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 409/500\n",
            "1/1 - 0s - loss: 0.5213 - accuracy: 0.7480 - val_loss: 1.0166 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 410/500\n",
            "1/1 - 0s - loss: 0.5247 - accuracy: 0.7160 - val_loss: 1.0204 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 411/500\n",
            "1/1 - 0s - loss: 0.5174 - accuracy: 0.7240 - val_loss: 1.0269 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 412/500\n",
            "1/1 - 0s - loss: 0.5259 - accuracy: 0.7040 - val_loss: 1.0353 - val_accuracy: 0.4603 - 31ms/epoch - 31ms/step\n",
            "Epoch 413/500\n",
            "1/1 - 0s - loss: 0.5072 - accuracy: 0.7360 - val_loss: 1.0412 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 414/500\n",
            "1/1 - 0s - loss: 0.5158 - accuracy: 0.7360 - val_loss: 1.0430 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 415/500\n",
            "1/1 - 0s - loss: 0.4985 - accuracy: 0.7560 - val_loss: 1.0434 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 416/500\n",
            "1/1 - 0s - loss: 0.5071 - accuracy: 0.7520 - val_loss: 1.0460 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 417/500\n",
            "1/1 - 0s - loss: 0.4863 - accuracy: 0.7680 - val_loss: 1.0506 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 418/500\n",
            "1/1 - 0s - loss: 0.5161 - accuracy: 0.7360 - val_loss: 1.0547 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 419/500\n",
            "1/1 - 0s - loss: 0.4921 - accuracy: 0.7680 - val_loss: 1.0562 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 420/500\n",
            "1/1 - 0s - loss: 0.4983 - accuracy: 0.7760 - val_loss: 1.0546 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 421/500\n",
            "1/1 - 0s - loss: 0.5092 - accuracy: 0.7280 - val_loss: 1.0531 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 422/500\n",
            "1/1 - 0s - loss: 0.5195 - accuracy: 0.7280 - val_loss: 1.0508 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 423/500\n",
            "1/1 - 0s - loss: 0.4866 - accuracy: 0.7520 - val_loss: 1.0490 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 424/500\n",
            "1/1 - 0s - loss: 0.5161 - accuracy: 0.7280 - val_loss: 1.0482 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 425/500\n",
            "1/1 - 0s - loss: 0.4924 - accuracy: 0.7640 - val_loss: 1.0471 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 426/500\n",
            "1/1 - 0s - loss: 0.4858 - accuracy: 0.7560 - val_loss: 1.0460 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 427/500\n",
            "1/1 - 0s - loss: 0.5056 - accuracy: 0.7200 - val_loss: 1.0452 - val_accuracy: 0.4921 - 36ms/epoch - 36ms/step\n",
            "Epoch 428/500\n",
            "1/1 - 0s - loss: 0.5019 - accuracy: 0.7600 - val_loss: 1.0476 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 429/500\n",
            "1/1 - 0s - loss: 0.5078 - accuracy: 0.7440 - val_loss: 1.0518 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 430/500\n",
            "1/1 - 0s - loss: 0.4991 - accuracy: 0.7400 - val_loss: 1.0578 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 431/500\n",
            "1/1 - 0s - loss: 0.4764 - accuracy: 0.7640 - val_loss: 1.0625 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 432/500\n",
            "1/1 - 0s - loss: 0.4858 - accuracy: 0.7560 - val_loss: 1.0675 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 433/500\n",
            "1/1 - 0s - loss: 0.4927 - accuracy: 0.7440 - val_loss: 1.0769 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 434/500\n",
            "1/1 - 0s - loss: 0.5021 - accuracy: 0.7280 - val_loss: 1.0826 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 435/500\n",
            "1/1 - 0s - loss: 0.4708 - accuracy: 0.7640 - val_loss: 1.0875 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 436/500\n",
            "1/1 - 0s - loss: 0.4853 - accuracy: 0.7600 - val_loss: 1.0905 - val_accuracy: 0.4762 - 29ms/epoch - 29ms/step\n",
            "Epoch 437/500\n",
            "1/1 - 0s - loss: 0.5109 - accuracy: 0.7040 - val_loss: 1.0913 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 438/500\n",
            "1/1 - 0s - loss: 0.5090 - accuracy: 0.7240 - val_loss: 1.0900 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 439/500\n",
            "1/1 - 0s - loss: 0.4904 - accuracy: 0.7320 - val_loss: 1.0868 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 440/500\n",
            "1/1 - 0s - loss: 0.4983 - accuracy: 0.7440 - val_loss: 1.0826 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 441/500\n",
            "1/1 - 0s - loss: 0.5006 - accuracy: 0.7520 - val_loss: 1.0813 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 442/500\n",
            "1/1 - 0s - loss: 0.4867 - accuracy: 0.7800 - val_loss: 1.0806 - val_accuracy: 0.4762 - 34ms/epoch - 34ms/step\n",
            "Epoch 443/500\n",
            "1/1 - 0s - loss: 0.4934 - accuracy: 0.7600 - val_loss: 1.0832 - val_accuracy: 0.4762 - 31ms/epoch - 31ms/step\n",
            "Epoch 444/500\n",
            "1/1 - 0s - loss: 0.4802 - accuracy: 0.7360 - val_loss: 1.0850 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 445/500\n",
            "1/1 - 0s - loss: 0.4936 - accuracy: 0.7280 - val_loss: 1.0841 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 446/500\n",
            "1/1 - 0s - loss: 0.4842 - accuracy: 0.7720 - val_loss: 1.0821 - val_accuracy: 0.4921 - 27ms/epoch - 27ms/step\n",
            "Epoch 447/500\n",
            "1/1 - 0s - loss: 0.5021 - accuracy: 0.7520 - val_loss: 1.0822 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 448/500\n",
            "1/1 - 0s - loss: 0.4875 - accuracy: 0.7480 - val_loss: 1.0825 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 449/500\n",
            "1/1 - 0s - loss: 0.4856 - accuracy: 0.7560 - val_loss: 1.0815 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 450/500\n",
            "1/1 - 0s - loss: 0.5021 - accuracy: 0.7640 - val_loss: 1.0795 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 451/500\n",
            "1/1 - 0s - loss: 0.4835 - accuracy: 0.7560 - val_loss: 1.0775 - val_accuracy: 0.4921 - 34ms/epoch - 34ms/step\n",
            "Epoch 452/500\n",
            "1/1 - 0s - loss: 0.4837 - accuracy: 0.7480 - val_loss: 1.0775 - val_accuracy: 0.5079 - 33ms/epoch - 33ms/step\n",
            "Epoch 453/500\n",
            "1/1 - 0s - loss: 0.4919 - accuracy: 0.7760 - val_loss: 1.0780 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 454/500\n",
            "1/1 - 0s - loss: 0.5126 - accuracy: 0.7200 - val_loss: 1.0844 - val_accuracy: 0.5079 - 31ms/epoch - 31ms/step\n",
            "Epoch 455/500\n",
            "1/1 - 0s - loss: 0.4756 - accuracy: 0.7400 - val_loss: 1.0911 - val_accuracy: 0.4921 - 43ms/epoch - 43ms/step\n",
            "Epoch 456/500\n",
            "1/1 - 0s - loss: 0.4969 - accuracy: 0.7400 - val_loss: 1.0993 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 457/500\n",
            "1/1 - 0s - loss: 0.4804 - accuracy: 0.7600 - val_loss: 1.1075 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 458/500\n",
            "1/1 - 0s - loss: 0.4804 - accuracy: 0.7840 - val_loss: 1.1131 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 459/500\n",
            "1/1 - 0s - loss: 0.5077 - accuracy: 0.7560 - val_loss: 1.1170 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n",
            "Epoch 460/500\n",
            "1/1 - 0s - loss: 0.4757 - accuracy: 0.7600 - val_loss: 1.1176 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 461/500\n",
            "1/1 - 0s - loss: 0.4925 - accuracy: 0.7360 - val_loss: 1.1162 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 462/500\n",
            "1/1 - 0s - loss: 0.4590 - accuracy: 0.8000 - val_loss: 1.1150 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 463/500\n",
            "1/1 - 0s - loss: 0.5036 - accuracy: 0.7280 - val_loss: 1.1138 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 464/500\n",
            "1/1 - 0s - loss: 0.4990 - accuracy: 0.7320 - val_loss: 1.1107 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 465/500\n",
            "1/1 - 0s - loss: 0.4966 - accuracy: 0.7480 - val_loss: 1.1055 - val_accuracy: 0.4921 - 34ms/epoch - 34ms/step\n",
            "Epoch 466/500\n",
            "1/1 - 0s - loss: 0.4813 - accuracy: 0.7640 - val_loss: 1.0999 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 467/500\n",
            "1/1 - 0s - loss: 0.4761 - accuracy: 0.7800 - val_loss: 1.0971 - val_accuracy: 0.4921 - 29ms/epoch - 29ms/step\n",
            "Epoch 468/500\n",
            "1/1 - 0s - loss: 0.4686 - accuracy: 0.7840 - val_loss: 1.0939 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 469/500\n",
            "1/1 - 0s - loss: 0.4965 - accuracy: 0.7440 - val_loss: 1.0898 - val_accuracy: 0.5079 - 36ms/epoch - 36ms/step\n",
            "Epoch 470/500\n",
            "1/1 - 0s - loss: 0.4784 - accuracy: 0.7560 - val_loss: 1.0882 - val_accuracy: 0.5079 - 32ms/epoch - 32ms/step\n",
            "Epoch 471/500\n",
            "1/1 - 0s - loss: 0.4978 - accuracy: 0.7560 - val_loss: 1.0884 - val_accuracy: 0.5079 - 33ms/epoch - 33ms/step\n",
            "Epoch 472/500\n",
            "1/1 - 0s - loss: 0.4667 - accuracy: 0.7880 - val_loss: 1.0929 - val_accuracy: 0.5079 - 34ms/epoch - 34ms/step\n",
            "Epoch 473/500\n",
            "1/1 - 0s - loss: 0.5098 - accuracy: 0.7280 - val_loss: 1.0970 - val_accuracy: 0.5079 - 35ms/epoch - 35ms/step\n",
            "Epoch 474/500\n",
            "1/1 - 0s - loss: 0.5031 - accuracy: 0.7640 - val_loss: 1.1006 - val_accuracy: 0.5079 - 29ms/epoch - 29ms/step\n",
            "Epoch 475/500\n",
            "1/1 - 0s - loss: 0.4801 - accuracy: 0.7360 - val_loss: 1.1061 - val_accuracy: 0.5079 - 32ms/epoch - 32ms/step\n",
            "Epoch 476/500\n",
            "1/1 - 0s - loss: 0.4839 - accuracy: 0.7640 - val_loss: 1.1119 - val_accuracy: 0.4921 - 37ms/epoch - 37ms/step\n",
            "Epoch 477/500\n",
            "1/1 - 0s - loss: 0.4889 - accuracy: 0.7400 - val_loss: 1.1176 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 478/500\n",
            "1/1 - 0s - loss: 0.4800 - accuracy: 0.7480 - val_loss: 1.1278 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 479/500\n",
            "1/1 - 0s - loss: 0.4839 - accuracy: 0.7960 - val_loss: 1.1351 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 480/500\n",
            "1/1 - 0s - loss: 0.4755 - accuracy: 0.7840 - val_loss: 1.1403 - val_accuracy: 0.4921 - 31ms/epoch - 31ms/step\n",
            "Epoch 481/500\n",
            "1/1 - 0s - loss: 0.4894 - accuracy: 0.7480 - val_loss: 1.1377 - val_accuracy: 0.4921 - 30ms/epoch - 30ms/step\n",
            "Epoch 482/500\n",
            "1/1 - 0s - loss: 0.4822 - accuracy: 0.7480 - val_loss: 1.1311 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 483/500\n",
            "1/1 - 0s - loss: 0.4830 - accuracy: 0.7720 - val_loss: 1.1271 - val_accuracy: 0.5079 - 35ms/epoch - 35ms/step\n",
            "Epoch 484/500\n",
            "1/1 - 0s - loss: 0.4670 - accuracy: 0.7760 - val_loss: 1.1234 - val_accuracy: 0.5079 - 32ms/epoch - 32ms/step\n",
            "Epoch 485/500\n",
            "1/1 - 0s - loss: 0.4810 - accuracy: 0.7600 - val_loss: 1.1205 - val_accuracy: 0.5079 - 33ms/epoch - 33ms/step\n",
            "Epoch 486/500\n",
            "1/1 - 0s - loss: 0.4680 - accuracy: 0.7600 - val_loss: 1.1156 - val_accuracy: 0.5079 - 30ms/epoch - 30ms/step\n",
            "Epoch 487/500\n",
            "1/1 - 0s - loss: 0.4876 - accuracy: 0.7680 - val_loss: 1.1116 - val_accuracy: 0.5079 - 28ms/epoch - 28ms/step\n",
            "Epoch 488/500\n",
            "1/1 - 0s - loss: 0.5111 - accuracy: 0.7200 - val_loss: 1.1072 - val_accuracy: 0.4921 - 35ms/epoch - 35ms/step\n",
            "Epoch 489/500\n",
            "1/1 - 0s - loss: 0.4994 - accuracy: 0.7240 - val_loss: 1.1055 - val_accuracy: 0.4921 - 33ms/epoch - 33ms/step\n",
            "Epoch 490/500\n",
            "1/1 - 0s - loss: 0.4760 - accuracy: 0.7520 - val_loss: 1.1053 - val_accuracy: 0.4921 - 28ms/epoch - 28ms/step\n",
            "Epoch 491/500\n",
            "1/1 - 0s - loss: 0.4661 - accuracy: 0.7800 - val_loss: 1.1093 - val_accuracy: 0.4762 - 36ms/epoch - 36ms/step\n",
            "Epoch 492/500\n",
            "1/1 - 0s - loss: 0.4855 - accuracy: 0.7520 - val_loss: 1.1147 - val_accuracy: 0.4921 - 32ms/epoch - 32ms/step\n",
            "Epoch 493/500\n",
            "1/1 - 0s - loss: 0.4630 - accuracy: 0.7600 - val_loss: 1.1195 - val_accuracy: 0.5079 - 51ms/epoch - 51ms/step\n",
            "Epoch 494/500\n",
            "1/1 - 0s - loss: 0.4877 - accuracy: 0.7560 - val_loss: 1.1247 - val_accuracy: 0.5079 - 32ms/epoch - 32ms/step\n",
            "Epoch 495/500\n",
            "1/1 - 0s - loss: 0.4717 - accuracy: 0.7840 - val_loss: 1.1284 - val_accuracy: 0.4762 - 32ms/epoch - 32ms/step\n",
            "Epoch 496/500\n",
            "1/1 - 0s - loss: 0.4857 - accuracy: 0.7640 - val_loss: 1.1350 - val_accuracy: 0.4762 - 35ms/epoch - 35ms/step\n",
            "Epoch 497/500\n",
            "1/1 - 0s - loss: 0.4928 - accuracy: 0.7720 - val_loss: 1.1409 - val_accuracy: 0.4762 - 39ms/epoch - 39ms/step\n",
            "Epoch 498/500\n",
            "1/1 - 0s - loss: 0.4606 - accuracy: 0.7720 - val_loss: 1.1457 - val_accuracy: 0.4762 - 30ms/epoch - 30ms/step\n",
            "Epoch 499/500\n",
            "1/1 - 0s - loss: 0.4685 - accuracy: 0.7760 - val_loss: 1.1492 - val_accuracy: 0.4762 - 33ms/epoch - 33ms/step\n",
            "Epoch 500/500\n",
            "1/1 - 0s - loss: 0.4878 - accuracy: 0.7360 - val_loss: 1.1540 - val_accuracy: 0.4762 - 28ms/epoch - 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc977a1b4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#myPredict = model.predict_classes( X_test).astype('int64')\n",
        "myPredict=model.predict(X_test).astype('int64') \n",
        "classes_x=np.argmax(myPredict,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFteMboknXEI",
        "outputId": "0dcd0233-6604-4e3c-bc7d-f87a6465af1c"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnctAHNo510",
        "outputId": "e054c521-8823-4ed4-cf5e-f83a0dfff5df"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5696\n",
            "score [1.0248225927352905, 0.5696202516555786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(y_test.nonzero()[1:])\n",
        "print(myPredict,'\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-dU9M6LpNqb",
        "outputId": "79467327-d5c6-45cf-c9a4-371e241ebae3"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]] \n",
            " [[0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1\n",
            "  1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0\n",
            "  0 0 0 1 1 0 0]]\n"
          ]
        }
      ]
    }
  ]
}