{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220814 2230.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeYf/6LBa6hDPJEeQEsrC/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TaylorShiehUSI/Github-Colab-test/blob/main/20220814_2230.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% reset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2k8nXyuRd_S",
        "outputId": "db52d3a5-14c5-494e-989d-f0c7acf810b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cviUbaTWRSko"
      },
      "outputs": [],
      "source": [
        "# 下載資料套件\n",
        "import requests as r\n",
        "\n",
        "# 資料處理套件\n",
        "from lxml import etree\n",
        "import json\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n",
        "# 財經套件\n",
        "# import yfinance as yf\n",
        "\n",
        "# 畫圖套件\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tw_stock_data(start_year, start_month, end_year, end_month, stock_code):\n",
        "    start_date = str(date(start_year, start_month, 1))\n",
        "    end_date = str(date(end_year, end_month, 1))\n",
        "    month_list = pd.date_range(start_date, end_date, freq='MS').strftime(\"%Y%m%d\").tolist()\n",
        "    \n",
        "    df = pd.DataFrame()\n",
        "    for month in month_list:\n",
        "        url = \"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date=\"+ month + \"&stockNo=\" + str(stock_code)\n",
        "        res = r.get(url)\n",
        "        stock_json = res.json()\n",
        "        stock_df = pd.DataFrame.from_dict(stock_json['data'])\n",
        "        df = df.append(stock_df, ignore_index = True)\n",
        "        \n",
        "    # 資料轉型\n",
        "    for col in [0, 1, 2, 3, 4, 5, 6, 8]:\n",
        "        for row in range(df.shape[0]):\n",
        "            # 把\"日期\"從字串(string)換成時間(datetime)，並將民國年換成西元年\n",
        "            if col == 0:\n",
        "                day = df.iloc[row,0].split('/')\n",
        "                df.iloc[row, 0] = datetime(int(day[0]) + 1911, int(day[1]), int(day[2]))  \n",
        "            # 把\"開盤價\", \"最高價\", \"最低價\", \"收盤價\"帶有逗號的字串(string)換成浮點數(float) \n",
        "            elif col != 0:\n",
        "                df.iloc[row, col] = float(df.iloc[row,col].replace(',', ''))\n",
        "    \n",
        "    df.columns = ['日期', '成交股數', '成交金額', '開盤價', '最高價', '最低價', '收盤價', '漲跌價差', '成交筆數']\n",
        "    return df"
      ],
      "metadata": {
        "id": "6IuqlNYjRvxb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df = get_tw_stock_data(start_year = 2021, \n",
        "                start_month = 1, \n",
        "                end_year = 2022, \n",
        "                end_month = 8, \n",
        "                stock_code = 2330)\n",
        "stock_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tjxBWizKRyTK",
        "outputId": "2ac268f9-a029-4211-9afe-65c68be0acbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      日期        成交股數           成交金額    開盤價    最高價    最低價  \\\n",
              "0    2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0   \n",
              "1    2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0   \n",
              "2    2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0   \n",
              "3    2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0   \n",
              "4    2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0   \n",
              "..                   ...         ...            ...    ...    ...    ...   \n",
              "387  2022-08-08 00:00:00  20568971.0  10531710250.0  510.0  515.0  509.0   \n",
              "388  2022-08-09 00:00:00  24370709.0  12372442661.0  507.0  511.0  504.0   \n",
              "389  2022-08-10 00:00:00  22112239.0  11075581424.0  500.0  503.0  499.5   \n",
              "390  2022-08-11 00:00:00  24906177.0  12771121611.0  513.0  514.0  510.0   \n",
              "391  2022-08-12 00:00:00  21343450.0  11016097043.0  515.0  518.0  514.0   \n",
              "\n",
              "       收盤價    漲跌價差     成交筆數  \n",
              "0    536.0   +6.00  33316.0  \n",
              "1    542.0   +6.00  28512.0  \n",
              "2    549.0   +7.00  55462.0  \n",
              "3    565.0  +16.00  47905.0  \n",
              "4    580.0  +15.00  56426.0  \n",
              "..     ...     ...      ...  \n",
              "387  512.0   -4.00  18131.0  \n",
              "388  510.0   -2.00  25433.0  \n",
              "389  500.0  -10.00  35188.0  \n",
              "390  514.0  +14.00  23949.0  \n",
              "391  517.0   +3.00  21701.0  \n",
              "\n",
              "[392 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3bc79f0-cee8-47c0-85f5-17f1f4c5f84b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>33316.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>+6.00</td>\n",
              "      <td>28512.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>+7.00</td>\n",
              "      <td>55462.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>+16.00</td>\n",
              "      <td>47905.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>+15.00</td>\n",
              "      <td>56426.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>2022-08-08 00:00:00</td>\n",
              "      <td>20568971.0</td>\n",
              "      <td>10531710250.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>509.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>-4.00</td>\n",
              "      <td>18131.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>2022-08-09 00:00:00</td>\n",
              "      <td>24370709.0</td>\n",
              "      <td>12372442661.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>511.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>-2.00</td>\n",
              "      <td>25433.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>2022-08-10 00:00:00</td>\n",
              "      <td>22112239.0</td>\n",
              "      <td>11075581424.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>503.0</td>\n",
              "      <td>499.5</td>\n",
              "      <td>500.0</td>\n",
              "      <td>-10.00</td>\n",
              "      <td>35188.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>2022-08-11 00:00:00</td>\n",
              "      <td>24906177.0</td>\n",
              "      <td>12771121611.0</td>\n",
              "      <td>513.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>+14.00</td>\n",
              "      <td>23949.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>2022-08-12 00:00:00</td>\n",
              "      <td>21343450.0</td>\n",
              "      <td>11016097043.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>518.0</td>\n",
              "      <td>514.0</td>\n",
              "      <td>517.0</td>\n",
              "      <td>+3.00</td>\n",
              "      <td>21701.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3bc79f0-cee8-47c0-85f5-17f1f4c5f84b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f3bc79f0-cee8-47c0-85f5-17f1f4c5f84b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f3bc79f0-cee8-47c0-85f5-17f1f4c5f84b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.to_csv('2230.csv',encoding='utf-8_sig')"
      ],
      "metadata": {
        "id": "aa45vys1Vefv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Processing // Add is_up\n",
        "import numpy as np\n",
        "\n",
        "stock_df['is_up'] = (stock_df['開盤價'].shift(-1) - stock_df['收盤價'] >0).astype('int')\n",
        "stock_df['高低差'] = (stock_df['最高價'] - stock_df['最低價']).astype('int')\n",
        "stock_df['漲跌價差'] = (stock_df['收盤價'] - stock_df['開盤價']).astype('int')\n",
        "stock_df['單筆股數'] = (stock_df['成交股數']/stock_df['成交筆數']).astype('int')\n",
        "\n",
        "def one_hot(targets, nb_classes):\n",
        "    return np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "y_data = one_hot(stock_df['is_up'], 2)\n",
        "stock_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s28R2AUsYOgW",
        "outputId": "0697e888-b507-45d0-87e2-f07d52b77ac1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    日期        成交股數           成交金額    開盤價    最高價    最低價    收盤價  \\\n",
              "0  2021-01-04 00:00:00  39489959.0  21127581248.0  530.0  540.0  528.0  536.0   \n",
              "1  2021-01-05 00:00:00  34839391.0  18761831567.0  536.0  542.0  535.0  542.0   \n",
              "2  2021-01-06 00:00:00  55614434.0  30572783229.0  555.0  555.0  541.0  549.0   \n",
              "3  2021-01-07 00:00:00  53392763.0  30018630685.0  554.0  570.0  553.0  565.0   \n",
              "4  2021-01-08 00:00:00  62957148.0  36339702855.0  580.0  580.0  571.0  580.0   \n",
              "\n",
              "   漲跌價差     成交筆數  is_up  高低差  單筆股數  \n",
              "0     6  33316.0      0   12  1185  \n",
              "1     6  28512.0      1    7  1221  \n",
              "2    -6  55462.0      1   14  1002  \n",
              "3    11  47905.0      1   17  1114  \n",
              "4     0  56426.0      0    9  1115  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-060b6fb0-7993-4f8d-80ca-2eedea4efb6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>日期</th>\n",
              "      <th>成交股數</th>\n",
              "      <th>成交金額</th>\n",
              "      <th>開盤價</th>\n",
              "      <th>最高價</th>\n",
              "      <th>最低價</th>\n",
              "      <th>收盤價</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>is_up</th>\n",
              "      <th>高低差</th>\n",
              "      <th>單筆股數</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-04 00:00:00</td>\n",
              "      <td>39489959.0</td>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>540.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>6</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-05 00:00:00</td>\n",
              "      <td>34839391.0</td>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>535.0</td>\n",
              "      <td>542.0</td>\n",
              "      <td>6</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-06 00:00:00</td>\n",
              "      <td>55614434.0</td>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>555.0</td>\n",
              "      <td>541.0</td>\n",
              "      <td>549.0</td>\n",
              "      <td>-6</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-07 00:00:00</td>\n",
              "      <td>53392763.0</td>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>554.0</td>\n",
              "      <td>570.0</td>\n",
              "      <td>553.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>11</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-08 00:00:00</td>\n",
              "      <td>62957148.0</td>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>571.0</td>\n",
              "      <td>580.0</td>\n",
              "      <td>0</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-060b6fb0-7993-4f8d-80ca-2eedea4efb6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-060b6fb0-7993-4f8d-80ca-2eedea4efb6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-060b6fb0-7993-4f8d-80ca-2eedea4efb6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare Feature Data\n",
        "X_data = stock_df.drop(['日期','成交股數','開盤價','最高價','最低價','收盤價','is_up','單筆股數'], axis=1)\n",
        "X_data.head()\n",
        "#X_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U6L5IslyY-A0",
        "outputId": "d864fdab-1fbb-44d0-94b8-1f99f905cbfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            成交金額  漲跌價差     成交筆數  高低差\n",
              "0  21127581248.0     6  33316.0   12\n",
              "1  18761831567.0     6  28512.0    7\n",
              "2  30572783229.0    -6  55462.0   14\n",
              "3  30018630685.0    11  47905.0   17\n",
              "4  36339702855.0     0  56426.0    9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a5350e9-2e43-436e-82e1-2f1adc5b1fdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>高低差</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21127581248.0</td>\n",
              "      <td>6</td>\n",
              "      <td>33316.0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18761831567.0</td>\n",
              "      <td>6</td>\n",
              "      <td>28512.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30572783229.0</td>\n",
              "      <td>-6</td>\n",
              "      <td>55462.0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30018630685.0</td>\n",
              "      <td>11</td>\n",
              "      <td>47905.0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36339702855.0</td>\n",
              "      <td>0</td>\n",
              "      <td>56426.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a5350e9-2e43-436e-82e1-2f1adc5b1fdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a5350e9-2e43-436e-82e1-2f1adc5b1fdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a5350e9-2e43-436e-82e1-2f1adc5b1fdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Normalized\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_data)\n",
        "scaled = scaler.fit_transform(X_data)\n",
        "X_data = pd.DataFrame(scaled, columns=X_data.columns)\n",
        "#print(X_data)\n",
        "X_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WeNiJCBNQ3x9",
        "outputId": "011bfdc9-43e5-4b1a-a85d-d50052c15fed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       成交金額      漲跌價差      成交筆數       高低差\n",
              "0 -0.079254  1.012010 -0.383994  0.611423\n",
              "1 -0.255043  1.012010 -0.492146 -0.390574\n",
              "2  0.622583 -0.899835  0.114573  1.012221\n",
              "3  0.581406  1.808611 -0.055556  1.613419\n",
              "4  1.051100  0.056087  0.136275  0.010224"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f1f3fcb-5ea8-48a6-91a3-dd081e2f672a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>成交金額</th>\n",
              "      <th>漲跌價差</th>\n",
              "      <th>成交筆數</th>\n",
              "      <th>高低差</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.079254</td>\n",
              "      <td>1.012010</td>\n",
              "      <td>-0.383994</td>\n",
              "      <td>0.611423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.255043</td>\n",
              "      <td>1.012010</td>\n",
              "      <td>-0.492146</td>\n",
              "      <td>-0.390574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.622583</td>\n",
              "      <td>-0.899835</td>\n",
              "      <td>0.114573</td>\n",
              "      <td>1.012221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.581406</td>\n",
              "      <td>1.808611</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>1.613419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.051100</td>\n",
              "      <td>0.056087</td>\n",
              "      <td>0.136275</td>\n",
              "      <td>0.010224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f1f3fcb-5ea8-48a6-91a3-dd081e2f672a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f1f3fcb-5ea8-48a6-91a3-dd081e2f672a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f1f3fcb-5ea8-48a6-91a3-dd081e2f672a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model, with preparing the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "X_train = K.cast_to_floatx(X_train)\n",
        "y_train = K.cast_to_floatx(y_train)\n",
        "X_test = K.cast_to_floatx(X_test)\n",
        "y_test = K.cast_to_floatx(y_test)"
      ],
      "metadata": {
        "id": "dSxbm6ltjPHa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot( stock_df['收盤價'], '--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2M7fNrNijimi",
        "outputId": "523de206-ce8a-4b20-b063-f9be6a678c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n"
      ],
      "metadata": {
        "id": "G_DulbtRjrdy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set up model, and print the model summary\n",
        "model = Sequential()\n",
        "model.add(Dense(units = 128,\n",
        "                input_shape=X_train.shape[1:],\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dense(units = 8,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='relu'))\n",
        "model.add(Dense(units = 2,\n",
        "                kernel_initializer = 'normal',\n",
        "                activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f98ijyGEjunx",
        "outputId": "a8085ac4-7be2-4a34-eeed-e68297f88a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               640       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 1032      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,762\n",
            "Trainable params: 1,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## train the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
        "model.fit(x = X_train,\n",
        "          y = y_train,\n",
        "          validation_split = 0.2,\n",
        "          batch_size=128,\n",
        "          epochs=600,\n",
        "          verbose = 2) "
      ],
      "metadata": {
        "id": "Kd8QlzjZkAG4",
        "outputId": "1bff30de-196f-41b9-dacf-0b2315fb34e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "2/2 - 1s - loss: 0.6932 - accuracy: 0.4680 - val_loss: 0.6931 - val_accuracy: 0.4921 - 1s/epoch - 613ms/step\n",
            "Epoch 2/600\n",
            "2/2 - 0s - loss: 0.6932 - accuracy: 0.5280 - val_loss: 0.6931 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 3/600\n",
            "2/2 - 0s - loss: 0.6931 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 4/600\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5079 - 52ms/epoch - 26ms/step\n",
            "Epoch 5/600\n",
            "2/2 - 0s - loss: 0.6930 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 6/600\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 7/600\n",
            "2/2 - 0s - loss: 0.6929 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 8/600\n",
            "2/2 - 0s - loss: 0.6928 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 9/600\n",
            "2/2 - 0s - loss: 0.6927 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 10/600\n",
            "2/2 - 0s - loss: 0.6926 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 39ms/epoch - 20ms/step\n",
            "Epoch 11/600\n",
            "2/2 - 0s - loss: 0.6926 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 12/600\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 13/600\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 14/600\n",
            "2/2 - 0s - loss: 0.6925 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 15/600\n",
            "2/2 - 0s - loss: 0.6924 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 16/600\n",
            "2/2 - 0s - loss: 0.6923 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 17/600\n",
            "2/2 - 0s - loss: 0.6922 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 39ms/epoch - 19ms/step\n",
            "Epoch 18/600\n",
            "2/2 - 0s - loss: 0.6922 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 19/600\n",
            "2/2 - 0s - loss: 0.6921 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 20/600\n",
            "2/2 - 0s - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5079 - 39ms/epoch - 19ms/step\n",
            "Epoch 21/600\n",
            "2/2 - 0s - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.4921 - 35ms/epoch - 18ms/step\n",
            "Epoch 22/600\n",
            "2/2 - 0s - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 23/600\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.4921 - 39ms/epoch - 19ms/step\n",
            "Epoch 24/600\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 25/600\n",
            "2/2 - 0s - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 26/600\n",
            "2/2 - 0s - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 27/600\n",
            "2/2 - 0s - loss: 0.6910 - accuracy: 0.5240 - val_loss: 0.6931 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 28/600\n",
            "2/2 - 0s - loss: 0.6909 - accuracy: 0.5240 - val_loss: 0.6931 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 29/600\n",
            "2/2 - 0s - loss: 0.6907 - accuracy: 0.5120 - val_loss: 0.6932 - val_accuracy: 0.5397 - 46ms/epoch - 23ms/step\n",
            "Epoch 30/600\n",
            "2/2 - 0s - loss: 0.6904 - accuracy: 0.5120 - val_loss: 0.6933 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 31/600\n",
            "2/2 - 0s - loss: 0.6901 - accuracy: 0.5280 - val_loss: 0.6933 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 32/600\n",
            "2/2 - 0s - loss: 0.6899 - accuracy: 0.5320 - val_loss: 0.6934 - val_accuracy: 0.5873 - 33ms/epoch - 17ms/step\n",
            "Epoch 33/600\n",
            "2/2 - 0s - loss: 0.6897 - accuracy: 0.5520 - val_loss: 0.6934 - val_accuracy: 0.5556 - 40ms/epoch - 20ms/step\n",
            "Epoch 34/600\n",
            "2/2 - 0s - loss: 0.6893 - accuracy: 0.5560 - val_loss: 0.6934 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 35/600\n",
            "2/2 - 0s - loss: 0.6889 - accuracy: 0.5600 - val_loss: 0.6935 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 36/600\n",
            "2/2 - 0s - loss: 0.6887 - accuracy: 0.5560 - val_loss: 0.6937 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 37/600\n",
            "2/2 - 0s - loss: 0.6879 - accuracy: 0.5640 - val_loss: 0.6938 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 38/600\n",
            "2/2 - 0s - loss: 0.6878 - accuracy: 0.5560 - val_loss: 0.6939 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 39/600\n",
            "2/2 - 0s - loss: 0.6871 - accuracy: 0.5600 - val_loss: 0.6940 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 40/600\n",
            "2/2 - 0s - loss: 0.6860 - accuracy: 0.5840 - val_loss: 0.6942 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 41/600\n",
            "2/2 - 0s - loss: 0.6864 - accuracy: 0.5640 - val_loss: 0.6945 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 42/600\n",
            "2/2 - 0s - loss: 0.6852 - accuracy: 0.5880 - val_loss: 0.6948 - val_accuracy: 0.5238 - 39ms/epoch - 19ms/step\n",
            "Epoch 43/600\n",
            "2/2 - 0s - loss: 0.6850 - accuracy: 0.5880 - val_loss: 0.6952 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 44/600\n",
            "2/2 - 0s - loss: 0.6834 - accuracy: 0.5920 - val_loss: 0.6956 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 45/600\n",
            "2/2 - 0s - loss: 0.6844 - accuracy: 0.5880 - val_loss: 0.6962 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 46/600\n",
            "2/2 - 0s - loss: 0.6833 - accuracy: 0.6000 - val_loss: 0.6969 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 47/600\n",
            "2/2 - 0s - loss: 0.6825 - accuracy: 0.5800 - val_loss: 0.6974 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 48/600\n",
            "2/2 - 0s - loss: 0.6815 - accuracy: 0.5800 - val_loss: 0.6979 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 49/600\n",
            "2/2 - 0s - loss: 0.6822 - accuracy: 0.6000 - val_loss: 0.6988 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 50/600\n",
            "2/2 - 0s - loss: 0.6796 - accuracy: 0.5880 - val_loss: 0.6997 - val_accuracy: 0.5079 - 42ms/epoch - 21ms/step\n",
            "Epoch 51/600\n",
            "2/2 - 0s - loss: 0.6795 - accuracy: 0.5840 - val_loss: 0.7009 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 52/600\n",
            "2/2 - 0s - loss: 0.6790 - accuracy: 0.5960 - val_loss: 0.7022 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 53/600\n",
            "2/2 - 0s - loss: 0.6790 - accuracy: 0.5840 - val_loss: 0.7030 - val_accuracy: 0.5079 - 47ms/epoch - 23ms/step\n",
            "Epoch 54/600\n",
            "2/2 - 0s - loss: 0.6788 - accuracy: 0.5800 - val_loss: 0.7035 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 55/600\n",
            "2/2 - 0s - loss: 0.6768 - accuracy: 0.5920 - val_loss: 0.7042 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 56/600\n",
            "2/2 - 0s - loss: 0.6759 - accuracy: 0.5880 - val_loss: 0.7051 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 57/600\n",
            "2/2 - 0s - loss: 0.6773 - accuracy: 0.5840 - val_loss: 0.7062 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 58/600\n",
            "2/2 - 0s - loss: 0.6760 - accuracy: 0.5920 - val_loss: 0.7071 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 59/600\n",
            "2/2 - 0s - loss: 0.6774 - accuracy: 0.5880 - val_loss: 0.7075 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 60/600\n",
            "2/2 - 0s - loss: 0.6764 - accuracy: 0.5800 - val_loss: 0.7084 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 61/600\n",
            "2/2 - 0s - loss: 0.6761 - accuracy: 0.5800 - val_loss: 0.7086 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 62/600\n",
            "2/2 - 0s - loss: 0.6760 - accuracy: 0.5920 - val_loss: 0.7088 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 63/600\n",
            "2/2 - 0s - loss: 0.6716 - accuracy: 0.5960 - val_loss: 0.7092 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 64/600\n",
            "2/2 - 0s - loss: 0.6742 - accuracy: 0.6080 - val_loss: 0.7094 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 65/600\n",
            "2/2 - 0s - loss: 0.6742 - accuracy: 0.5800 - val_loss: 0.7099 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 66/600\n",
            "2/2 - 0s - loss: 0.6692 - accuracy: 0.6000 - val_loss: 0.7094 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 67/600\n",
            "2/2 - 0s - loss: 0.6717 - accuracy: 0.5960 - val_loss: 0.7098 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 68/600\n",
            "2/2 - 0s - loss: 0.6717 - accuracy: 0.5960 - val_loss: 0.7097 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 69/600\n",
            "2/2 - 0s - loss: 0.6711 - accuracy: 0.5840 - val_loss: 0.7101 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 70/600\n",
            "2/2 - 0s - loss: 0.6728 - accuracy: 0.5880 - val_loss: 0.7106 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 71/600\n",
            "2/2 - 0s - loss: 0.6704 - accuracy: 0.5760 - val_loss: 0.7111 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 72/600\n",
            "2/2 - 0s - loss: 0.6695 - accuracy: 0.6000 - val_loss: 0.7113 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 73/600\n",
            "2/2 - 0s - loss: 0.6705 - accuracy: 0.5840 - val_loss: 0.7117 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 74/600\n",
            "2/2 - 0s - loss: 0.6657 - accuracy: 0.5920 - val_loss: 0.7124 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 75/600\n",
            "2/2 - 0s - loss: 0.6735 - accuracy: 0.5800 - val_loss: 0.7136 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 76/600\n",
            "2/2 - 0s - loss: 0.6686 - accuracy: 0.5800 - val_loss: 0.7134 - val_accuracy: 0.5238 - 37ms/epoch - 19ms/step\n",
            "Epoch 77/600\n",
            "2/2 - 0s - loss: 0.6686 - accuracy: 0.5800 - val_loss: 0.7139 - val_accuracy: 0.5238 - 31ms/epoch - 16ms/step\n",
            "Epoch 78/600\n",
            "2/2 - 0s - loss: 0.6667 - accuracy: 0.5880 - val_loss: 0.7140 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 79/600\n",
            "2/2 - 0s - loss: 0.6670 - accuracy: 0.6080 - val_loss: 0.7137 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 80/600\n",
            "2/2 - 0s - loss: 0.6687 - accuracy: 0.6000 - val_loss: 0.7129 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 81/600\n",
            "2/2 - 0s - loss: 0.6681 - accuracy: 0.6000 - val_loss: 0.7115 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 82/600\n",
            "2/2 - 0s - loss: 0.6712 - accuracy: 0.5920 - val_loss: 0.7107 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 83/600\n",
            "2/2 - 0s - loss: 0.6663 - accuracy: 0.5840 - val_loss: 0.7100 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 84/600\n",
            "2/2 - 0s - loss: 0.6640 - accuracy: 0.5960 - val_loss: 0.7102 - val_accuracy: 0.4921 - 41ms/epoch - 20ms/step\n",
            "Epoch 85/600\n",
            "2/2 - 0s - loss: 0.6671 - accuracy: 0.6120 - val_loss: 0.7107 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 86/600\n",
            "2/2 - 0s - loss: 0.6672 - accuracy: 0.5960 - val_loss: 0.7109 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 87/600\n",
            "2/2 - 0s - loss: 0.6641 - accuracy: 0.6120 - val_loss: 0.7114 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 88/600\n",
            "2/2 - 0s - loss: 0.6653 - accuracy: 0.6000 - val_loss: 0.7115 - val_accuracy: 0.5238 - 31ms/epoch - 15ms/step\n",
            "Epoch 89/600\n",
            "2/2 - 0s - loss: 0.6676 - accuracy: 0.5960 - val_loss: 0.7111 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 90/600\n",
            "2/2 - 0s - loss: 0.6648 - accuracy: 0.5920 - val_loss: 0.7110 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 91/600\n",
            "2/2 - 0s - loss: 0.6596 - accuracy: 0.6120 - val_loss: 0.7110 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 92/600\n",
            "2/2 - 0s - loss: 0.6617 - accuracy: 0.5960 - val_loss: 0.7102 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 93/600\n",
            "2/2 - 0s - loss: 0.6626 - accuracy: 0.6120 - val_loss: 0.7090 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 94/600\n",
            "2/2 - 0s - loss: 0.6631 - accuracy: 0.6040 - val_loss: 0.7084 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 95/600\n",
            "2/2 - 0s - loss: 0.6644 - accuracy: 0.6040 - val_loss: 0.7082 - val_accuracy: 0.5397 - 35ms/epoch - 18ms/step\n",
            "Epoch 96/600\n",
            "2/2 - 0s - loss: 0.6637 - accuracy: 0.6120 - val_loss: 0.7080 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 97/600\n",
            "2/2 - 0s - loss: 0.6530 - accuracy: 0.6400 - val_loss: 0.7078 - val_accuracy: 0.5556 - 37ms/epoch - 18ms/step\n",
            "Epoch 98/600\n",
            "2/2 - 0s - loss: 0.6545 - accuracy: 0.6200 - val_loss: 0.7077 - val_accuracy: 0.5556 - 42ms/epoch - 21ms/step\n",
            "Epoch 99/600\n",
            "2/2 - 0s - loss: 0.6553 - accuracy: 0.6120 - val_loss: 0.7078 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 100/600\n",
            "2/2 - 0s - loss: 0.6604 - accuracy: 0.6280 - val_loss: 0.7086 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 101/600\n",
            "2/2 - 0s - loss: 0.6595 - accuracy: 0.6400 - val_loss: 0.7087 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 102/600\n",
            "2/2 - 0s - loss: 0.6541 - accuracy: 0.6280 - val_loss: 0.7089 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 103/600\n",
            "2/2 - 0s - loss: 0.6635 - accuracy: 0.6200 - val_loss: 0.7087 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 104/600\n",
            "2/2 - 0s - loss: 0.6634 - accuracy: 0.6080 - val_loss: 0.7083 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 105/600\n",
            "2/2 - 0s - loss: 0.6580 - accuracy: 0.6400 - val_loss: 0.7081 - val_accuracy: 0.5397 - 40ms/epoch - 20ms/step\n",
            "Epoch 106/600\n",
            "2/2 - 0s - loss: 0.6525 - accuracy: 0.6280 - val_loss: 0.7082 - val_accuracy: 0.5556 - 31ms/epoch - 16ms/step\n",
            "Epoch 107/600\n",
            "2/2 - 0s - loss: 0.6558 - accuracy: 0.6200 - val_loss: 0.7084 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 108/600\n",
            "2/2 - 0s - loss: 0.6607 - accuracy: 0.6080 - val_loss: 0.7083 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 109/600\n",
            "2/2 - 0s - loss: 0.6555 - accuracy: 0.6040 - val_loss: 0.7086 - val_accuracy: 0.5556 - 37ms/epoch - 19ms/step\n",
            "Epoch 110/600\n",
            "2/2 - 0s - loss: 0.6562 - accuracy: 0.6160 - val_loss: 0.7089 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 111/600\n",
            "2/2 - 0s - loss: 0.6631 - accuracy: 0.6160 - val_loss: 0.7091 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 112/600\n",
            "2/2 - 0s - loss: 0.6561 - accuracy: 0.6240 - val_loss: 0.7090 - val_accuracy: 0.5556 - 43ms/epoch - 22ms/step\n",
            "Epoch 113/600\n",
            "2/2 - 0s - loss: 0.6508 - accuracy: 0.6320 - val_loss: 0.7088 - val_accuracy: 0.5556 - 31ms/epoch - 15ms/step\n",
            "Epoch 114/600\n",
            "2/2 - 0s - loss: 0.6531 - accuracy: 0.6200 - val_loss: 0.7089 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 115/600\n",
            "2/2 - 0s - loss: 0.6502 - accuracy: 0.6360 - val_loss: 0.7083 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 116/600\n",
            "2/2 - 0s - loss: 0.6509 - accuracy: 0.6360 - val_loss: 0.7083 - val_accuracy: 0.5556 - 33ms/epoch - 17ms/step\n",
            "Epoch 117/600\n",
            "2/2 - 0s - loss: 0.6549 - accuracy: 0.6280 - val_loss: 0.7082 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 118/600\n",
            "2/2 - 0s - loss: 0.6554 - accuracy: 0.6240 - val_loss: 0.7080 - val_accuracy: 0.5556 - 33ms/epoch - 16ms/step\n",
            "Epoch 119/600\n",
            "2/2 - 0s - loss: 0.6480 - accuracy: 0.6360 - val_loss: 0.7083 - val_accuracy: 0.5556 - 33ms/epoch - 16ms/step\n",
            "Epoch 120/600\n",
            "2/2 - 0s - loss: 0.6513 - accuracy: 0.6160 - val_loss: 0.7086 - val_accuracy: 0.5556 - 39ms/epoch - 19ms/step\n",
            "Epoch 121/600\n",
            "2/2 - 0s - loss: 0.6555 - accuracy: 0.6360 - val_loss: 0.7095 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 122/600\n",
            "2/2 - 0s - loss: 0.6461 - accuracy: 0.6400 - val_loss: 0.7099 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 123/600\n",
            "2/2 - 0s - loss: 0.6518 - accuracy: 0.6280 - val_loss: 0.7102 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 124/600\n",
            "2/2 - 0s - loss: 0.6529 - accuracy: 0.6200 - val_loss: 0.7107 - val_accuracy: 0.5556 - 37ms/epoch - 19ms/step\n",
            "Epoch 125/600\n",
            "2/2 - 0s - loss: 0.6467 - accuracy: 0.6320 - val_loss: 0.7107 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 126/600\n",
            "2/2 - 0s - loss: 0.6490 - accuracy: 0.6120 - val_loss: 0.7108 - val_accuracy: 0.5556 - 37ms/epoch - 18ms/step\n",
            "Epoch 127/600\n",
            "2/2 - 0s - loss: 0.6488 - accuracy: 0.6320 - val_loss: 0.7100 - val_accuracy: 0.5556 - 38ms/epoch - 19ms/step\n",
            "Epoch 128/600\n",
            "2/2 - 0s - loss: 0.6481 - accuracy: 0.6440 - val_loss: 0.7092 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 129/600\n",
            "2/2 - 0s - loss: 0.6540 - accuracy: 0.6080 - val_loss: 0.7082 - val_accuracy: 0.5556 - 37ms/epoch - 19ms/step\n",
            "Epoch 130/600\n",
            "2/2 - 0s - loss: 0.6532 - accuracy: 0.6240 - val_loss: 0.7073 - val_accuracy: 0.5556 - 41ms/epoch - 20ms/step\n",
            "Epoch 131/600\n",
            "2/2 - 0s - loss: 0.6497 - accuracy: 0.6440 - val_loss: 0.7067 - val_accuracy: 0.5556 - 33ms/epoch - 17ms/step\n",
            "Epoch 132/600\n",
            "2/2 - 0s - loss: 0.6445 - accuracy: 0.6560 - val_loss: 0.7064 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 133/600\n",
            "2/2 - 0s - loss: 0.6561 - accuracy: 0.6360 - val_loss: 0.7058 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 134/600\n",
            "2/2 - 0s - loss: 0.6474 - accuracy: 0.6240 - val_loss: 0.7053 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 135/600\n",
            "2/2 - 0s - loss: 0.6468 - accuracy: 0.6320 - val_loss: 0.7051 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 136/600\n",
            "2/2 - 0s - loss: 0.6481 - accuracy: 0.6320 - val_loss: 0.7051 - val_accuracy: 0.5556 - 31ms/epoch - 16ms/step\n",
            "Epoch 137/600\n",
            "2/2 - 0s - loss: 0.6444 - accuracy: 0.6480 - val_loss: 0.7059 - val_accuracy: 0.5556 - 38ms/epoch - 19ms/step\n",
            "Epoch 138/600\n",
            "2/2 - 0s - loss: 0.6456 - accuracy: 0.6240 - val_loss: 0.7070 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 139/600\n",
            "2/2 - 0s - loss: 0.6467 - accuracy: 0.6440 - val_loss: 0.7077 - val_accuracy: 0.5556 - 54ms/epoch - 27ms/step\n",
            "Epoch 140/600\n",
            "2/2 - 0s - loss: 0.6464 - accuracy: 0.6320 - val_loss: 0.7076 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 141/600\n",
            "2/2 - 0s - loss: 0.6442 - accuracy: 0.6320 - val_loss: 0.7079 - val_accuracy: 0.5556 - 37ms/epoch - 18ms/step\n",
            "Epoch 142/600\n",
            "2/2 - 0s - loss: 0.6491 - accuracy: 0.6360 - val_loss: 0.7079 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 143/600\n",
            "2/2 - 0s - loss: 0.6493 - accuracy: 0.6240 - val_loss: 0.7077 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 144/600\n",
            "2/2 - 0s - loss: 0.6389 - accuracy: 0.6520 - val_loss: 0.7068 - val_accuracy: 0.5556 - 31ms/epoch - 15ms/step\n",
            "Epoch 145/600\n",
            "2/2 - 0s - loss: 0.6455 - accuracy: 0.6640 - val_loss: 0.7062 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 146/600\n",
            "2/2 - 0s - loss: 0.6455 - accuracy: 0.6560 - val_loss: 0.7055 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 147/600\n",
            "2/2 - 0s - loss: 0.6442 - accuracy: 0.6200 - val_loss: 0.7051 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 148/600\n",
            "2/2 - 0s - loss: 0.6461 - accuracy: 0.6280 - val_loss: 0.7044 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 149/600\n",
            "2/2 - 0s - loss: 0.6446 - accuracy: 0.6440 - val_loss: 0.7038 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 150/600\n",
            "2/2 - 0s - loss: 0.6469 - accuracy: 0.6400 - val_loss: 0.7038 - val_accuracy: 0.5238 - 48ms/epoch - 24ms/step\n",
            "Epoch 151/600\n",
            "2/2 - 0s - loss: 0.6447 - accuracy: 0.6120 - val_loss: 0.7028 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 152/600\n",
            "2/2 - 0s - loss: 0.6403 - accuracy: 0.6400 - val_loss: 0.7018 - val_accuracy: 0.5238 - 41ms/epoch - 20ms/step\n",
            "Epoch 153/600\n",
            "2/2 - 0s - loss: 0.6351 - accuracy: 0.6440 - val_loss: 0.7021 - val_accuracy: 0.5238 - 37ms/epoch - 18ms/step\n",
            "Epoch 154/600\n",
            "2/2 - 0s - loss: 0.6456 - accuracy: 0.6360 - val_loss: 0.7025 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 155/600\n",
            "2/2 - 0s - loss: 0.6359 - accuracy: 0.6320 - val_loss: 0.7038 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 156/600\n",
            "2/2 - 0s - loss: 0.6410 - accuracy: 0.6440 - val_loss: 0.7050 - val_accuracy: 0.5238 - 55ms/epoch - 28ms/step\n",
            "Epoch 157/600\n",
            "2/2 - 0s - loss: 0.6348 - accuracy: 0.6440 - val_loss: 0.7060 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 158/600\n",
            "2/2 - 0s - loss: 0.6340 - accuracy: 0.6440 - val_loss: 0.7067 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 159/600\n",
            "2/2 - 0s - loss: 0.6426 - accuracy: 0.6440 - val_loss: 0.7066 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 160/600\n",
            "2/2 - 0s - loss: 0.6399 - accuracy: 0.6400 - val_loss: 0.7067 - val_accuracy: 0.5238 - 50ms/epoch - 25ms/step\n",
            "Epoch 161/600\n",
            "2/2 - 0s - loss: 0.6416 - accuracy: 0.6280 - val_loss: 0.7059 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 162/600\n",
            "2/2 - 0s - loss: 0.6395 - accuracy: 0.6360 - val_loss: 0.7047 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 163/600\n",
            "2/2 - 0s - loss: 0.6376 - accuracy: 0.6480 - val_loss: 0.7047 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 164/600\n",
            "2/2 - 0s - loss: 0.6419 - accuracy: 0.6560 - val_loss: 0.7044 - val_accuracy: 0.5238 - 43ms/epoch - 21ms/step\n",
            "Epoch 165/600\n",
            "2/2 - 0s - loss: 0.6298 - accuracy: 0.6560 - val_loss: 0.7050 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 166/600\n",
            "2/2 - 0s - loss: 0.6341 - accuracy: 0.6640 - val_loss: 0.7055 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 167/600\n",
            "2/2 - 0s - loss: 0.6433 - accuracy: 0.6440 - val_loss: 0.7062 - val_accuracy: 0.5238 - 31ms/epoch - 16ms/step\n",
            "Epoch 168/600\n",
            "2/2 - 0s - loss: 0.6378 - accuracy: 0.6560 - val_loss: 0.7063 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 169/600\n",
            "2/2 - 0s - loss: 0.6397 - accuracy: 0.6400 - val_loss: 0.7072 - val_accuracy: 0.5238 - 28ms/epoch - 14ms/step\n",
            "Epoch 170/600\n",
            "2/2 - 0s - loss: 0.6384 - accuracy: 0.6480 - val_loss: 0.7076 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 171/600\n",
            "2/2 - 0s - loss: 0.6362 - accuracy: 0.6560 - val_loss: 0.7069 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 172/600\n",
            "2/2 - 0s - loss: 0.6291 - accuracy: 0.6560 - val_loss: 0.7069 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 173/600\n",
            "2/2 - 0s - loss: 0.6363 - accuracy: 0.6480 - val_loss: 0.7063 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 174/600\n",
            "2/2 - 0s - loss: 0.6311 - accuracy: 0.6680 - val_loss: 0.7058 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 175/600\n",
            "2/2 - 0s - loss: 0.6323 - accuracy: 0.6400 - val_loss: 0.7048 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 176/600\n",
            "2/2 - 0s - loss: 0.6277 - accuracy: 0.6600 - val_loss: 0.7034 - val_accuracy: 0.5238 - 37ms/epoch - 19ms/step\n",
            "Epoch 177/600\n",
            "2/2 - 0s - loss: 0.6347 - accuracy: 0.6440 - val_loss: 0.7017 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 178/600\n",
            "2/2 - 0s - loss: 0.6377 - accuracy: 0.6440 - val_loss: 0.7010 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 179/600\n",
            "2/2 - 0s - loss: 0.6360 - accuracy: 0.6560 - val_loss: 0.7008 - val_accuracy: 0.5238 - 37ms/epoch - 19ms/step\n",
            "Epoch 180/600\n",
            "2/2 - 0s - loss: 0.6367 - accuracy: 0.6480 - val_loss: 0.7009 - val_accuracy: 0.5397 - 43ms/epoch - 22ms/step\n",
            "Epoch 181/600\n",
            "2/2 - 0s - loss: 0.6386 - accuracy: 0.6480 - val_loss: 0.7023 - val_accuracy: 0.5556 - 41ms/epoch - 20ms/step\n",
            "Epoch 182/600\n",
            "2/2 - 0s - loss: 0.6313 - accuracy: 0.6520 - val_loss: 0.7037 - val_accuracy: 0.5714 - 36ms/epoch - 18ms/step\n",
            "Epoch 183/600\n",
            "2/2 - 0s - loss: 0.6352 - accuracy: 0.6680 - val_loss: 0.7050 - val_accuracy: 0.5556 - 36ms/epoch - 18ms/step\n",
            "Epoch 184/600\n",
            "2/2 - 0s - loss: 0.6366 - accuracy: 0.6560 - val_loss: 0.7061 - val_accuracy: 0.5714 - 36ms/epoch - 18ms/step\n",
            "Epoch 185/600\n",
            "2/2 - 0s - loss: 0.6407 - accuracy: 0.6520 - val_loss: 0.7062 - val_accuracy: 0.5714 - 30ms/epoch - 15ms/step\n",
            "Epoch 186/600\n",
            "2/2 - 0s - loss: 0.6198 - accuracy: 0.6760 - val_loss: 0.7065 - val_accuracy: 0.5556 - 33ms/epoch - 17ms/step\n",
            "Epoch 187/600\n",
            "2/2 - 0s - loss: 0.6366 - accuracy: 0.6600 - val_loss: 0.7072 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 188/600\n",
            "2/2 - 0s - loss: 0.6352 - accuracy: 0.6400 - val_loss: 0.7068 - val_accuracy: 0.5556 - 38ms/epoch - 19ms/step\n",
            "Epoch 189/600\n",
            "2/2 - 0s - loss: 0.6319 - accuracy: 0.6720 - val_loss: 0.7058 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 190/600\n",
            "2/2 - 0s - loss: 0.6278 - accuracy: 0.6760 - val_loss: 0.7048 - val_accuracy: 0.5714 - 42ms/epoch - 21ms/step\n",
            "Epoch 191/600\n",
            "2/2 - 0s - loss: 0.6244 - accuracy: 0.6800 - val_loss: 0.7031 - val_accuracy: 0.5714 - 31ms/epoch - 16ms/step\n",
            "Epoch 192/600\n",
            "2/2 - 0s - loss: 0.6254 - accuracy: 0.6440 - val_loss: 0.7026 - val_accuracy: 0.5714 - 32ms/epoch - 16ms/step\n",
            "Epoch 193/600\n",
            "2/2 - 0s - loss: 0.6321 - accuracy: 0.6520 - val_loss: 0.7022 - val_accuracy: 0.5714 - 34ms/epoch - 17ms/step\n",
            "Epoch 194/600\n",
            "2/2 - 0s - loss: 0.6267 - accuracy: 0.6600 - val_loss: 0.7023 - val_accuracy: 0.5714 - 38ms/epoch - 19ms/step\n",
            "Epoch 195/600\n",
            "2/2 - 0s - loss: 0.6249 - accuracy: 0.6680 - val_loss: 0.7028 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 196/600\n",
            "2/2 - 0s - loss: 0.6258 - accuracy: 0.6520 - val_loss: 0.7043 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 197/600\n",
            "2/2 - 0s - loss: 0.6133 - accuracy: 0.6560 - val_loss: 0.7061 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 198/600\n",
            "2/2 - 0s - loss: 0.6322 - accuracy: 0.6560 - val_loss: 0.7073 - val_accuracy: 0.5556 - 31ms/epoch - 16ms/step\n",
            "Epoch 199/600\n",
            "2/2 - 0s - loss: 0.6275 - accuracy: 0.6320 - val_loss: 0.7086 - val_accuracy: 0.5556 - 37ms/epoch - 18ms/step\n",
            "Epoch 200/600\n",
            "2/2 - 0s - loss: 0.6282 - accuracy: 0.6760 - val_loss: 0.7101 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 201/600\n",
            "2/2 - 0s - loss: 0.6251 - accuracy: 0.6440 - val_loss: 0.7112 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 202/600\n",
            "2/2 - 0s - loss: 0.6212 - accuracy: 0.6760 - val_loss: 0.7117 - val_accuracy: 0.5238 - 37ms/epoch - 19ms/step\n",
            "Epoch 203/600\n",
            "2/2 - 0s - loss: 0.6269 - accuracy: 0.6600 - val_loss: 0.7119 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 204/600\n",
            "2/2 - 0s - loss: 0.6244 - accuracy: 0.6680 - val_loss: 0.7119 - val_accuracy: 0.5397 - 29ms/epoch - 15ms/step\n",
            "Epoch 205/600\n",
            "2/2 - 0s - loss: 0.6210 - accuracy: 0.6680 - val_loss: 0.7119 - val_accuracy: 0.5556 - 45ms/epoch - 23ms/step\n",
            "Epoch 206/600\n",
            "2/2 - 0s - loss: 0.6177 - accuracy: 0.6480 - val_loss: 0.7105 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 207/600\n",
            "2/2 - 0s - loss: 0.6253 - accuracy: 0.6720 - val_loss: 0.7084 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 208/600\n",
            "2/2 - 0s - loss: 0.6129 - accuracy: 0.6840 - val_loss: 0.7069 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 209/600\n",
            "2/2 - 0s - loss: 0.6216 - accuracy: 0.6640 - val_loss: 0.7068 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 210/600\n",
            "2/2 - 0s - loss: 0.6129 - accuracy: 0.6720 - val_loss: 0.7086 - val_accuracy: 0.5397 - 30ms/epoch - 15ms/step\n",
            "Epoch 211/600\n",
            "2/2 - 0s - loss: 0.6169 - accuracy: 0.6760 - val_loss: 0.7104 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 212/600\n",
            "2/2 - 0s - loss: 0.6233 - accuracy: 0.6760 - val_loss: 0.7128 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 213/600\n",
            "2/2 - 0s - loss: 0.6156 - accuracy: 0.6720 - val_loss: 0.7154 - val_accuracy: 0.5079 - 28ms/epoch - 14ms/step\n",
            "Epoch 214/600\n",
            "2/2 - 0s - loss: 0.6271 - accuracy: 0.6480 - val_loss: 0.7150 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 215/600\n",
            "2/2 - 0s - loss: 0.6207 - accuracy: 0.6800 - val_loss: 0.7151 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 216/600\n",
            "2/2 - 0s - loss: 0.6209 - accuracy: 0.6600 - val_loss: 0.7149 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 217/600\n",
            "2/2 - 0s - loss: 0.6279 - accuracy: 0.6560 - val_loss: 0.7144 - val_accuracy: 0.5397 - 33ms/epoch - 16ms/step\n",
            "Epoch 218/600\n",
            "2/2 - 0s - loss: 0.6201 - accuracy: 0.6600 - val_loss: 0.7156 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 219/600\n",
            "2/2 - 0s - loss: 0.6094 - accuracy: 0.6800 - val_loss: 0.7154 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 220/600\n",
            "2/2 - 0s - loss: 0.6203 - accuracy: 0.6680 - val_loss: 0.7147 - val_accuracy: 0.5079 - 39ms/epoch - 20ms/step\n",
            "Epoch 221/600\n",
            "2/2 - 0s - loss: 0.6149 - accuracy: 0.6960 - val_loss: 0.7134 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 222/600\n",
            "2/2 - 0s - loss: 0.6249 - accuracy: 0.6640 - val_loss: 0.7125 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 223/600\n",
            "2/2 - 0s - loss: 0.6112 - accuracy: 0.6960 - val_loss: 0.7120 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 224/600\n",
            "2/2 - 0s - loss: 0.6077 - accuracy: 0.6640 - val_loss: 0.7125 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 225/600\n",
            "2/2 - 0s - loss: 0.6088 - accuracy: 0.6960 - val_loss: 0.7137 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 226/600\n",
            "2/2 - 0s - loss: 0.6223 - accuracy: 0.6640 - val_loss: 0.7149 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 227/600\n",
            "2/2 - 0s - loss: 0.6136 - accuracy: 0.6640 - val_loss: 0.7164 - val_accuracy: 0.5397 - 30ms/epoch - 15ms/step\n",
            "Epoch 228/600\n",
            "2/2 - 0s - loss: 0.6191 - accuracy: 0.6720 - val_loss: 0.7178 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 229/600\n",
            "2/2 - 0s - loss: 0.6092 - accuracy: 0.6920 - val_loss: 0.7188 - val_accuracy: 0.5397 - 30ms/epoch - 15ms/step\n",
            "Epoch 230/600\n",
            "2/2 - 0s - loss: 0.6156 - accuracy: 0.6800 - val_loss: 0.7200 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 231/600\n",
            "2/2 - 0s - loss: 0.6207 - accuracy: 0.6560 - val_loss: 0.7204 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 232/600\n",
            "2/2 - 0s - loss: 0.6171 - accuracy: 0.6560 - val_loss: 0.7196 - val_accuracy: 0.5238 - 49ms/epoch - 25ms/step\n",
            "Epoch 233/600\n",
            "2/2 - 0s - loss: 0.6134 - accuracy: 0.6840 - val_loss: 0.7193 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 234/600\n",
            "2/2 - 0s - loss: 0.6116 - accuracy: 0.6520 - val_loss: 0.7188 - val_accuracy: 0.5238 - 49ms/epoch - 25ms/step\n",
            "Epoch 235/600\n",
            "2/2 - 0s - loss: 0.6191 - accuracy: 0.6840 - val_loss: 0.7187 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 236/600\n",
            "2/2 - 0s - loss: 0.6095 - accuracy: 0.6720 - val_loss: 0.7176 - val_accuracy: 0.5238 - 46ms/epoch - 23ms/step\n",
            "Epoch 237/600\n",
            "2/2 - 0s - loss: 0.6139 - accuracy: 0.6680 - val_loss: 0.7180 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 238/600\n",
            "2/2 - 0s - loss: 0.6188 - accuracy: 0.6560 - val_loss: 0.7177 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 239/600\n",
            "2/2 - 0s - loss: 0.6124 - accuracy: 0.6680 - val_loss: 0.7173 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 240/600\n",
            "2/2 - 0s - loss: 0.6112 - accuracy: 0.6640 - val_loss: 0.7172 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 241/600\n",
            "2/2 - 0s - loss: 0.6146 - accuracy: 0.6640 - val_loss: 0.7173 - val_accuracy: 0.5079 - 41ms/epoch - 20ms/step\n",
            "Epoch 242/600\n",
            "2/2 - 0s - loss: 0.6152 - accuracy: 0.6560 - val_loss: 0.7181 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 243/600\n",
            "2/2 - 0s - loss: 0.6066 - accuracy: 0.6800 - val_loss: 0.7190 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 244/600\n",
            "2/2 - 0s - loss: 0.6068 - accuracy: 0.6800 - val_loss: 0.7204 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 245/600\n",
            "2/2 - 0s - loss: 0.6134 - accuracy: 0.6720 - val_loss: 0.7217 - val_accuracy: 0.5238 - 31ms/epoch - 16ms/step\n",
            "Epoch 246/600\n",
            "2/2 - 0s - loss: 0.6178 - accuracy: 0.6520 - val_loss: 0.7222 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 247/600\n",
            "2/2 - 0s - loss: 0.6060 - accuracy: 0.6840 - val_loss: 0.7230 - val_accuracy: 0.5238 - 41ms/epoch - 20ms/step\n",
            "Epoch 248/600\n",
            "2/2 - 0s - loss: 0.6126 - accuracy: 0.6760 - val_loss: 0.7236 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 249/600\n",
            "2/2 - 0s - loss: 0.6152 - accuracy: 0.6720 - val_loss: 0.7244 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 250/600\n",
            "2/2 - 0s - loss: 0.6103 - accuracy: 0.6840 - val_loss: 0.7255 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 251/600\n",
            "2/2 - 0s - loss: 0.6016 - accuracy: 0.6760 - val_loss: 0.7247 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 252/600\n",
            "2/2 - 0s - loss: 0.6077 - accuracy: 0.6640 - val_loss: 0.7232 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 253/600\n",
            "2/2 - 0s - loss: 0.5992 - accuracy: 0.7000 - val_loss: 0.7215 - val_accuracy: 0.5238 - 31ms/epoch - 15ms/step\n",
            "Epoch 254/600\n",
            "2/2 - 0s - loss: 0.5950 - accuracy: 0.6760 - val_loss: 0.7204 - val_accuracy: 0.5397 - 30ms/epoch - 15ms/step\n",
            "Epoch 255/600\n",
            "2/2 - 0s - loss: 0.5944 - accuracy: 0.6880 - val_loss: 0.7199 - val_accuracy: 0.5397 - 33ms/epoch - 16ms/step\n",
            "Epoch 256/600\n",
            "2/2 - 0s - loss: 0.6005 - accuracy: 0.6640 - val_loss: 0.7207 - val_accuracy: 0.5397 - 37ms/epoch - 19ms/step\n",
            "Epoch 257/600\n",
            "2/2 - 0s - loss: 0.6230 - accuracy: 0.6680 - val_loss: 0.7212 - val_accuracy: 0.5397 - 44ms/epoch - 22ms/step\n",
            "Epoch 258/600\n",
            "2/2 - 0s - loss: 0.6146 - accuracy: 0.6640 - val_loss: 0.7213 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 259/600\n",
            "2/2 - 0s - loss: 0.6024 - accuracy: 0.6720 - val_loss: 0.7220 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 260/600\n",
            "2/2 - 0s - loss: 0.6120 - accuracy: 0.6520 - val_loss: 0.7233 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 261/600\n",
            "2/2 - 0s - loss: 0.6029 - accuracy: 0.6720 - val_loss: 0.7245 - val_accuracy: 0.5079 - 29ms/epoch - 15ms/step\n",
            "Epoch 262/600\n",
            "2/2 - 0s - loss: 0.6030 - accuracy: 0.6640 - val_loss: 0.7254 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 263/600\n",
            "2/2 - 0s - loss: 0.6013 - accuracy: 0.6880 - val_loss: 0.7261 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 264/600\n",
            "2/2 - 0s - loss: 0.6039 - accuracy: 0.6640 - val_loss: 0.7270 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 265/600\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6960 - val_loss: 0.7270 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 266/600\n",
            "2/2 - 0s - loss: 0.6082 - accuracy: 0.6880 - val_loss: 0.7273 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 267/600\n",
            "2/2 - 0s - loss: 0.5942 - accuracy: 0.6600 - val_loss: 0.7271 - val_accuracy: 0.5397 - 38ms/epoch - 19ms/step\n",
            "Epoch 268/600\n",
            "2/2 - 0s - loss: 0.5978 - accuracy: 0.6560 - val_loss: 0.7264 - val_accuracy: 0.5397 - 39ms/epoch - 20ms/step\n",
            "Epoch 269/600\n",
            "2/2 - 0s - loss: 0.6074 - accuracy: 0.6680 - val_loss: 0.7254 - val_accuracy: 0.5397 - 33ms/epoch - 16ms/step\n",
            "Epoch 270/600\n",
            "2/2 - 0s - loss: 0.6025 - accuracy: 0.6680 - val_loss: 0.7253 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 271/600\n",
            "2/2 - 0s - loss: 0.5978 - accuracy: 0.6800 - val_loss: 0.7259 - val_accuracy: 0.5238 - 37ms/epoch - 19ms/step\n",
            "Epoch 272/600\n",
            "2/2 - 0s - loss: 0.5917 - accuracy: 0.6800 - val_loss: 0.7257 - val_accuracy: 0.5397 - 35ms/epoch - 18ms/step\n",
            "Epoch 273/600\n",
            "2/2 - 0s - loss: 0.6005 - accuracy: 0.6720 - val_loss: 0.7253 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 274/600\n",
            "2/2 - 0s - loss: 0.6063 - accuracy: 0.6640 - val_loss: 0.7252 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 275/600\n",
            "2/2 - 0s - loss: 0.6021 - accuracy: 0.6440 - val_loss: 0.7255 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 276/600\n",
            "2/2 - 0s - loss: 0.5926 - accuracy: 0.7000 - val_loss: 0.7255 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 277/600\n",
            "2/2 - 0s - loss: 0.5960 - accuracy: 0.6760 - val_loss: 0.7268 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 278/600\n",
            "2/2 - 0s - loss: 0.5949 - accuracy: 0.6960 - val_loss: 0.7279 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 279/600\n",
            "2/2 - 0s - loss: 0.5975 - accuracy: 0.6520 - val_loss: 0.7289 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 280/600\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6760 - val_loss: 0.7308 - val_accuracy: 0.5238 - 37ms/epoch - 18ms/step\n",
            "Epoch 281/600\n",
            "2/2 - 0s - loss: 0.6073 - accuracy: 0.6560 - val_loss: 0.7326 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 282/600\n",
            "2/2 - 0s - loss: 0.6035 - accuracy: 0.6680 - val_loss: 0.7338 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 283/600\n",
            "2/2 - 0s - loss: 0.5972 - accuracy: 0.6360 - val_loss: 0.7341 - val_accuracy: 0.5079 - 43ms/epoch - 22ms/step\n",
            "Epoch 284/600\n",
            "2/2 - 0s - loss: 0.6056 - accuracy: 0.6800 - val_loss: 0.7345 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 285/600\n",
            "2/2 - 0s - loss: 0.6177 - accuracy: 0.6920 - val_loss: 0.7359 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 286/600\n",
            "2/2 - 0s - loss: 0.5969 - accuracy: 0.6640 - val_loss: 0.7364 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 287/600\n",
            "2/2 - 0s - loss: 0.5993 - accuracy: 0.6880 - val_loss: 0.7390 - val_accuracy: 0.4762 - 32ms/epoch - 16ms/step\n",
            "Epoch 288/600\n",
            "2/2 - 0s - loss: 0.5947 - accuracy: 0.6680 - val_loss: 0.7411 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 289/600\n",
            "2/2 - 0s - loss: 0.5891 - accuracy: 0.6760 - val_loss: 0.7432 - val_accuracy: 0.4603 - 40ms/epoch - 20ms/step\n",
            "Epoch 290/600\n",
            "2/2 - 0s - loss: 0.5985 - accuracy: 0.6920 - val_loss: 0.7458 - val_accuracy: 0.4603 - 30ms/epoch - 15ms/step\n",
            "Epoch 291/600\n",
            "2/2 - 0s - loss: 0.6098 - accuracy: 0.6720 - val_loss: 0.7476 - val_accuracy: 0.4603 - 32ms/epoch - 16ms/step\n",
            "Epoch 292/600\n",
            "2/2 - 0s - loss: 0.6165 - accuracy: 0.6520 - val_loss: 0.7456 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 293/600\n",
            "2/2 - 0s - loss: 0.6003 - accuracy: 0.6560 - val_loss: 0.7428 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 294/600\n",
            "2/2 - 0s - loss: 0.5721 - accuracy: 0.7120 - val_loss: 0.7417 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 295/600\n",
            "2/2 - 0s - loss: 0.5893 - accuracy: 0.6840 - val_loss: 0.7396 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 296/600\n",
            "2/2 - 0s - loss: 0.6088 - accuracy: 0.6600 - val_loss: 0.7369 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 297/600\n",
            "2/2 - 0s - loss: 0.5854 - accuracy: 0.6720 - val_loss: 0.7330 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 298/600\n",
            "2/2 - 0s - loss: 0.5957 - accuracy: 0.6960 - val_loss: 0.7310 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 299/600\n",
            "2/2 - 0s - loss: 0.5925 - accuracy: 0.6960 - val_loss: 0.7303 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 300/600\n",
            "2/2 - 0s - loss: 0.5958 - accuracy: 0.6640 - val_loss: 0.7311 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 301/600\n",
            "2/2 - 0s - loss: 0.5835 - accuracy: 0.7000 - val_loss: 0.7324 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 302/600\n",
            "2/2 - 0s - loss: 0.5873 - accuracy: 0.6760 - val_loss: 0.7333 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 303/600\n",
            "2/2 - 0s - loss: 0.5962 - accuracy: 0.6880 - val_loss: 0.7339 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 304/600\n",
            "2/2 - 0s - loss: 0.5833 - accuracy: 0.7040 - val_loss: 0.7352 - val_accuracy: 0.4921 - 31ms/epoch - 15ms/step\n",
            "Epoch 305/600\n",
            "2/2 - 0s - loss: 0.5991 - accuracy: 0.6760 - val_loss: 0.7358 - val_accuracy: 0.4921 - 31ms/epoch - 16ms/step\n",
            "Epoch 306/600\n",
            "2/2 - 0s - loss: 0.5903 - accuracy: 0.6800 - val_loss: 0.7365 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 307/600\n",
            "2/2 - 0s - loss: 0.6004 - accuracy: 0.6800 - val_loss: 0.7374 - val_accuracy: 0.5238 - 31ms/epoch - 16ms/step\n",
            "Epoch 308/600\n",
            "2/2 - 0s - loss: 0.5850 - accuracy: 0.6720 - val_loss: 0.7376 - val_accuracy: 0.5238 - 31ms/epoch - 15ms/step\n",
            "Epoch 309/600\n",
            "2/2 - 0s - loss: 0.6036 - accuracy: 0.6520 - val_loss: 0.7371 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 310/600\n",
            "2/2 - 0s - loss: 0.5858 - accuracy: 0.7040 - val_loss: 0.7376 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 311/600\n",
            "2/2 - 0s - loss: 0.5844 - accuracy: 0.6720 - val_loss: 0.7386 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 312/600\n",
            "2/2 - 0s - loss: 0.5884 - accuracy: 0.6960 - val_loss: 0.7394 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 313/600\n",
            "2/2 - 0s - loss: 0.6031 - accuracy: 0.6760 - val_loss: 0.7402 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 314/600\n",
            "2/2 - 0s - loss: 0.5809 - accuracy: 0.7160 - val_loss: 0.7421 - val_accuracy: 0.4762 - 31ms/epoch - 15ms/step\n",
            "Epoch 315/600\n",
            "2/2 - 0s - loss: 0.5873 - accuracy: 0.6680 - val_loss: 0.7436 - val_accuracy: 0.4762 - 35ms/epoch - 17ms/step\n",
            "Epoch 316/600\n",
            "2/2 - 0s - loss: 0.5958 - accuracy: 0.7000 - val_loss: 0.7435 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 317/600\n",
            "2/2 - 0s - loss: 0.5851 - accuracy: 0.7080 - val_loss: 0.7432 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 318/600\n",
            "2/2 - 0s - loss: 0.5977 - accuracy: 0.6520 - val_loss: 0.7436 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 319/600\n",
            "2/2 - 0s - loss: 0.5837 - accuracy: 0.7120 - val_loss: 0.7454 - val_accuracy: 0.4921 - 41ms/epoch - 21ms/step\n",
            "Epoch 320/600\n",
            "2/2 - 0s - loss: 0.5802 - accuracy: 0.6880 - val_loss: 0.7478 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 321/600\n",
            "2/2 - 0s - loss: 0.5976 - accuracy: 0.6680 - val_loss: 0.7486 - val_accuracy: 0.4762 - 38ms/epoch - 19ms/step\n",
            "Epoch 322/600\n",
            "2/2 - 0s - loss: 0.6120 - accuracy: 0.6720 - val_loss: 0.7502 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 323/600\n",
            "2/2 - 0s - loss: 0.5866 - accuracy: 0.6880 - val_loss: 0.7501 - val_accuracy: 0.4921 - 35ms/epoch - 18ms/step\n",
            "Epoch 324/600\n",
            "2/2 - 0s - loss: 0.5772 - accuracy: 0.6840 - val_loss: 0.7499 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 325/600\n",
            "2/2 - 0s - loss: 0.5869 - accuracy: 0.6920 - val_loss: 0.7493 - val_accuracy: 0.4921 - 47ms/epoch - 24ms/step\n",
            "Epoch 326/600\n",
            "2/2 - 0s - loss: 0.5839 - accuracy: 0.6880 - val_loss: 0.7493 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 327/600\n",
            "2/2 - 0s - loss: 0.5813 - accuracy: 0.6880 - val_loss: 0.7504 - val_accuracy: 0.4762 - 37ms/epoch - 18ms/step\n",
            "Epoch 328/600\n",
            "2/2 - 0s - loss: 0.5906 - accuracy: 0.6960 - val_loss: 0.7505 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 329/600\n",
            "2/2 - 0s - loss: 0.5720 - accuracy: 0.7080 - val_loss: 0.7507 - val_accuracy: 0.5079 - 35ms/epoch - 17ms/step\n",
            "Epoch 330/600\n",
            "2/2 - 0s - loss: 0.5771 - accuracy: 0.7160 - val_loss: 0.7510 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 331/600\n",
            "2/2 - 0s - loss: 0.5771 - accuracy: 0.6960 - val_loss: 0.7522 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 332/600\n",
            "2/2 - 0s - loss: 0.5863 - accuracy: 0.6800 - val_loss: 0.7530 - val_accuracy: 0.4921 - 37ms/epoch - 19ms/step\n",
            "Epoch 333/600\n",
            "2/2 - 0s - loss: 0.5852 - accuracy: 0.6840 - val_loss: 0.7532 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 334/600\n",
            "2/2 - 0s - loss: 0.5777 - accuracy: 0.7000 - val_loss: 0.7535 - val_accuracy: 0.4921 - 46ms/epoch - 23ms/step\n",
            "Epoch 335/600\n",
            "2/2 - 0s - loss: 0.5921 - accuracy: 0.6960 - val_loss: 0.7545 - val_accuracy: 0.4921 - 39ms/epoch - 20ms/step\n",
            "Epoch 336/600\n",
            "2/2 - 0s - loss: 0.5628 - accuracy: 0.7000 - val_loss: 0.7559 - val_accuracy: 0.4603 - 36ms/epoch - 18ms/step\n",
            "Epoch 337/600\n",
            "2/2 - 0s - loss: 0.5647 - accuracy: 0.7200 - val_loss: 0.7575 - val_accuracy: 0.4603 - 33ms/epoch - 17ms/step\n",
            "Epoch 338/600\n",
            "2/2 - 0s - loss: 0.5952 - accuracy: 0.6800 - val_loss: 0.7579 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 339/600\n",
            "2/2 - 0s - loss: 0.5919 - accuracy: 0.6800 - val_loss: 0.7587 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 340/600\n",
            "2/2 - 0s - loss: 0.5744 - accuracy: 0.6800 - val_loss: 0.7600 - val_accuracy: 0.4921 - 41ms/epoch - 20ms/step\n",
            "Epoch 341/600\n",
            "2/2 - 0s - loss: 0.5818 - accuracy: 0.6920 - val_loss: 0.7598 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 342/600\n",
            "2/2 - 0s - loss: 0.5908 - accuracy: 0.6680 - val_loss: 0.7597 - val_accuracy: 0.4762 - 31ms/epoch - 16ms/step\n",
            "Epoch 343/600\n",
            "2/2 - 0s - loss: 0.5726 - accuracy: 0.6840 - val_loss: 0.7583 - val_accuracy: 0.4762 - 29ms/epoch - 15ms/step\n",
            "Epoch 344/600\n",
            "2/2 - 0s - loss: 0.5774 - accuracy: 0.7200 - val_loss: 0.7603 - val_accuracy: 0.4603 - 53ms/epoch - 26ms/step\n",
            "Epoch 345/600\n",
            "2/2 - 0s - loss: 0.5868 - accuracy: 0.6840 - val_loss: 0.7601 - val_accuracy: 0.4603 - 31ms/epoch - 15ms/step\n",
            "Epoch 346/600\n",
            "2/2 - 0s - loss: 0.5904 - accuracy: 0.6880 - val_loss: 0.7586 - val_accuracy: 0.4603 - 34ms/epoch - 17ms/step\n",
            "Epoch 347/600\n",
            "2/2 - 0s - loss: 0.5740 - accuracy: 0.7000 - val_loss: 0.7577 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 348/600\n",
            "2/2 - 0s - loss: 0.5783 - accuracy: 0.7040 - val_loss: 0.7590 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 349/600\n",
            "2/2 - 0s - loss: 0.6041 - accuracy: 0.6600 - val_loss: 0.7602 - val_accuracy: 0.4762 - 38ms/epoch - 19ms/step\n",
            "Epoch 350/600\n",
            "2/2 - 0s - loss: 0.5844 - accuracy: 0.6600 - val_loss: 0.7557 - val_accuracy: 0.5079 - 39ms/epoch - 20ms/step\n",
            "Epoch 351/600\n",
            "2/2 - 0s - loss: 0.5772 - accuracy: 0.7040 - val_loss: 0.7527 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 352/600\n",
            "2/2 - 0s - loss: 0.5769 - accuracy: 0.6920 - val_loss: 0.7516 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 353/600\n",
            "2/2 - 0s - loss: 0.5715 - accuracy: 0.6640 - val_loss: 0.7503 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 354/600\n",
            "2/2 - 0s - loss: 0.5795 - accuracy: 0.6840 - val_loss: 0.7487 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 355/600\n",
            "2/2 - 0s - loss: 0.5745 - accuracy: 0.6960 - val_loss: 0.7462 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 356/600\n",
            "2/2 - 0s - loss: 0.5723 - accuracy: 0.6960 - val_loss: 0.7458 - val_accuracy: 0.5079 - 41ms/epoch - 21ms/step\n",
            "Epoch 357/600\n",
            "2/2 - 0s - loss: 0.5792 - accuracy: 0.6800 - val_loss: 0.7468 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 358/600\n",
            "2/2 - 0s - loss: 0.5841 - accuracy: 0.6680 - val_loss: 0.7496 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 359/600\n",
            "2/2 - 0s - loss: 0.5817 - accuracy: 0.7040 - val_loss: 0.7532 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 360/600\n",
            "2/2 - 0s - loss: 0.5743 - accuracy: 0.7040 - val_loss: 0.7566 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 361/600\n",
            "2/2 - 0s - loss: 0.5712 - accuracy: 0.7240 - val_loss: 0.7593 - val_accuracy: 0.4921 - 35ms/epoch - 17ms/step\n",
            "Epoch 362/600\n",
            "2/2 - 0s - loss: 0.5863 - accuracy: 0.6800 - val_loss: 0.7610 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 363/600\n",
            "2/2 - 0s - loss: 0.5782 - accuracy: 0.6840 - val_loss: 0.7611 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 364/600\n",
            "2/2 - 0s - loss: 0.5665 - accuracy: 0.7320 - val_loss: 0.7622 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 365/600\n",
            "2/2 - 0s - loss: 0.5865 - accuracy: 0.6800 - val_loss: 0.7628 - val_accuracy: 0.4762 - 30ms/epoch - 15ms/step\n",
            "Epoch 366/600\n",
            "2/2 - 0s - loss: 0.5746 - accuracy: 0.6920 - val_loss: 0.7623 - val_accuracy: 0.4762 - 34ms/epoch - 17ms/step\n",
            "Epoch 367/600\n",
            "2/2 - 0s - loss: 0.5609 - accuracy: 0.6920 - val_loss: 0.7619 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 368/600\n",
            "2/2 - 0s - loss: 0.5700 - accuracy: 0.7000 - val_loss: 0.7607 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 369/600\n",
            "2/2 - 0s - loss: 0.5689 - accuracy: 0.7120 - val_loss: 0.7607 - val_accuracy: 0.4921 - 35ms/epoch - 18ms/step\n",
            "Epoch 370/600\n",
            "2/2 - 0s - loss: 0.5740 - accuracy: 0.7000 - val_loss: 0.7602 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 371/600\n",
            "2/2 - 0s - loss: 0.5818 - accuracy: 0.6840 - val_loss: 0.7599 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 372/600\n",
            "2/2 - 0s - loss: 0.5776 - accuracy: 0.7000 - val_loss: 0.7595 - val_accuracy: 0.5079 - 39ms/epoch - 19ms/step\n",
            "Epoch 373/600\n",
            "2/2 - 0s - loss: 0.5662 - accuracy: 0.6920 - val_loss: 0.7598 - val_accuracy: 0.4921 - 37ms/epoch - 18ms/step\n",
            "Epoch 374/600\n",
            "2/2 - 0s - loss: 0.5941 - accuracy: 0.6800 - val_loss: 0.7614 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 375/600\n",
            "2/2 - 0s - loss: 0.5842 - accuracy: 0.6640 - val_loss: 0.7638 - val_accuracy: 0.4921 - 33ms/epoch - 16ms/step\n",
            "Epoch 376/600\n",
            "2/2 - 0s - loss: 0.5669 - accuracy: 0.7000 - val_loss: 0.7666 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 377/600\n",
            "2/2 - 0s - loss: 0.5732 - accuracy: 0.6920 - val_loss: 0.7697 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 378/600\n",
            "2/2 - 0s - loss: 0.5628 - accuracy: 0.7000 - val_loss: 0.7723 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 379/600\n",
            "2/2 - 0s - loss: 0.5776 - accuracy: 0.6840 - val_loss: 0.7738 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 380/600\n",
            "2/2 - 0s - loss: 0.5607 - accuracy: 0.7200 - val_loss: 0.7754 - val_accuracy: 0.4921 - 33ms/epoch - 17ms/step\n",
            "Epoch 381/600\n",
            "2/2 - 0s - loss: 0.5592 - accuracy: 0.7120 - val_loss: 0.7773 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 382/600\n",
            "2/2 - 0s - loss: 0.5764 - accuracy: 0.7000 - val_loss: 0.7777 - val_accuracy: 0.5079 - 33ms/epoch - 17ms/step\n",
            "Epoch 383/600\n",
            "2/2 - 0s - loss: 0.5696 - accuracy: 0.7080 - val_loss: 0.7761 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 384/600\n",
            "2/2 - 0s - loss: 0.5885 - accuracy: 0.6680 - val_loss: 0.7747 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 385/600\n",
            "2/2 - 0s - loss: 0.5652 - accuracy: 0.6840 - val_loss: 0.7749 - val_accuracy: 0.5079 - 43ms/epoch - 22ms/step\n",
            "Epoch 386/600\n",
            "2/2 - 0s - loss: 0.5782 - accuracy: 0.6680 - val_loss: 0.7751 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 387/600\n",
            "2/2 - 0s - loss: 0.5693 - accuracy: 0.7160 - val_loss: 0.7746 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 388/600\n",
            "2/2 - 0s - loss: 0.5693 - accuracy: 0.6960 - val_loss: 0.7739 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 389/600\n",
            "2/2 - 0s - loss: 0.5517 - accuracy: 0.7280 - val_loss: 0.7730 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 390/600\n",
            "2/2 - 0s - loss: 0.5715 - accuracy: 0.7000 - val_loss: 0.7738 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 391/600\n",
            "2/2 - 0s - loss: 0.5504 - accuracy: 0.7160 - val_loss: 0.7743 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 392/600\n",
            "2/2 - 0s - loss: 0.5766 - accuracy: 0.7080 - val_loss: 0.7734 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 393/600\n",
            "2/2 - 0s - loss: 0.5924 - accuracy: 0.7000 - val_loss: 0.7725 - val_accuracy: 0.5238 - 42ms/epoch - 21ms/step\n",
            "Epoch 394/600\n",
            "2/2 - 0s - loss: 0.5603 - accuracy: 0.7200 - val_loss: 0.7708 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 395/600\n",
            "2/2 - 0s - loss: 0.5708 - accuracy: 0.6960 - val_loss: 0.7708 - val_accuracy: 0.5238 - 42ms/epoch - 21ms/step\n",
            "Epoch 396/600\n",
            "2/2 - 0s - loss: 0.5876 - accuracy: 0.7040 - val_loss: 0.7726 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 397/600\n",
            "2/2 - 0s - loss: 0.5648 - accuracy: 0.7000 - val_loss: 0.7742 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 398/600\n",
            "2/2 - 0s - loss: 0.5598 - accuracy: 0.7240 - val_loss: 0.7755 - val_accuracy: 0.4921 - 34ms/epoch - 17ms/step\n",
            "Epoch 399/600\n",
            "2/2 - 0s - loss: 0.5785 - accuracy: 0.6760 - val_loss: 0.7756 - val_accuracy: 0.4921 - 40ms/epoch - 20ms/step\n",
            "Epoch 400/600\n",
            "2/2 - 0s - loss: 0.5590 - accuracy: 0.6880 - val_loss: 0.7757 - val_accuracy: 0.4921 - 38ms/epoch - 19ms/step\n",
            "Epoch 401/600\n",
            "2/2 - 0s - loss: 0.5708 - accuracy: 0.7200 - val_loss: 0.7770 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 402/600\n",
            "2/2 - 0s - loss: 0.5799 - accuracy: 0.6920 - val_loss: 0.7765 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 403/600\n",
            "2/2 - 0s - loss: 0.5638 - accuracy: 0.7000 - val_loss: 0.7757 - val_accuracy: 0.4921 - 32ms/epoch - 16ms/step\n",
            "Epoch 404/600\n",
            "2/2 - 0s - loss: 0.5670 - accuracy: 0.7040 - val_loss: 0.7740 - val_accuracy: 0.5079 - 38ms/epoch - 19ms/step\n",
            "Epoch 405/600\n",
            "2/2 - 0s - loss: 0.5720 - accuracy: 0.6760 - val_loss: 0.7722 - val_accuracy: 0.5079 - 31ms/epoch - 15ms/step\n",
            "Epoch 406/600\n",
            "2/2 - 0s - loss: 0.5691 - accuracy: 0.6800 - val_loss: 0.7711 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 407/600\n",
            "2/2 - 0s - loss: 0.5633 - accuracy: 0.6920 - val_loss: 0.7700 - val_accuracy: 0.5079 - 51ms/epoch - 26ms/step\n",
            "Epoch 408/600\n",
            "2/2 - 0s - loss: 0.5827 - accuracy: 0.7080 - val_loss: 0.7682 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 409/600\n",
            "2/2 - 0s - loss: 0.5833 - accuracy: 0.6680 - val_loss: 0.7666 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 410/600\n",
            "2/2 - 0s - loss: 0.5518 - accuracy: 0.7240 - val_loss: 0.7673 - val_accuracy: 0.5238 - 61ms/epoch - 31ms/step\n",
            "Epoch 411/600\n",
            "2/2 - 0s - loss: 0.5696 - accuracy: 0.7160 - val_loss: 0.7673 - val_accuracy: 0.5238 - 27ms/epoch - 14ms/step\n",
            "Epoch 412/600\n",
            "2/2 - 0s - loss: 0.5796 - accuracy: 0.6720 - val_loss: 0.7672 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 413/600\n",
            "2/2 - 0s - loss: 0.5781 - accuracy: 0.6880 - val_loss: 0.7663 - val_accuracy: 0.5238 - 31ms/epoch - 15ms/step\n",
            "Epoch 414/600\n",
            "2/2 - 0s - loss: 0.5643 - accuracy: 0.6960 - val_loss: 0.7655 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 415/600\n",
            "2/2 - 0s - loss: 0.5512 - accuracy: 0.7120 - val_loss: 0.7655 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 416/600\n",
            "2/2 - 0s - loss: 0.5408 - accuracy: 0.7360 - val_loss: 0.7662 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 417/600\n",
            "2/2 - 0s - loss: 0.5648 - accuracy: 0.7280 - val_loss: 0.7678 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 418/600\n",
            "2/2 - 0s - loss: 0.5823 - accuracy: 0.6880 - val_loss: 0.7687 - val_accuracy: 0.4921 - 30ms/epoch - 15ms/step\n",
            "Epoch 419/600\n",
            "2/2 - 0s - loss: 0.5713 - accuracy: 0.7080 - val_loss: 0.7706 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 420/600\n",
            "2/2 - 0s - loss: 0.5646 - accuracy: 0.6920 - val_loss: 0.7723 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 421/600\n",
            "2/2 - 0s - loss: 0.5471 - accuracy: 0.7320 - val_loss: 0.7739 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 422/600\n",
            "2/2 - 0s - loss: 0.5541 - accuracy: 0.7280 - val_loss: 0.7765 - val_accuracy: 0.5079 - 37ms/epoch - 19ms/step\n",
            "Epoch 423/600\n",
            "2/2 - 0s - loss: 0.5459 - accuracy: 0.7120 - val_loss: 0.7783 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 424/600\n",
            "2/2 - 0s - loss: 0.5358 - accuracy: 0.7280 - val_loss: 0.7784 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 425/600\n",
            "2/2 - 0s - loss: 0.5580 - accuracy: 0.7000 - val_loss: 0.7780 - val_accuracy: 0.5079 - 33ms/epoch - 16ms/step\n",
            "Epoch 426/600\n",
            "2/2 - 0s - loss: 0.5631 - accuracy: 0.7360 - val_loss: 0.7776 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 427/600\n",
            "2/2 - 0s - loss: 0.5700 - accuracy: 0.7040 - val_loss: 0.7774 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 428/600\n",
            "2/2 - 0s - loss: 0.5551 - accuracy: 0.7000 - val_loss: 0.7763 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 429/600\n",
            "2/2 - 0s - loss: 0.5540 - accuracy: 0.7160 - val_loss: 0.7761 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 430/600\n",
            "2/2 - 0s - loss: 0.5595 - accuracy: 0.7000 - val_loss: 0.7764 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 431/600\n",
            "2/2 - 0s - loss: 0.5581 - accuracy: 0.6960 - val_loss: 0.7763 - val_accuracy: 0.5238 - 39ms/epoch - 19ms/step\n",
            "Epoch 432/600\n",
            "2/2 - 0s - loss: 0.5533 - accuracy: 0.7320 - val_loss: 0.7756 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 433/600\n",
            "2/2 - 0s - loss: 0.5611 - accuracy: 0.6840 - val_loss: 0.7764 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 434/600\n",
            "2/2 - 0s - loss: 0.5729 - accuracy: 0.7040 - val_loss: 0.7784 - val_accuracy: 0.5079 - 30ms/epoch - 15ms/step\n",
            "Epoch 435/600\n",
            "2/2 - 0s - loss: 0.5694 - accuracy: 0.6920 - val_loss: 0.7808 - val_accuracy: 0.5238 - 52ms/epoch - 26ms/step\n",
            "Epoch 436/600\n",
            "2/2 - 0s - loss: 0.5539 - accuracy: 0.7000 - val_loss: 0.7816 - val_accuracy: 0.5079 - 31ms/epoch - 16ms/step\n",
            "Epoch 437/600\n",
            "2/2 - 0s - loss: 0.5482 - accuracy: 0.7200 - val_loss: 0.7804 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 438/600\n",
            "2/2 - 0s - loss: 0.5713 - accuracy: 0.6880 - val_loss: 0.7793 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 439/600\n",
            "2/2 - 0s - loss: 0.5459 - accuracy: 0.7080 - val_loss: 0.7793 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 440/600\n",
            "2/2 - 0s - loss: 0.5519 - accuracy: 0.7280 - val_loss: 0.7788 - val_accuracy: 0.5556 - 33ms/epoch - 16ms/step\n",
            "Epoch 441/600\n",
            "2/2 - 0s - loss: 0.5476 - accuracy: 0.7200 - val_loss: 0.7779 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 442/600\n",
            "2/2 - 0s - loss: 0.5567 - accuracy: 0.7320 - val_loss: 0.7786 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 443/600\n",
            "2/2 - 0s - loss: 0.5473 - accuracy: 0.6920 - val_loss: 0.7806 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 444/600\n",
            "2/2 - 0s - loss: 0.5622 - accuracy: 0.6800 - val_loss: 0.7823 - val_accuracy: 0.5397 - 48ms/epoch - 24ms/step\n",
            "Epoch 445/600\n",
            "2/2 - 0s - loss: 0.5414 - accuracy: 0.7280 - val_loss: 0.7841 - val_accuracy: 0.5238 - 31ms/epoch - 15ms/step\n",
            "Epoch 446/600\n",
            "2/2 - 0s - loss: 0.5397 - accuracy: 0.7240 - val_loss: 0.7861 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 447/600\n",
            "2/2 - 0s - loss: 0.5586 - accuracy: 0.6960 - val_loss: 0.7865 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 448/600\n",
            "2/2 - 0s - loss: 0.5515 - accuracy: 0.7280 - val_loss: 0.7866 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 449/600\n",
            "2/2 - 0s - loss: 0.5603 - accuracy: 0.7040 - val_loss: 0.7874 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 450/600\n",
            "2/2 - 0s - loss: 0.5471 - accuracy: 0.7160 - val_loss: 0.7881 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 451/600\n",
            "2/2 - 0s - loss: 0.5580 - accuracy: 0.6960 - val_loss: 0.7875 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 452/600\n",
            "2/2 - 0s - loss: 0.5515 - accuracy: 0.7120 - val_loss: 0.7900 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 453/600\n",
            "2/2 - 0s - loss: 0.5536 - accuracy: 0.7000 - val_loss: 0.7938 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 454/600\n",
            "2/2 - 0s - loss: 0.5476 - accuracy: 0.7160 - val_loss: 0.7980 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 455/600\n",
            "2/2 - 0s - loss: 0.5540 - accuracy: 0.7080 - val_loss: 0.8004 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 456/600\n",
            "2/2 - 0s - loss: 0.5521 - accuracy: 0.7120 - val_loss: 0.8020 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 457/600\n",
            "2/2 - 0s - loss: 0.5461 - accuracy: 0.7160 - val_loss: 0.8015 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 458/600\n",
            "2/2 - 0s - loss: 0.5475 - accuracy: 0.7160 - val_loss: 0.8020 - val_accuracy: 0.5238 - 30ms/epoch - 15ms/step\n",
            "Epoch 459/600\n",
            "2/2 - 0s - loss: 0.5522 - accuracy: 0.6920 - val_loss: 0.8021 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 460/600\n",
            "2/2 - 0s - loss: 0.5476 - accuracy: 0.7120 - val_loss: 0.8013 - val_accuracy: 0.5238 - 29ms/epoch - 15ms/step\n",
            "Epoch 461/600\n",
            "2/2 - 0s - loss: 0.5439 - accuracy: 0.7240 - val_loss: 0.7995 - val_accuracy: 0.5238 - 42ms/epoch - 21ms/step\n",
            "Epoch 462/600\n",
            "2/2 - 0s - loss: 0.5566 - accuracy: 0.7000 - val_loss: 0.7992 - val_accuracy: 0.5397 - 38ms/epoch - 19ms/step\n",
            "Epoch 463/600\n",
            "2/2 - 0s - loss: 0.5483 - accuracy: 0.7320 - val_loss: 0.7975 - val_accuracy: 0.5397 - 39ms/epoch - 19ms/step\n",
            "Epoch 464/600\n",
            "2/2 - 0s - loss: 0.5511 - accuracy: 0.6880 - val_loss: 0.7979 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 465/600\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7440 - val_loss: 0.7979 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 466/600\n",
            "2/2 - 0s - loss: 0.5347 - accuracy: 0.7400 - val_loss: 0.7984 - val_accuracy: 0.5397 - 38ms/epoch - 19ms/step\n",
            "Epoch 467/600\n",
            "2/2 - 0s - loss: 0.5571 - accuracy: 0.7000 - val_loss: 0.7973 - val_accuracy: 0.5397 - 35ms/epoch - 17ms/step\n",
            "Epoch 468/600\n",
            "2/2 - 0s - loss: 0.5491 - accuracy: 0.7280 - val_loss: 0.7972 - val_accuracy: 0.5238 - 39ms/epoch - 20ms/step\n",
            "Epoch 469/600\n",
            "2/2 - 0s - loss: 0.5399 - accuracy: 0.7160 - val_loss: 0.7982 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 470/600\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7400 - val_loss: 0.7986 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 471/600\n",
            "2/2 - 0s - loss: 0.5480 - accuracy: 0.7160 - val_loss: 0.7964 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 472/600\n",
            "2/2 - 0s - loss: 0.5478 - accuracy: 0.7400 - val_loss: 0.7940 - val_accuracy: 0.5238 - 28ms/epoch - 14ms/step\n",
            "Epoch 473/600\n",
            "2/2 - 0s - loss: 0.5705 - accuracy: 0.7000 - val_loss: 0.7929 - val_accuracy: 0.5397 - 38ms/epoch - 19ms/step\n",
            "Epoch 474/600\n",
            "2/2 - 0s - loss: 0.5528 - accuracy: 0.7160 - val_loss: 0.7927 - val_accuracy: 0.5397 - 43ms/epoch - 21ms/step\n",
            "Epoch 475/600\n",
            "2/2 - 0s - loss: 0.5256 - accuracy: 0.7480 - val_loss: 0.7916 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 476/600\n",
            "2/2 - 0s - loss: 0.5411 - accuracy: 0.7280 - val_loss: 0.7914 - val_accuracy: 0.5238 - 35ms/epoch - 18ms/step\n",
            "Epoch 477/600\n",
            "2/2 - 0s - loss: 0.5366 - accuracy: 0.7320 - val_loss: 0.7906 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 478/600\n",
            "2/2 - 0s - loss: 0.5206 - accuracy: 0.7480 - val_loss: 0.7910 - val_accuracy: 0.5397 - 33ms/epoch - 16ms/step\n",
            "Epoch 479/600\n",
            "2/2 - 0s - loss: 0.5582 - accuracy: 0.6920 - val_loss: 0.7929 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 480/600\n",
            "2/2 - 0s - loss: 0.5500 - accuracy: 0.7280 - val_loss: 0.7951 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 481/600\n",
            "2/2 - 0s - loss: 0.5408 - accuracy: 0.7280 - val_loss: 0.7978 - val_accuracy: 0.5556 - 31ms/epoch - 15ms/step\n",
            "Epoch 482/600\n",
            "2/2 - 0s - loss: 0.5428 - accuracy: 0.7040 - val_loss: 0.7990 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 483/600\n",
            "2/2 - 0s - loss: 0.5323 - accuracy: 0.7360 - val_loss: 0.7975 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 484/600\n",
            "2/2 - 0s - loss: 0.5367 - accuracy: 0.7120 - val_loss: 0.7959 - val_accuracy: 0.5238 - 39ms/epoch - 20ms/step\n",
            "Epoch 485/600\n",
            "2/2 - 0s - loss: 0.5591 - accuracy: 0.6840 - val_loss: 0.7963 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 486/600\n",
            "2/2 - 0s - loss: 0.5506 - accuracy: 0.7240 - val_loss: 0.7973 - val_accuracy: 0.5079 - 66ms/epoch - 33ms/step\n",
            "Epoch 487/600\n",
            "2/2 - 0s - loss: 0.5365 - accuracy: 0.7240 - val_loss: 0.7969 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 488/600\n",
            "2/2 - 0s - loss: 0.5361 - accuracy: 0.7200 - val_loss: 0.7970 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 489/600\n",
            "2/2 - 0s - loss: 0.5328 - accuracy: 0.7240 - val_loss: 0.7981 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 490/600\n",
            "2/2 - 0s - loss: 0.5543 - accuracy: 0.7200 - val_loss: 0.7997 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 491/600\n",
            "2/2 - 0s - loss: 0.5443 - accuracy: 0.6960 - val_loss: 0.8003 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 492/600\n",
            "2/2 - 0s - loss: 0.5438 - accuracy: 0.7040 - val_loss: 0.8009 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 493/600\n",
            "2/2 - 0s - loss: 0.5487 - accuracy: 0.7120 - val_loss: 0.8016 - val_accuracy: 0.5079 - 47ms/epoch - 23ms/step\n",
            "Epoch 494/600\n",
            "2/2 - 0s - loss: 0.5419 - accuracy: 0.7240 - val_loss: 0.8008 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 495/600\n",
            "2/2 - 0s - loss: 0.5175 - accuracy: 0.7480 - val_loss: 0.8004 - val_accuracy: 0.5079 - 39ms/epoch - 20ms/step\n",
            "Epoch 496/600\n",
            "2/2 - 0s - loss: 0.5329 - accuracy: 0.7240 - val_loss: 0.8007 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 497/600\n",
            "2/2 - 0s - loss: 0.5299 - accuracy: 0.7240 - val_loss: 0.8013 - val_accuracy: 0.5079 - 46ms/epoch - 23ms/step\n",
            "Epoch 498/600\n",
            "2/2 - 0s - loss: 0.5196 - accuracy: 0.7120 - val_loss: 0.8017 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 499/600\n",
            "2/2 - 0s - loss: 0.5415 - accuracy: 0.7200 - val_loss: 0.8023 - val_accuracy: 0.5079 - 41ms/epoch - 21ms/step\n",
            "Epoch 500/600\n",
            "2/2 - 0s - loss: 0.5510 - accuracy: 0.7040 - val_loss: 0.8020 - val_accuracy: 0.5079 - 32ms/epoch - 16ms/step\n",
            "Epoch 501/600\n",
            "2/2 - 0s - loss: 0.5266 - accuracy: 0.7240 - val_loss: 0.8025 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 502/600\n",
            "2/2 - 0s - loss: 0.5116 - accuracy: 0.7400 - val_loss: 0.8040 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 503/600\n",
            "2/2 - 0s - loss: 0.5319 - accuracy: 0.7240 - val_loss: 0.8051 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 504/600\n",
            "2/2 - 0s - loss: 0.5296 - accuracy: 0.7440 - val_loss: 0.8044 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 505/600\n",
            "2/2 - 0s - loss: 0.5497 - accuracy: 0.7200 - val_loss: 0.8052 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 506/600\n",
            "2/2 - 0s - loss: 0.5385 - accuracy: 0.7280 - val_loss: 0.8065 - val_accuracy: 0.5714 - 37ms/epoch - 19ms/step\n",
            "Epoch 507/600\n",
            "2/2 - 0s - loss: 0.5312 - accuracy: 0.7040 - val_loss: 0.8068 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 508/600\n",
            "2/2 - 0s - loss: 0.5300 - accuracy: 0.7280 - val_loss: 0.8068 - val_accuracy: 0.5397 - 40ms/epoch - 20ms/step\n",
            "Epoch 509/600\n",
            "2/2 - 0s - loss: 0.5504 - accuracy: 0.7040 - val_loss: 0.8073 - val_accuracy: 0.5397 - 35ms/epoch - 18ms/step\n",
            "Epoch 510/600\n",
            "2/2 - 0s - loss: 0.5341 - accuracy: 0.7200 - val_loss: 0.8061 - val_accuracy: 0.5079 - 40ms/epoch - 20ms/step\n",
            "Epoch 511/600\n",
            "2/2 - 0s - loss: 0.5182 - accuracy: 0.7320 - val_loss: 0.8063 - val_accuracy: 0.4921 - 36ms/epoch - 18ms/step\n",
            "Epoch 512/600\n",
            "2/2 - 0s - loss: 0.5238 - accuracy: 0.7200 - val_loss: 0.8065 - val_accuracy: 0.5079 - 34ms/epoch - 17ms/step\n",
            "Epoch 513/600\n",
            "2/2 - 0s - loss: 0.5308 - accuracy: 0.7320 - val_loss: 0.8069 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 514/600\n",
            "2/2 - 0s - loss: 0.5361 - accuracy: 0.7280 - val_loss: 0.8085 - val_accuracy: 0.5556 - 48ms/epoch - 24ms/step\n",
            "Epoch 515/600\n",
            "2/2 - 0s - loss: 0.5335 - accuracy: 0.7360 - val_loss: 0.8101 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 516/600\n",
            "2/2 - 0s - loss: 0.5407 - accuracy: 0.7240 - val_loss: 0.8102 - val_accuracy: 0.5238 - 36ms/epoch - 18ms/step\n",
            "Epoch 517/600\n",
            "2/2 - 0s - loss: 0.5326 - accuracy: 0.7400 - val_loss: 0.8098 - val_accuracy: 0.5079 - 41ms/epoch - 21ms/step\n",
            "Epoch 518/600\n",
            "2/2 - 0s - loss: 0.5271 - accuracy: 0.7320 - val_loss: 0.8127 - val_accuracy: 0.5079 - 37ms/epoch - 18ms/step\n",
            "Epoch 519/600\n",
            "2/2 - 0s - loss: 0.5510 - accuracy: 0.7040 - val_loss: 0.8154 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 520/600\n",
            "2/2 - 0s - loss: 0.5342 - accuracy: 0.7360 - val_loss: 0.8172 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 521/600\n",
            "2/2 - 0s - loss: 0.5251 - accuracy: 0.7200 - val_loss: 0.8189 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 522/600\n",
            "2/2 - 0s - loss: 0.5246 - accuracy: 0.7240 - val_loss: 0.8219 - val_accuracy: 0.5238 - 35ms/epoch - 17ms/step\n",
            "Epoch 523/600\n",
            "2/2 - 0s - loss: 0.5142 - accuracy: 0.7680 - val_loss: 0.8240 - val_accuracy: 0.5397 - 35ms/epoch - 18ms/step\n",
            "Epoch 524/600\n",
            "2/2 - 0s - loss: 0.5226 - accuracy: 0.7440 - val_loss: 0.8250 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 525/600\n",
            "2/2 - 0s - loss: 0.5249 - accuracy: 0.7400 - val_loss: 0.8242 - val_accuracy: 0.5556 - 38ms/epoch - 19ms/step\n",
            "Epoch 526/600\n",
            "2/2 - 0s - loss: 0.5299 - accuracy: 0.7640 - val_loss: 0.8222 - val_accuracy: 0.5556 - 35ms/epoch - 17ms/step\n",
            "Epoch 527/600\n",
            "2/2 - 0s - loss: 0.5183 - accuracy: 0.7440 - val_loss: 0.8216 - val_accuracy: 0.5714 - 35ms/epoch - 17ms/step\n",
            "Epoch 528/600\n",
            "2/2 - 0s - loss: 0.5337 - accuracy: 0.7280 - val_loss: 0.8222 - val_accuracy: 0.5556 - 37ms/epoch - 18ms/step\n",
            "Epoch 529/600\n",
            "2/2 - 0s - loss: 0.5550 - accuracy: 0.7080 - val_loss: 0.8232 - val_accuracy: 0.5238 - 31ms/epoch - 16ms/step\n",
            "Epoch 530/600\n",
            "2/2 - 0s - loss: 0.5185 - accuracy: 0.7360 - val_loss: 0.8237 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 531/600\n",
            "2/2 - 0s - loss: 0.5357 - accuracy: 0.7440 - val_loss: 0.8234 - val_accuracy: 0.5397 - 34ms/epoch - 17ms/step\n",
            "Epoch 532/600\n",
            "2/2 - 0s - loss: 0.5293 - accuracy: 0.7360 - val_loss: 0.8250 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 533/600\n",
            "2/2 - 0s - loss: 0.5357 - accuracy: 0.7440 - val_loss: 0.8255 - val_accuracy: 0.5556 - 48ms/epoch - 24ms/step\n",
            "Epoch 534/600\n",
            "2/2 - 0s - loss: 0.5382 - accuracy: 0.7080 - val_loss: 0.8267 - val_accuracy: 0.5397 - 39ms/epoch - 19ms/step\n",
            "Epoch 535/600\n",
            "2/2 - 0s - loss: 0.4996 - accuracy: 0.7920 - val_loss: 0.8275 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 536/600\n",
            "2/2 - 0s - loss: 0.5085 - accuracy: 0.7560 - val_loss: 0.8287 - val_accuracy: 0.5238 - 33ms/epoch - 17ms/step\n",
            "Epoch 537/600\n",
            "2/2 - 0s - loss: 0.5270 - accuracy: 0.7360 - val_loss: 0.8287 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 538/600\n",
            "2/2 - 0s - loss: 0.5144 - accuracy: 0.7520 - val_loss: 0.8267 - val_accuracy: 0.5238 - 33ms/epoch - 16ms/step\n",
            "Epoch 539/600\n",
            "2/2 - 0s - loss: 0.5120 - accuracy: 0.7520 - val_loss: 0.8258 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 540/600\n",
            "2/2 - 0s - loss: 0.5166 - accuracy: 0.7320 - val_loss: 0.8267 - val_accuracy: 0.5556 - 52ms/epoch - 26ms/step\n",
            "Epoch 541/600\n",
            "2/2 - 0s - loss: 0.5179 - accuracy: 0.7240 - val_loss: 0.8283 - val_accuracy: 0.5556 - 41ms/epoch - 21ms/step\n",
            "Epoch 542/600\n",
            "2/2 - 0s - loss: 0.5163 - accuracy: 0.7480 - val_loss: 0.8304 - val_accuracy: 0.5556 - 44ms/epoch - 22ms/step\n",
            "Epoch 543/600\n",
            "2/2 - 0s - loss: 0.5204 - accuracy: 0.7560 - val_loss: 0.8322 - val_accuracy: 0.5556 - 34ms/epoch - 17ms/step\n",
            "Epoch 544/600\n",
            "2/2 - 0s - loss: 0.4999 - accuracy: 0.7400 - val_loss: 0.8340 - val_accuracy: 0.5397 - 30ms/epoch - 15ms/step\n",
            "Epoch 545/600\n",
            "2/2 - 0s - loss: 0.5028 - accuracy: 0.7640 - val_loss: 0.8359 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 546/600\n",
            "2/2 - 0s - loss: 0.5132 - accuracy: 0.7320 - val_loss: 0.8360 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 547/600\n",
            "2/2 - 0s - loss: 0.5135 - accuracy: 0.7280 - val_loss: 0.8353 - val_accuracy: 0.5238 - 32ms/epoch - 16ms/step\n",
            "Epoch 548/600\n",
            "2/2 - 0s - loss: 0.5246 - accuracy: 0.7200 - val_loss: 0.8362 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 549/600\n",
            "2/2 - 0s - loss: 0.5349 - accuracy: 0.7200 - val_loss: 0.8349 - val_accuracy: 0.5079 - 35ms/epoch - 18ms/step\n",
            "Epoch 550/600\n",
            "2/2 - 0s - loss: 0.5240 - accuracy: 0.7400 - val_loss: 0.8337 - val_accuracy: 0.5079 - 36ms/epoch - 18ms/step\n",
            "Epoch 551/600\n",
            "2/2 - 0s - loss: 0.5323 - accuracy: 0.7400 - val_loss: 0.8343 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 552/600\n",
            "2/2 - 0s - loss: 0.5053 - accuracy: 0.7480 - val_loss: 0.8336 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 553/600\n",
            "2/2 - 0s - loss: 0.5251 - accuracy: 0.7360 - val_loss: 0.8345 - val_accuracy: 0.5556 - 28ms/epoch - 14ms/step\n",
            "Epoch 554/600\n",
            "2/2 - 0s - loss: 0.5221 - accuracy: 0.7200 - val_loss: 0.8342 - val_accuracy: 0.5556 - 32ms/epoch - 16ms/step\n",
            "Epoch 555/600\n",
            "2/2 - 0s - loss: 0.5369 - accuracy: 0.7200 - val_loss: 0.8320 - val_accuracy: 0.5556 - 39ms/epoch - 20ms/step\n",
            "Epoch 556/600\n",
            "2/2 - 0s - loss: 0.5135 - accuracy: 0.7360 - val_loss: 0.8307 - val_accuracy: 0.5556 - 33ms/epoch - 16ms/step\n",
            "Epoch 557/600\n",
            "2/2 - 0s - loss: 0.5132 - accuracy: 0.7400 - val_loss: 0.8323 - val_accuracy: 0.5556 - 30ms/epoch - 15ms/step\n",
            "Epoch 558/600\n",
            "2/2 - 0s - loss: 0.5088 - accuracy: 0.7400 - val_loss: 0.8344 - val_accuracy: 0.5397 - 33ms/epoch - 17ms/step\n",
            "Epoch 559/600\n",
            "2/2 - 0s - loss: 0.4907 - accuracy: 0.7240 - val_loss: 0.8369 - val_accuracy: 0.5397 - 43ms/epoch - 21ms/step\n",
            "Epoch 560/600\n",
            "2/2 - 0s - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.8401 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 561/600\n",
            "2/2 - 0s - loss: 0.5034 - accuracy: 0.7560 - val_loss: 0.8459 - val_accuracy: 0.5397 - 31ms/epoch - 16ms/step\n",
            "Epoch 562/600\n",
            "2/2 - 0s - loss: 0.5183 - accuracy: 0.7400 - val_loss: 0.8492 - val_accuracy: 0.5397 - 31ms/epoch - 15ms/step\n",
            "Epoch 563/600\n",
            "2/2 - 0s - loss: 0.5183 - accuracy: 0.7200 - val_loss: 0.8509 - val_accuracy: 0.5397 - 36ms/epoch - 18ms/step\n",
            "Epoch 564/600\n",
            "2/2 - 0s - loss: 0.5510 - accuracy: 0.7240 - val_loss: 0.8507 - val_accuracy: 0.5397 - 32ms/epoch - 16ms/step\n",
            "Epoch 565/600\n",
            "2/2 - 0s - loss: 0.5117 - accuracy: 0.7600 - val_loss: 0.8518 - val_accuracy: 0.5238 - 34ms/epoch - 17ms/step\n",
            "Epoch 566/600\n",
            "2/2 - 0s - loss: 0.5272 - accuracy: 0.7240 - val_loss: 0.8523 - val_accuracy: 0.5397 - 37ms/epoch - 19ms/step\n",
            "Epoch 567/600\n",
            "2/2 - 0s - loss: 0.5285 - accuracy: 0.7280 - val_loss: 0.8523 - val_accuracy: 0.5238 - 38ms/epoch - 19ms/step\n",
            "Epoch 568/600\n",
            "2/2 - 0s - loss: 0.5124 - accuracy: 0.7800 - val_loss: 0.8525 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 569/600\n",
            "2/2 - 0s - loss: 0.5280 - accuracy: 0.7080 - val_loss: 0.8517 - val_accuracy: 0.5238 - 53ms/epoch - 27ms/step\n",
            "Epoch 570/600\n",
            "2/2 - 0s - loss: 0.5019 - accuracy: 0.7640 - val_loss: 0.8508 - val_accuracy: 0.5238 - 58ms/epoch - 29ms/step\n",
            "Epoch 571/600\n",
            "2/2 - 0s - loss: 0.5091 - accuracy: 0.7440 - val_loss: 0.8505 - val_accuracy: 0.5238 - 44ms/epoch - 22ms/step\n",
            "Epoch 572/600\n",
            "2/2 - 0s - loss: 0.5220 - accuracy: 0.7440 - val_loss: 0.8484 - val_accuracy: 0.5238 - 47ms/epoch - 23ms/step\n",
            "Epoch 573/600\n",
            "2/2 - 0s - loss: 0.5219 - accuracy: 0.7240 - val_loss: 0.8476 - val_accuracy: 0.5238 - 44ms/epoch - 22ms/step\n",
            "Epoch 574/600\n",
            "2/2 - 0s - loss: 0.5212 - accuracy: 0.7400 - val_loss: 0.8441 - val_accuracy: 0.5238 - 43ms/epoch - 21ms/step\n",
            "Epoch 575/600\n",
            "2/2 - 0s - loss: 0.5056 - accuracy: 0.7400 - val_loss: 0.8425 - val_accuracy: 0.5397 - 43ms/epoch - 22ms/step\n",
            "Epoch 576/600\n",
            "2/2 - 0s - loss: 0.5127 - accuracy: 0.7440 - val_loss: 0.8375 - val_accuracy: 0.5397 - 54ms/epoch - 27ms/step\n",
            "Epoch 577/600\n",
            "2/2 - 0s - loss: 0.4876 - accuracy: 0.7760 - val_loss: 0.8349 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 578/600\n",
            "2/2 - 0s - loss: 0.5183 - accuracy: 0.7400 - val_loss: 0.8364 - val_accuracy: 0.5397 - 46ms/epoch - 23ms/step\n",
            "Epoch 579/600\n",
            "2/2 - 0s - loss: 0.5377 - accuracy: 0.7200 - val_loss: 0.8379 - val_accuracy: 0.5238 - 42ms/epoch - 21ms/step\n",
            "Epoch 580/600\n",
            "2/2 - 0s - loss: 0.5383 - accuracy: 0.7240 - val_loss: 0.8400 - val_accuracy: 0.5238 - 40ms/epoch - 20ms/step\n",
            "Epoch 581/600\n",
            "2/2 - 0s - loss: 0.5189 - accuracy: 0.7440 - val_loss: 0.8420 - val_accuracy: 0.5238 - 78ms/epoch - 39ms/step\n",
            "Epoch 582/600\n",
            "2/2 - 0s - loss: 0.5240 - accuracy: 0.7520 - val_loss: 0.8428 - val_accuracy: 0.5238 - 57ms/epoch - 29ms/step\n",
            "Epoch 583/600\n",
            "2/2 - 0s - loss: 0.5350 - accuracy: 0.7520 - val_loss: 0.8409 - val_accuracy: 0.5238 - 58ms/epoch - 29ms/step\n",
            "Epoch 584/600\n",
            "2/2 - 0s - loss: 0.5168 - accuracy: 0.7600 - val_loss: 0.8403 - val_accuracy: 0.5238 - 45ms/epoch - 23ms/step\n",
            "Epoch 585/600\n",
            "2/2 - 0s - loss: 0.4953 - accuracy: 0.7720 - val_loss: 0.8387 - val_accuracy: 0.5238 - 43ms/epoch - 22ms/step\n",
            "Epoch 586/600\n",
            "2/2 - 0s - loss: 0.5344 - accuracy: 0.7040 - val_loss: 0.8374 - val_accuracy: 0.5238 - 41ms/epoch - 21ms/step\n",
            "Epoch 587/600\n",
            "2/2 - 0s - loss: 0.5104 - accuracy: 0.7400 - val_loss: 0.8372 - val_accuracy: 0.5238 - 43ms/epoch - 22ms/step\n",
            "Epoch 588/600\n",
            "2/2 - 0s - loss: 0.5073 - accuracy: 0.7480 - val_loss: 0.8376 - val_accuracy: 0.5238 - 55ms/epoch - 28ms/step\n",
            "Epoch 589/600\n",
            "2/2 - 0s - loss: 0.5131 - accuracy: 0.7360 - val_loss: 0.8405 - val_accuracy: 0.5238 - 49ms/epoch - 25ms/step\n",
            "Epoch 590/600\n",
            "2/2 - 0s - loss: 0.4968 - accuracy: 0.7440 - val_loss: 0.8440 - val_accuracy: 0.5238 - 53ms/epoch - 27ms/step\n",
            "Epoch 591/600\n",
            "2/2 - 0s - loss: 0.5134 - accuracy: 0.7440 - val_loss: 0.8489 - val_accuracy: 0.5238 - 47ms/epoch - 24ms/step\n",
            "Epoch 592/600\n",
            "2/2 - 0s - loss: 0.5159 - accuracy: 0.7480 - val_loss: 0.8516 - val_accuracy: 0.5238 - 48ms/epoch - 24ms/step\n",
            "Epoch 593/600\n",
            "2/2 - 0s - loss: 0.5372 - accuracy: 0.7320 - val_loss: 0.8531 - val_accuracy: 0.5238 - 48ms/epoch - 24ms/step\n",
            "Epoch 594/600\n",
            "2/2 - 0s - loss: 0.5122 - accuracy: 0.7320 - val_loss: 0.8523 - val_accuracy: 0.5397 - 44ms/epoch - 22ms/step\n",
            "Epoch 595/600\n",
            "2/2 - 0s - loss: 0.5197 - accuracy: 0.7360 - val_loss: 0.8531 - val_accuracy: 0.5397 - 47ms/epoch - 24ms/step\n",
            "Epoch 596/600\n",
            "2/2 - 0s - loss: 0.4994 - accuracy: 0.7720 - val_loss: 0.8546 - val_accuracy: 0.5397 - 38ms/epoch - 19ms/step\n",
            "Epoch 597/600\n",
            "2/2 - 0s - loss: 0.5193 - accuracy: 0.7400 - val_loss: 0.8555 - val_accuracy: 0.5397 - 42ms/epoch - 21ms/step\n",
            "Epoch 598/600\n",
            "2/2 - 0s - loss: 0.5048 - accuracy: 0.7440 - val_loss: 0.8549 - val_accuracy: 0.5397 - 54ms/epoch - 27ms/step\n",
            "Epoch 599/600\n",
            "2/2 - 0s - loss: 0.5175 - accuracy: 0.7240 - val_loss: 0.8556 - val_accuracy: 0.5397 - 58ms/epoch - 29ms/step\n",
            "Epoch 600/600\n",
            "2/2 - 0s - loss: 0.5130 - accuracy: 0.7240 - val_loss: 0.8546 - val_accuracy: 0.5556 - 58ms/epoch - 29ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd02d04be50>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#myPredict = model.predict_classes( X_test).astype('int64')\n",
        "myPredict=model.predict(X_test).astype('int64') \n",
        "classes_x=np.argmax(myPredict,axis=1)\n",
        "classes_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFteMboknXEI",
        "outputId": "da37d14b-49bb-4322-f33e-554bc5c04c91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "#print('score', score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnctAHNo510",
        "outputId": "321871d8-09ca-4cf6-ac10-a93884d8d780"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.4304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(y_test.nonzero()[1:])\n",
        "print(myPredict,'\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-dU9M6LpNqb",
        "outputId": "5713ac23-c749-4d99-8c81-7f30d9588a3c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]] \n",
            " [[1 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 0 1\n",
            "  1 0 0 0 0 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0\n",
            "  1 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    }
  ]
}